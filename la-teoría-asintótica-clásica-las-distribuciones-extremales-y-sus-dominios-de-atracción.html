<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 1 La teoría asintótica clásica, las distribuciones extremales y sus dominios de atracción | 01-asint.knit</title>
  <meta name="description" content="" />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 1 La teoría asintótica clásica, las distribuciones extremales y sus dominios de atracción | 01-asint.knit" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 1 La teoría asintótica clásica, las distribuciones extremales y sus dominios de atracción | 01-asint.knit" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  


<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Estadística para datos extremales</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path=""><a href="#la-teoría-asintótica-clásica-las-distribuciones-extremales-y-sus-dominios-de-atracción"><i class="fa fa-check"></i><b>1</b> La teoría asintótica clásica, las distribuciones extremales y sus dominios de atracción</a>
<ul>
<li class="chapter" data-level="1.1" data-path=""><a href="#datos-extremos"><i class="fa fa-check"></i><b>1.1</b> Datos extremos</a></li>
<li class="chapter" data-level="1.2" data-path=""><a href="#teoría-de-los-valores-extremos-formulación-del-modelo"><i class="fa fa-check"></i><b>1.2</b> Teoría de los valores extremos: formulación del modelo</a></li>
<li class="chapter" data-level="1.3" data-path=""><a href="#las-distribuciones-extremales"><i class="fa fa-check"></i><b>1.3</b> Las distribuciones extremales</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path=""><a href="#supuesto-de-datos-iid"><i class="fa fa-check"></i><b>1.3.1</b> Supuesto de datos <span class="math inline">\(iid\)</span></a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path=""><a href="#hipótesis"><i class="fa fa-check"></i><b>1.4</b> Hipótesis</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path=""><a href="#ajuste"><i class="fa fa-check"></i><b>1.4.1</b> Ajuste</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path=""><a href="#distribución-extremal-asintótica-dea"><i class="fa fa-check"></i><b>1.5</b> Distribución extremal asintótica (DEA)</a></li>
<li class="chapter" data-level="1.6" data-path=""><a href="#distribuciones-max-estables"><i class="fa fa-check"></i><b>1.6</b> Distribuciones max-estables</a></li>
<li class="chapter" data-level="1.7" data-path=""><a href="#dominio-de-atracción-maximal-dam"><i class="fa fa-check"></i><b>1.7</b> Dominio de Atracción Maximal (DAM)</a></li>
<li class="chapter" data-level="1.8" data-path=""><a href="#distribución-generalizada-de-valores-extremos-gev"><i class="fa fa-check"></i><b>1.8</b> Distribución Generalizada de valores extremos (GEV)</a></li>
<li class="chapter" data-level="1.9" data-path=""><a href="#estimación-por-máxima-verosimilitud-mv"><i class="fa fa-check"></i><b>1.9</b> Estimación por Máxima Verosimilitud (MV)</a></li>
<li class="chapter" data-level="1.10" data-path=""><a href="#tiempos-y-valores-de-retorno"><i class="fa fa-check"></i><b>1.10</b> Tiempos y Valores de Retorno</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!--bookdown:title:end-->
<!--bookdown:title:start-->
<div id="la-teoría-asintótica-clásica-las-distribuciones-extremales-y-sus-dominios-de-atracción" class="section level1 hasAnchor" number="1">
<h1><span class="header-section-number">Capítulo 1</span> La teoría asintótica clásica, las distribuciones extremales y sus dominios de atracción<a href="#la-teoría-asintótica-clásica-las-distribuciones-extremales-y-sus-dominios-de-atracción" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<!-- ## Introducción: las distribuciones extremales {#intro}-->
<!-- ecuaciones, su label y ref
\begin{equation} 
  f\left(k\right) = \binom{n}{k} p^k\left(1-p\right)^{n-k}
  (\#eq:binom)
\end{equation} 

You may refer to using `\@ref(eq:binom)`, like see Equation \@ref(eq:binom).
-->
<!-- 
{.unlisted .unnumbered}. 
para sacar la numeracion a la seccion
-->
<div id="datos-extremos" class="section level2 hasAnchor" number="1.1">
<h2><span class="header-section-number">1.1</span> Datos extremos<a href="#datos-extremos" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Se dice que tenemos <em>datos extremos</em> cuando cada dato corresponde al máximo o mínimo de varios
registros. Ejemplos de este tipo de datos son:</p>
<ul>
<li>La máxima altura semanal de la ola en una
plataforma marina o portuaria <span class="math inline">\((m)\)</span>.</li>
<li>La máxima velocidad de viento en determinada
dirección a lo largo de un mes <span class="math inline">\((km/h)\)</span>.</li>
<li>La temperatura ambiental mínima a lo largo de
un día <span class="math inline">\((\dot{C})\)</span>.</li>
<li>La temperatura ambiental mínima a lo largo de
un día (<span class="math inline">\(\dot{C}\)</span>)</li>
<li>La máxima velocidad de tráfico en un enlace de
una red de datos de datos en una hora (<span class="math inline">\(Mb/s\)</span>).</li>
<li>El mayor registro en un conteo de Coliformes
fecales sobre agua costeras al cabo de quince días.</li>
</ul>
<p>Son un caso particular de evento raro o gran desviación respecto a la media. En resumen, para una gran variedad de dominios disciplinares suele ser de gran interés el trabajo con datos extremos, por ejemplo, medioambiente, telecomunicaciones, portafolio y riesgo, entre otros.</p>
<p>El comienzo del curso se centra en la teoría más clásica de estadística de datos extremos, basada en los trabajos de <span class="citation">@frechet1927</span>, <span class="citation">@gumbel1958</span>, <span class="citation">@weibull1951</span>, <span class="citation">@fisher1928limiting</span>, <span class="citation">@gnedenko1943</span>, entre otros. En este marco, los argumentos que manejamos son de tipo <strong>asintóticos</strong><a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> y podríamos decir que nos ubicamos en lo que se conoce en la literatura como <em>paradigma de los valores extremos</em> <span class="citation">[@coles2001introduction]</span>.</p>
<p>En la teoría de valores extremos<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>, existen dos enfoques fundamentales, ambos ampliamente utilizados: el método de máximos por bloques (BM)<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> y el método de excedencias sobre umbral (POT)<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a> <span class="citation">[@ferreira2015]</span>. En este capítulo se pone el foco en el método BM y más adelante veremos el POT.</p>
<p>La metodología de BM en la EVT consiste en dividir el período de observación en bloques no superpuestos de igual tamaño y considerar únicamente el valor máximo observado en cada bloque. Las nuevas observaciones así generadas seguirán (bajo ciertas condiciones) alguna de las distribuciones que veremos en este capítulo (<span class="citation">@ferreira2015</span>, gumbel1958).</p>
<p><strong>Observación 1.1</strong> (Distribución del máximo de dos variables independientes).
Se recuerda que si <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> son variables aleatorias independientes, con funciones de distribución acumulada (cdf) <span class="math inline">\(F\)</span> y <span class="math inline">\(G\)</span>, respectivamente. Entonces, la función de distribución acumulada de la variable aleatoria</p>
<p><span class="math display">\[\begin{equation}
Z = \max(X, Y)
\label{eq:defZ}
\end{equation}\]</span></p>
<p>es</p>
<p><span class="math display" id="eq:HZ">\[\begin{equation}
H(t) = \Pr(\max(X, Y) \le t) = \Pr(X \le t, Y \le t) = F(t) \cdot G(t)
\tag{1.1}
\end{equation}\]</span></p>
<p>donde <span class="math inline">\(t \in \mathbb{R}\)</span> es un valor real arbitrario.</p>
<p>Esto se debe directamente a la independencia de <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>, que implica que</p>
<p><span class="math display" id="eq:indep">\[\begin{equation}
\Pr(X \le t, Y \le t) = \Pr(X \le t) \cdot \Pr(Y \le t).
\tag{1.2}
\end{equation}\]</span></p>
<p><strong>Observación 2.1</strong> (Datos independientes e idénticamente distribuidos (<span class="math inline">\(iid\)</span>)). En esta parte inicial del curso
asumiremos que nuestros datos son <span class="math inline">\(iid\)</span>. Esta doble suposición suele no ser realista en aplicaciones concretas pero
para comenzar a entender la teoría clásica, la utilizaremos por un tiempo.</p>
<p><strong>Observación 3.1</strong> Resulta de la Observación 1.1, que si tenemos la secuencia de datos <span class="math inline">\(X_1,\dots,X_n\)</span> que son <span class="math inline">\(iid\)</span> con distribución <span class="math inline">\(F\)</span>, entonces</p>
<p><span class="math display">\[\begin{equation}
X_n= \max \left( X_1,\dots,X_n \right)\quad\text{tiene distribución}\quad F^{n}.
\end{equation}\]</span></p>
<!--tiene distribución $F^{n}$

\begin{equation}
F^{n\ast} (t) = F^n (t)
\end{equation}
-->
<p>Si conocieramos la distribución <span class="math inline">\(F\)</span> conoceríamos la distribución <span class="math inline">\(F^{n}\)</span>, pero en algunos casos la lectura que queda registrada es la del dato máximo, y no la de cada observación que dio lugar al mismo, por lo que a veces ni siquiera es viable estimar <span class="math inline">\(F\)</span>. Pero aún en los casos en que <span class="math inline">\(F\)</span> es conocida o estimable, si <span class="math inline">\(n\)</span> es grande, la fórmula de <span class="math inline">\(F^{n}\)</span> puede resultar prácticamente inmanejable. En una línea de trabajo similar a la que aporta el Teorema Central del Límite (TCL) <span class="citation">[@bertsekas2008introduction]</span> en la estadística de valores medios (ver Apéndice <a href="#sec:ap"><strong>??</strong></a>), vamos a ver un teorema que nos va a permitir aproximar <span class="math inline">\(F^{n}\)</span> por distribuciones más sencillas. Este es el Teorema de Fischer-Tippet-Gnedenko (FTG) que presentaremos en breve (<span class="citation">@fisher1928limiting</span>, <span class="citation">@gnedenko1943</span>).</p>
<p><strong>Observación 4:</strong> Si la secuencia de datos <span class="math inline">\(X_1,\dots,X_n\;\)</span> es <span class="math inline">\(iid\;\)</span> y definimos
<span class="math inline">\(\;Y_i = -X_i\;\)</span> para todo valor de <span class="math inline">\(i,\dots,n\)</span>, entonces <span class="math inline">\(Y_1,\dots,Y_n\;\)</span> es <span class="math inline">\(iid\;\)</span> y además</p>
<p><span class="math display">\[\begin{equation}
min(X_1,\dots,X_n) = - max(Y_1,\dots,Y_n)
\end{equation}\]</span></p>
<p>la teoría asintótica de los mínimos de datos <span class="math inline">\(iid\)</span> se reduce a la de los máximos, razón por la que
nos concentramos aquí en estudiar el comportamiento asintótico de los máximos exclusivamente. A modo de ejemplo, si suponemos que <span class="math inline">\(R_1, R_2, \dots\)</span> es la secuencia de rendimientos diarios de un índice bursátil. Entonces</p>
<p><span class="math display">\[\begin{equation}
M_n=\max\left\{ R_1, \dots, R_t\right\}
\end{equation}\]</span></p>
<p>es el máximo rendimiento diario observado en un período de “t observaciones”, con <span class="math inline">\(t=1,\dots, T\)</span>.</p>
</div>
<div id="teoría-de-los-valores-extremos-formulación-del-modelo" class="section level2 hasAnchor" number="1.2">
<h2><span class="header-section-number">1.2</span> Teoría de los valores extremos: formulación del modelo<a href="#teoría-de-los-valores-extremos-formulación-del-modelo" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>En un marco asintótico, se puede partir de la siguiente formulación. Supongamos que nuestro modelo se basa en el comportamiento estadístico de</p>
<p><span class="math display">\[\begin{equation}
M_n=\max\left\{ X_1, \dots, X_n\right\}
\end{equation}\]</span></p>
<p>donde <span class="math inline">\(X_1, \dots, X_n\)</span> es la secuencia de variables aleatorias independientes que tienen una distribución común <span class="math inline">\(F\)</span>.</p>
<p>En teoría, la distribución de <span class="math inline">\(M_n\)</span> podría derivarse exactamente para todos los valores de <span class="math inline">\(n\)</span>:
<span class="math display" id="eq:Mn">\[\begin{align}
\Pr\{M_n \leq z\} &amp;= \Pr\{X_1 \leq z, \ldots, X_n \leq z\}\nonumber \\
&amp;= \Pr\{X_1 \leq z\} \times \cdots \times \Pr\{X_n \leq z\} \nonumber \\
&amp;= \left[F(z)\right]^n
\tag{1.3}
\end{align}\]</span></p>
<p>donde <span class="math inline">\(F(z) = \Pr\{X_i \leq z\}\)</span> es la función de distribución de cada variable <span class="math inline">\(X_i\)</span>. Sin embargo, en la práctica esto no es útil porque la función de distribución <span class="math inline">\(F\)</span> es desconocida. Por este motivo, una solución consiste en aproximar <em>familias de modelos</em> para <span class="math inline">\(F^n\)</span> que se estiman únicamente en base a datos extremos:</p>
<ul>
<li><p>Vamos a emplear argumentos análogos a los del TCL: estudiamos el comportamiento de <span class="math inline">\(F^n\)</span> cuando <span class="math inline">\(n\rightarrow \infty\)</span>.</p></li>
<li><p>Lo anterior por sí solo no es suficiente: para cualquier <span class="math inline">\(z &lt; z^+\)</span>, donde <span class="math inline">\(z^+\)</span> es el extremo superior<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a> de la función de distribución <span class="math inline">\(F\)</span>, se cumple que <span class="math inline">\(F^n (z) \to 0\)</span> cuando <span class="math inline">\(n \to \infty\)</span>, lo que implica que la distribución de <span class="math inline">\(M_n\)</span> degenera en una masa puntual en <span class="math inline">\(z^+\)</span>.</p></li>
</ul>
<!--__¿Qué significa lo anterior?__ Si tomás infinitos datos, el máximo va a ser siempre, con probabilidad 1, \( z^+ \).-->
<p>Lo anterior se puede evitar normalizando la variable</p>
<p><span class="math display" id="eq:Mnr">\[\begin{equation}
M^{\ast}_n=\frac{M_n-b_n}{a_n}.
\tag{1.4}
\end{equation}\]</span></p>
<!-- \quad \text{para las secuencias de constantes}\;\left\{  a_n \right\}\;,  \left\{  b_n \right\}.-->
<p>Si elegimos apropiadamente los valores de las secuencias de constantes <span class="math inline">\(\left\{  a_n \right\}\)</span> y <span class="math inline">\(\left\{  b_n \right\}\)</span> es posible estabilizar la escala de <span class="math inline">\(M^{\ast}_n\)</span> a medida que <span class="math inline">\(n\)</span> aumenta. Es por esto, que vamos a buscar las distribuciones límite de <span class="math inline">\(M^{\ast}_n\)</span> <span class="citation">[@coles2001introduction]</span>.</p>
</div>
<div id="las-distribuciones-extremales" class="section level2 hasAnchor" number="1.3">
<h2><span class="header-section-number">1.3</span> Las distribuciones extremales<a href="#las-distribuciones-extremales" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Las distribuciones extremales son tres: la <em>distribución de Gumbel</em>, la <em>distribución de Weibull</em> y
la <em>distribución de Fréchet</em>. En su versión <em>standard</em> o <em>típica</em> se definen del modo siguiente<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a>.</p>
<p>Bajo ciertas condiciones, <span class="math inline">\(M_n^*\)</span> tiende, cuando <span class="math inline">\(n \to \infty\)</span>, a una función límite <span class="math inline">\(G\)</span> que puede pertenecer a una de las siguientes tres familias<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a>:</p>
<p>-<strong>Gumbel</strong> si su distribución es</p>
<p><span class="math display">\[\Lambda(x) = e^{\{-e^{-x}\}}\hspace{0.3cm},\text{ para todo }\: x \;\text{real}\]</span></p>
<p>-<strong>Weibull</strong> de orden <span class="math inline">\(\alpha&gt;0\)</span> si su distribución es</p>
<p><span class="math display">\[\Psi_{\alpha}(x)=\begin{cases}
e^{\left\{-(-x)^{\alpha}  \right\}} &amp;, si\;x&lt;0\\
1 &amp;,\text{en otro caso}
\end{cases}\]</span></p>
<p>-<strong>Fréchet</strong> de orden <span class="math inline">\(\alpha&gt;0\)</span> si su distribución es</p>
<p><span class="math display">\[
\Phi_{\alpha}(x)=\begin{cases}
e^{\left\{ -x^{-\alpha}\right\}} &amp;, \:si\;x&gt;0\\
0&amp;, \:\text{en otro caso}
\end{cases}
\]</span></p>
<p>Las familias Fréchet y Weibull tienen un parámetro de forma <span class="math inline">\(\alpha\)</span>.</p>
<p>Como los máximos en general son valores grandes, importa particularmente observar el comportamiento de estas distribuciones cuando <span class="math inline">\(x \to \infty\)</span>. En toda distribución, el límite es 1, pero no todas se acercan a ese valor de la misma manera. La Weibull se aproxima rápidamente, seguida por la Gumbel y luego la Fréchet. Esto indica que la distribución Fréchet modela datos , es decir, valores máximos provenientes de datos con colas más pesadas que la Gumbel, y ésta más pesadas que la Weibull (Figura <a href="#fig:colas">1.1</a>).</p>
<div class="figure"><span style="display:block;" id="fig:colas"></span>
<img src="01-asint_files/figure-html/colas-1.png" alt="CDF extremales" width="576" />
<p class="caption">
Figura 1.1: CDF extremales
</p>
</div>
<p>En la distribución Fréchet, cuanto menor es el parámetro de forma <span class="math inline">\(\alpha\)</span>, más pesada es la cola y más lenta la convergencia a 1 (Figura <a href="#fig:frcolas">1.2</a>). En cambio, la Weibull tiene soporte acotado superior y el parámetro <span class="math inline">\(\alpha\)</span> afecta principalmente la forma de la cola izquierda<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a>, hacia <span class="math inline">\(-\infty\)</span> (Figura <a href="#fig:weicolas">1.3</a>).</p>
<div class="figure"><span style="display:block;" id="fig:frcolas"></span>
<img src="01-asint_files/figure-html/frcolas-1.png" alt="Distribución Fréchet para distintos parámetros de forma" width="576" />
<p class="caption">
Figura 1.2: Distribución Fréchet para distintos parámetros de forma
</p>
</div>
<div class="figure"><span style="display:block;" id="fig:weicolas"></span>
<img src="01-asint_files/figure-html/weicolas-1.png" alt="Distribución Weibull para dististos parámetros de forma" width="576" />
<p class="caption">
Figura 1.3: Distribución Weibull para dististos parámetros de forma
</p>
</div>
<div style="page-break-after: always;"></div>
<p>Estos fenómenos se visualizarán con mayor claridad al presentar el Teorema <a href="#thm:foo1">1.1</a>. Además, observar las funciones de densidad correspondientes puede ayudar a comprender mejor el peso relativo de las colas de cada distribución. En la Figura <a href="#fig:distributions">1.4</a>, se presentan las funciones de densidad de probabilidad (PDF) extremales. Las PDF permiten visualizar de forma clara las diferencias en la forma, simetría y comportamiento en las colas<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a>.
</p>
<!--
Como los máximos en general son valores grandes, importa particularmente observar el comportamiento de estas distribuciones para $x$ tendiendo a infinito. En toda distribución, el límite es $1$. Tiende más rápido a 1 la Weibull, luego la Gumbel y luego la Fréchet. Esto es indica que la distribución Fréchet modela datos *más extremos*, es decir, máximos de datos de colas más pesadas que la Gumbel y ésta que la Weibull. 

En la Fréchet, la velocidad de convergencia a 1 crece al aumentar el orden. En cambio en la Weibull el orden afecta la velocidad con que va a 0 cuando $x$ tiende a menos infinito, que crece cuanto mayor el orden. Esto quedará más claro con el Teorema 1 del curso. La visualización de las densidades de cada tipo quizás ayude a comprender mejor los pesos relativos de las colas.
-->
<div class="figure"><span style="display:block;" id="fig:distributions"></span>
<img src="01-asint_files/figure-html/distributions-1.png" alt="PDF extremales (alpha=1)" width="576" />
<p class="caption">
Figura 1.4: PDF extremales (alpha=1)
</p>
</div>
<div style="page-break-after: always;"></div>
<p>A estas versiones standard se las puede extender agregando un parámetro de recentramiento <span class="math inline">\((\mu)\)</span> y
un parámetro de escala <span class="math inline">\((\beta)\)</span>.</p>
<p>Se dice que <span class="math inline">\(X\)</span> tiene distribución:</p>
<ul>
<li><p><strong>Gumbel</strong> : <span class="math inline">\(\Lambda^{(\mu, \beta)}\)</span> si <span class="math inline">\(\;X=\mu + \beta Y\;\)</span>, donde <span class="math inline">\(Y\)</span> tiene distribución <span class="math inline">\(\Lambda\)</span>.</p></li>
<li><p><strong>Weibull</strong>: <span class="math inline">\(\;\Psi^{(\mu, \beta)}\;\)</span> si <span class="math inline">\(\;X=\mu + \beta Y\;\)</span>, donde <span class="math inline">\(Y\)</span> tiene distribución <span class="math inline">\(\Psi_{\alpha}\)</span>.</p></li>
<li><p><strong>Fréchet</strong>: <span class="math inline">\(\;\Phi^{(\mu, \beta)}\;\)</span> si <span class="math inline">\(X=\mu + \beta Y\)</span>, donde <span class="math inline">\(Y\)</span> tiene distribución <span class="math inline">\(\Phi_{\alpha}\)</span>.</p></li>
</ul>
<p>En general, es en este sentido que diremos que una variable es Gumbel, Weibull o Fréchet (incluyendo recentramiento y reescalamiento), pero en cálculos donde los parámetros <span class="math inline">\(\mu\)</span> y <span class="math inline">\(\beta\)</span> no sean relevantes, por simplicidad, usaremos las versiones standard.</p>
<p>El siguiente teorema vincula las distribuciones extremales en sus formatos standard (ver Apéndice <a href="#sec:gev"><strong>??</strong></a>) que resulta de gran utilidad práctica, sobre todo al hacer tests de ajustes, etc.</p>
<div class="theorem">
<p><span id="thm:foo1" class="theorem"><strong>Teorema 1.1  (Relaciones entre las versiones standard de las distribuciones extremales) </strong></span><span class="math inline">\(X\)</span> tiene distribución Fréchet <span class="math inline">\(\Phi_{\alpha}\)</span> <span class="math inline">\(\Leftrightarrow\)</span> <span class="math inline">\((-1/X)\)</span> tiene distribución Weibull <span class="math inline">\(\Psi_{\alpha}\)</span> <span class="math inline">\(\Leftrightarrow\)</span> <span class="math inline">\(\log(X^{\alpha})\)</span> tiene distribución Gumbel <span class="math inline">\(\Lambda\)</span>.</p>
</div>
<p><strong>Nota:</strong> En otros contextos de la Estadística (en particular enalguna rutinas de R), se le llama Weibull a una variable que corresponde a <span class="math inline">\(-X\)</span>, con <span class="math inline">\(X\)</span> Weibull como definimos nosotros.</p>
<p><strong>Observación 5:</strong> Recordamos que la función Gamma (<span class="math inline">\(\Gamma\)</span> ), que extiende a la función factorial
(<span class="math inline">\(\;\Gamma(n)=n-1!\quad \forall n\;\)</span> natural)<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a> definida por</p>
<p><span class="math display">\[\begin{equation}
\Gamma(x)=\int_{0}^{\infty} t^{u-1}e^{-t}dt
\end{equation}\]</span></p>
<p>es una función disponible tanto en el software R como en planillas de cálculo, etc.</p>
<div style="page-break-after: always;"></div>
<div class="theorem">
<p><span id="thm:foo2" class="theorem"><strong>Teorema 1.2  (Algunos datos de las distribuciones extremales) </strong></span>Tres partes:</p>
<p><strong>Parte 1)</strong> Si <span class="math inline">\(X\)</span> tiene distribución <span class="math inline">\(\Lambda^{(\mu,\beta)}\)</span> entonces tiene:</p>
<ol style="list-style-type: lower-alpha">
<li><strong>Esperanza</strong>: <span class="math inline">\(E(X) = \mu + \beta\gamma\)</span>, donde <span class="math inline">\(\gamma\)</span> es la constante de Euler-Mascheroni, cuyo valor aproximado es <span class="math inline">\(0.5772156649\)</span>.</li>
</ol>
<ol start="2" style="list-style-type: lower-alpha">
<li><strong>Moda</strong>: <span class="math inline">\(\text{moda}(X)=\mu\)</span>
</li>
<li><strong>Mediana</strong>: <span class="math inline">\(\text{med}(X)=\mu - \beta \log(\log 2) \approx \mu - 0.36651 \beta\)</span>
</li>
<li><strong>Desviación estándar</strong>: <span class="math inline">\(\sigma(X)=\frac{\beta \pi}{\sqrt{6}}   \approx 1.2825 \beta\)</span>
</li>
<li>Si <span class="math inline">\(X^+ = \max(X,0)\)</span>, entonces <span class="math inline">\(E(X^{+k})\)</span> es finito para todo valor de <span class="math inline">\(k\)</span> natural
</li>
<li>Para simular computacionalmente <span class="math inline">\(X\)</span>, se puede tomar <span class="math inline">\(U\)</span> uniforme en <span class="math inline">\((0,1)\)</span> y hacer <span class="math inline">\(X = \mu - \beta \log(-\log U)\)</span>.</li>
</ol>
<p><strong>Parte 2)</strong> Si <span class="math inline">\(X\)</span> tiene distribución <span class="math inline">\(\Psi^{(\mu, \beta)}\)</span> entonces tiene:</p>
<ol style="list-style-type: lower-alpha">
<li><p><span class="math inline">\(E(X)=\mu -\beta \Gamma (1+1/\alpha)\)</span>
</p></li>
<li><p><span class="math display">\[\begin{equation*}\text{moda}(X) =\begin{cases}
  \mu  &amp; \text{si }\; \alpha \leq 1 \\
\mu-\beta\left\{ \frac{\left( \alpha-1 \right)}{\alpha} \right\}^{1/\alpha} &amp; \text{si }\; \alpha &gt;1
\end{cases}\end{equation*}\]</span>
</p></li>
<li><p><span class="math inline">\(\text{med}(X)=\mu - \beta (\log 2)^{\frac{1}{\alpha}}\)</span>
</p></li>
<li><p><span class="math inline">\(\sigma(X)=\beta\left\{\Gamma\left( 1+\frac{2}{\alpha} \right)-\Gamma\left( 1+\frac{1}{\alpha} \right)^2  \right\}^{1/2}\)</span>.
</p></li>
</ol>
<p><strong>Parte 3)</strong> Si <span class="math inline">\(X\)</span> tiene distribución <span class="math inline">\(\Phi_{\alpha}^{(\mu, \beta)}\)</span> entonces tiene:</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math display">\[\begin{equation*}
E(x) =
\begin{cases}
\mu + \beta\;\Gamma\left( 1-\frac{1}{\alpha} \right) &amp; \text{si } \alpha&gt;1 \\
\infty &amp; \text{en otro caso}
\end{cases}
\end{equation*}\]</span>
</li>
<li><span class="math inline">\(\text{moda}(X)=\mu+ \beta\;\left\{ \frac{\alpha}{\left( 1+ \alpha\right)}\right\}^{1/\alpha}\)</span>
</li>
<li><span class="math inline">\(\text{med}(X)=\mu + \beta \;\left( \log 2 \right)^{\left( -1/\alpha \right)}\)</span>
</li>
<li><span class="math display">\[\begin{equation*}
\sigma(x) =
\begin{cases}
\beta \left| \Gamma \left( 1 - \frac{2}{\alpha} \right) - \Gamma \left(  1 - \frac{1}{\alpha}\right)^2\right|  &amp; \text{si } \; \alpha&gt;2 \\
\infty &amp; \text{si } \; 1&lt;\alpha \leq 2
\end{cases}
\end{equation*}\]</span></li>
</ol>
</div>
<p><strong>Observación 6:</strong> El item e) de la Parte 1 es trivialmente cierto para Weibull y tomando en
cuenta el item a) de la Parte 3, es claramente falso
para Fréchet.</p>
<p><strong>Observación 7:</strong> El item f) de la Parte 1 en conjunto con el Teorema <a href="#thm:foo1">1.1</a> brinda fórmulas
sencillas para simular computacionalmente distribuciones Weibull o Fréchet.</p>
<p><strong>Observación 8:</strong> Se generaron mil números aleatorios y aplicando el item f) de la Parte 1: se simularon mil variables Gumbel standard <span class="math inline">\(iid\)</span>, calculándose su promedio, su desviación standard empírica y su mediana
empírica.
</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="do">## Observación 8:</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="co"># Fijar semilla para reproducibilidad</span></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="co"># Definir parámetros</span></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="dv">0</span>       <span class="co"># Centro</span></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a>beta <span class="ot">&lt;-</span> <span class="dv">1</span>     <span class="co"># Escala</span></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a>gamma <span class="ot">&lt;-</span> <span class="fl">0.5772156649</span>  <span class="co"># Constante de Euler-Mascheroni</span></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a><span class="co"># Número de simulaciones</span></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a><span class="co"># Generar 1000 valores de una variable uniforme en (0,1)</span></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a>U <span class="ot">&lt;-</span> <span class="fu">runif</span>(n)</span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a><span class="co"># Simular la variable Gumbel con parámetros (mu, beta)</span></span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a>X_gumbel <span class="ot">&lt;-</span> mu <span class="sc">-</span> beta <span class="sc">*</span> <span class="fu">log</span>(<span class="sc">-</span><span class="fu">log</span>(U))</span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a><span class="co"># Calcular estadísticas</span></span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a>esperanza <span class="ot">&lt;-</span> mu <span class="sc">+</span> beta <span class="sc">*</span> gamma</span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a>moda <span class="ot">&lt;-</span> mu</span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a>mediana_teorica <span class="ot">&lt;-</span> mu <span class="sc">-</span> beta <span class="sc">*</span> <span class="fu">log</span>(<span class="fu">log</span>(<span class="dv">2</span>))</span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a>desviacion_std_teorica <span class="ot">&lt;-</span> beta <span class="sc">*</span> pi <span class="sc">/</span> <span class="fu">sqrt</span>(<span class="dv">6</span>)</span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a><span class="co"># Calcular estadísticas empíricas</span></span>
<span id="cb1-20"><a href="#cb1-20" tabindex="-1"></a>promedio_empirico <span class="ot">&lt;-</span> <span class="fu">mean</span>(X_gumbel)</span>
<span id="cb1-21"><a href="#cb1-21" tabindex="-1"></a>desviacion_std_empirica <span class="ot">&lt;-</span> <span class="fu">sd</span>(X_gumbel)</span>
<span id="cb1-22"><a href="#cb1-22" tabindex="-1"></a>mediana_empirica <span class="ot">&lt;-</span> <span class="fu">median</span>(X_gumbel)</span></code></pre></div>
<p>Los resultados fueron los siguientes:</p>
<pre><code>## ----- Resultados teóricos: -----</code></pre>
<pre><code>## Esperanza teórica: 0.5772157</code></pre>
<pre><code>## Moda teórica: 0</code></pre>
<pre><code>## Mediana teórica: 0.3665129</code></pre>
<pre><code>## Desviación estándar teórica: 1.28255</code></pre>
<pre><code>## ----- Resultados empíricos (simulación con n = 1000 ): -----</code></pre>
<pre><code>## Promedio empírico: 0.5610296</code></pre>
<pre><code>## Mediana empírica: 0.3376409</code></pre>
<pre><code>## Desviación estándar empírica: 1.261928</code></pre>
<p>Observar que los resultados empíricos están cerca del valor esperado, desvío standard y mediana de la Gumbel standard.</p>
<div style="page-break-after: always;"></div>
<p>A continuación presentaremos el Teorema medular de esta primera parte, expresado de la manera más simple posible (<span class="citation">@fisher1928limiting</span>, <span class="citation">@gnedenko1943</span>). Veremos posteriormente algunos detalles con más cuidado. En particular, veremos que la continuidad de la distribución <span class="math inline">\(F\)</span> no es una hipótesis real (ni es necesaria ni es suficiente, por eso la
entrecomillamos), pero ayuda a visualizar que no vale el teorema para toda distribución <span class="math inline">\(F\)</span>, así como veremos con cierto detalle más adelante…</p>
<div class="theorem">
<p><span id="thm:FTG" class="theorem"><strong>Teorema 1.3  (De Fischer-Tippet-Gnedenko (FTG)) </strong></span>Si <span class="math inline">\(X_1,\dots,X_n\)</span> es <span class="math inline">\(iid\)</span> con distribución <span class="math inline">\(F\)</span> continua,
llamamos <span class="math inline">\(F^n\)</span> a la distribución de <span class="math inline">\(max(X_1,\dots,X_n)\)</span>. Si <span class="math inline">\(n\)</span>
es grande, entonces existen <span class="math inline">\(\mu\)</span> real y <span class="math inline">\(\beta &gt; 0\)</span> tales que
alguna de las siguientes tres afirmaciones es
correcta:</p>
<ol style="list-style-type: lower-alpha">
<li><p><span class="math inline">\(F^n\)</span> se puede aproximar por la distribución de <span class="math inline">\(\mu+\beta Y\)</span>, con <span class="math inline">\(Y\)</span> variable con distribución <span class="math inline">\(\Lambda\)</span>.</p></li>
<li><p>Existe <span class="math inline">\(\alpha&gt;0\)</span> tal que <span class="math inline">\(F_n^{\ast}\)</span> se puede aproximar por la distribución de <span class="math inline">\(\mu+\beta Y\)</span> con <span class="math inline">\(Y\)</span> variable con distribución <span class="math inline">\(\Phi_{\alpha}\)</span>.</p></li>
<li><p>Existe <span class="math inline">\(\alpha&gt;0\)</span> tal que <span class="math inline">\(F^n\)</span> se puede aproximar por la distribución de <span class="math inline">\(\mu+\beta Y\)</span> con <span class="math inline">\(Y\)</span> variable con distribución <span class="math inline">\(\Phi_{\alpha}\)</span>.</p></li>
</ol>
</div>
<p>Lo anterior equivale a decir que la distribución del máximo de datos <em>continuos</em> e <span class="math inline">\(iid\)</span>, si <span class="math inline">\(n\)</span> es grande, puede aproximarse por una Gumbel, una Fréchet o una Weibull.</p>
<p><strong>Observación 9:</strong> Cuál de las tres aproximaciones es la válida depende de cómo sea la distribución <span class="math inline">\(F\)</span>.</p>
<p>Por ejemplo, veremos que:</p>
<ul>
<li>Si <span class="math inline">\(F\)</span> es normal o exponencial, se aplica a <span class="math inline">\(F^n\)</span> la aproximación por una Gumbel .</li>
<li>Si <span class="math inline">\(F\)</span> es uniforme, vale para <span class="math inline">\(F^n\)</span> la aproximación por una Weibull.</li>
<li>Si <span class="math inline">\(F\)</span> es Cauchy, la aproximación válida para <span class="math inline">\(F^n\)</span> es por una Fréchet.</li>
</ul>
<p>Más precisamente, cuál de las tres aproximaciones es la aplicable depende de la cola de <span class="math inline">\(F\)</span>: los valores de <span class="math inline">\(F(t)\)</span> para valores grandes de <span class="math inline">\(t\)</span>.</p>
<p>En concreto, Weibull aparece cuando <span class="math inline">\(F\)</span> es la distribución de una variable acotada por arriba
(como la Uniforme), Gumbel para distribuciones de variables no acotadas por arriba pero con colas muy livianas (caso Exponencial y Normal) y Fréchet para colas pesadas (caso Cauchy).</p>
<p>Finalmente, si bien aclaramos que la hipótesis de continuidad de <span class="math inline">\(F\)</span> no es esencial, veremos que si <span class="math inline">\(F\)</span> es la distribución Binomial o Poisson, por mencionar dos ejemplos muy conocidos y sencillos, NO se
puede aplicar ninguna de las tres aproximaciones anteriores.</p>
<p><strong>Observación 10.</strong> Como consecuencia del Teorema <a href="#thm:FTG">1.3</a> si se tienen datos de máximos, las distribuciones extremales son <em>candidatas</em> razonables para proponer en un ajuste.
Sin embargo no debe pensarse que siempre se va a lograr ajustar a una de las tres distribuciones extremales, ya que hay al menos dos causas evidentes que podrían desbaratar la aplicación del Teorema <a href="#thm:FTG">1.3</a>:</p>
<ol style="list-style-type: decimal">
<li><p>Que la cantidad de registros que se consideran al calcular cada máximo no sea suficientemente
grande.</p></li>
<li><p>Que los registros que se consideran al calcular cada máximo no sean <span class="math inline">\(iid\)</span><a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a>.</p></li>
</ol>
<p>Por consiguiente el <a href="#thm:FTG">1.3</a> alienta a intentar ajustar datos extremales a una de las tres distribuciones extremales, pero no siempre un tal ajuste dará un resultado afirmativo.</p>
<!--- EJEMPLO DEL LIBRO A REVEER -->
<div class="example">
<p><span id="exm:ejemplo1" class="example"><strong>Ejemplo 1.1  </strong></span>Veamos un ejemplo de ajuste. Los siguientes datos corresponden a los valores, en <span class="math inline">\(80\)</span> puntos geográficos distintos de la región parisina, del máximo estival del contaminante atmosférico <span class="math inline">\(O_3\)</span> (no perceptible sensorialmente y con impacto sanitario serio). Cada dato es el máximo registro en cada sensor a lo largo de todo un verano; el contaminante se mide diariamente, por lo cual, cada uno de nuestros <span class="math inline">\(80\)</span> datos es el máximo de unas <span class="math inline">\(100\)</span> lecturas diarias (Figura <a href="#fig:parismax">1.5</a>).</p>
</div>
<pre><code>## Error: object &#39;X_i&#39; not found</code></pre>
<div class="figure"><span style="display:block;" id="fig:parismax"></span>
<img src="01-asint_files/figure-html/parismax-1.png" alt="Máximos diarios durante el verano" width="576" />
<p class="caption">
Figura 1.5: Máximos diarios durante el verano
</p>
</div>
<p>Los valores se miden en unidades de referencia standarizadas que, en particular, permiten comparar las medidas de lugares diferentes, independientemente de variables relevantes como altura e incidencia solar, por trabajo previo de calibración.</p>
<p>El <strong>objetivo</strong> del estudio en esta etapa es conocer la distribución de estos datos y en particular estimar la probabilidad de que el máximo estival en los 80 puntos supere el valor 50 (correspondiente a
existencia de riesgo moderado).</p>
<p>Veamos los datos que tenemos:</p>
<pre><code>## [1] &quot;Cálculo de estadísticos básicos&quot;</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    4.48   23.44   52.77  183.93  166.82 1675.00</code></pre>
<div id="supuesto-de-datos-iid" class="section level3 hasAnchor" number="1.3.1">
<h3><span class="header-section-number">1.3.1</span> Supuesto de datos <span class="math inline">\(iid\)</span><a href="#supuesto-de-datos-iid" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Como la mayoría de tests de ajustes suponen datos <span class="math inline">\(iid\)</span>, realizaremos dos tests de aleatoriedad<a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a>:</p>
<ul>
<li>Runs test (Up &amp; Down) : <a href="https://www.geeksforgeeks.org/r-machine-learning/how-to-perform-runs-test-in-r/">runs tests en R</a></li>
<li>Spearman correlation of ranks</li>
</ul>
<div id="prueba-de-rachas-runs-test" class="section level4 hasAnchor" number="1.3.1.1">
<h4><span class="header-section-number">1.3.1.1</span> Prueba de rachas (Runs Test)<a href="#prueba-de-rachas-runs-test" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>La prueba de rachas es un método estadístico sencillo para analizar la <strong>aleatoriedad</strong> de una secuencia de datos. Permite determinar si los datos fluctúan de manera aleatoria o si presentan patrones o tendencias sistemáticas.</p>
<div id="qué-es-la-prueba-de-rachas" class="section level5 hasAnchor" number="1.3.1.1.1">
<h5><span class="header-section-number">1.3.1.1.1</span> ¿Qué es la prueba de rachas?<a href="#qué-es-la-prueba-de-rachas" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Una prueba de rachas evalúa si una secuencia de datos es aleatoria o sigue un patrón sistemático examinando la aparición de rachas.<br />
Una racha es una sucesión consecutiva de valores similares, por ejemplo: altos y bajos, éxitos y fracasos, o cualquier otro resultado binario.</p>
</div>
<div id="cómo-funciona" class="section level5 hasAnchor" number="1.3.1.1.2">
<h5><span class="header-section-number">1.3.1.1.2</span> ¿Cómo funciona?<a href="#cómo-funciona" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ol style="list-style-type: decimal">
<li><strong>Definir rachas:</strong> agrupar los datos en rachas, es decir, ocurrencias consecutivas de valores similares (p. ej., altos vs. bajos o éxitos vs. fracasos).</li>
<li><strong>Calcular rachas esperadas:</strong> suponiendo aleatoriedad, calcular cuántas rachas esperaríamos dado el tamaño del conjunto y la proporción de valores por encima o por debajo de un umbral definido.</li>
<li><strong>Comparar rachas:</strong> comparar el número observado de rachas con el número esperado y usar métodos estadísticos para evaluar si la diferencia es significativa.</li>
<li><strong>Interpretar resultados:</strong> si las rachas observadas difieren significativamente de las esperadas bajo aleatoriedad, se concluye que podría haber <strong>patrones</strong> o <strong>no-aleatoriedad</strong> en los datos.</li>
</ol>
</div>
</div>
</div>
</div>
<div id="hipótesis" class="section level2 hasAnchor" number="1.4">
<h2><span class="header-section-number">1.4</span> Hipótesis<a href="#hipótesis" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li><strong>Hipótesis nula (<span class="math inline">\(H_0\)</span>)</strong>: la secuencia es aleatoria</li>
<li><strong>Hipótesis alternativa (<span class="math inline">\(H_1\)</span>)</strong>: la secuencia no es aleatoria; existe algún patrón no aleatorio.</li>
</ul>
<p>Sources</p>
<p>Aplicamos los tests:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="fu">library</span>(tseries)</span></code></pre></div>
<pre><code>## Registered S3 method overwritten by &#39;quantmod&#39;:
##   method            from
##   as.zoo.data.frame zoo</code></pre>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="co"># ------------------------------</span></span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a><span class="co"># 1. Tests de aleatoriedad</span></span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a><span class="co"># ------------------------------</span></span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a><span class="co"># (a) Runs up and down</span></span>
<span id="cb16-5"><a href="#cb16-5" tabindex="-1"></a>runs_test_result <span class="ot">&lt;-</span> <span class="fu">runs.test</span>(<span class="fu">factor</span>(X_i <span class="sc">&gt;</span> <span class="fu">median</span>(X_i)))</span></code></pre></div>
<pre><code>## Error: object &#39;X_i&#39; not found</code></pre>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a><span class="co"># (b) Spearman</span></span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a>spearman_pval <span class="ot">&lt;-</span> <span class="fu">cor.test</span>(X_i[<span class="sc">-</span>n], X_i[<span class="sc">-</span><span class="dv">1</span>], <span class="at">method =</span> <span class="st">&quot;spearman&quot;</span>)<span class="sc">$</span>p.value</span></code></pre></div>
<pre><code>## Error: object &#39;X_i&#39; not found</code></pre>
<p>Resultados de los tests:</p>
<pre><code>## Error: object &#39;runs_test_result&#39; not found</code></pre>
<pre><code>## Error: object &#39;spearman_pval&#39; not found</code></pre>
<p>Interpretación de tus resultados:</p>
<ul>
<li><p>Runs up and down: No se rechaza la hipótesis nula de aleatoriedad. La secuencia de datos no presenta un patrón sistemático de subidas o bajadas.</p></li>
<li><p>Spearman: No hay evidencia de correlación entre observaciones sucesivas. De hecho, este valor sugiere una independencia aún más clara que la del test de corridas.</p></li>
</ul>
<p>Ambos tests son coherentes con la hipótesis de que los datos se comportan como independientes e idénticamente distribuidos (<span class="math inline">\(iid\)</span>), lo cual justifica el uso de modelos estadísticos que requieren esta suposición.</p>
<div id="ajuste" class="section level3 hasAnchor" number="1.4.1">
<h3><span class="header-section-number">1.4.1</span> Ajuste<a href="#ajuste" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Para realizar el ajuste utilizaremos un conocido test de ajuste de carácter general: el test <span class="math inline">\(\chi^2\)</span> de ajuste. Este test requiere elegir una partición mas o menos arbitraria de la recta real en intervalos; sin embargo es importante que en cada intervalo caiga una cantidad suficiente de datos de la muestra; en este caso hemos tomado como extremos de los intervalos los quintiles empíricos de nuestra muestra. Una aclaración mucho más importante es que este test requiere estimar parámetros por el método de Máxima Verosimilitud Categórica, que da resultado distintos al método de Máxima Verosimilitud a secas. Este hecho es frecuentemente ignorado y presentado erróneamente en los textos y cursos básicos de Estadística.</p>
<!--El p-valor en runs up and down es 0,868 y en
Spearman es 0,474.-->
<p>Como cada dato de los 80 que disponemos es un máximo de un centenar de observaciones, intentaremos ajustarlos a una distribución extremal sabiendo que no necesariamente tendremos éxito. Observemos en particular que lo que pasamos por dos tests de aleatoriedad son los 80 máximos, pero no el centenar de lecturas que forman cada uno de los 80 máximos (ni siquiera tenemos esos datos originales).</p>
<p>Dado que visualmente se aprecian valores muy apartados (Figura <a href="#fig:parishist">1.6</a>), se
presume una distribución de colas pesadas y por ese motivo se intenta un ajuste a una Fréchet.</p>
<div class="figure"><span style="display:block;" id="fig:parishist"></span>
<img src="01-asint_files/figure-html/parishist-1.png" alt="Histograma de los máximos diarios" width="576" />
<p class="caption">
Figura 1.6: Histograma de los máximos diarios
</p>
</div>
<p>Ajuste a una Fréchet:</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" tabindex="-1"></a><span class="co"># ----------------------------</span></span>
<span id="cb22-2"><a href="#cb22-2" tabindex="-1"></a><span class="co"># 1. CDF de Fréchet</span></span>
<span id="cb22-3"><a href="#cb22-3" tabindex="-1"></a><span class="co"># ----------------------------</span></span>
<span id="cb22-4"><a href="#cb22-4" tabindex="-1"></a>frechet_cdf <span class="ot">&lt;-</span> <span class="cf">function</span>(x, alpha, mu, beta) {</span>
<span id="cb22-5"><a href="#cb22-5" tabindex="-1"></a>  <span class="fu">ifelse</span>(x <span class="sc">&gt;</span> mu,</span>
<span id="cb22-6"><a href="#cb22-6" tabindex="-1"></a>         <span class="fu">exp</span>(<span class="sc">-</span>((x <span class="sc">-</span> mu) <span class="sc">/</span> beta)<span class="sc">^</span>(<span class="sc">-</span>alpha)),</span>
<span id="cb22-7"><a href="#cb22-7" tabindex="-1"></a>         <span class="dv">0</span>)</span>
<span id="cb22-8"><a href="#cb22-8" tabindex="-1"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" tabindex="-1"></a><span class="co"># ----------------------------</span></span>
<span id="cb23-2"><a href="#cb23-2" tabindex="-1"></a><span class="co"># 2. Datos y cortes (quintiles)</span></span>
<span id="cb23-3"><a href="#cb23-3" tabindex="-1"></a><span class="co"># ----------------------------</span></span>
<span id="cb23-4"><a href="#cb23-4" tabindex="-1"></a>X_i <span class="ot">&lt;-</span> data<span class="sc">$</span>X_i</span>
<span id="cb23-5"><a href="#cb23-5" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">length</span>(X_i)</span>
<span id="cb23-6"><a href="#cb23-6" tabindex="-1"></a>breaks <span class="ot">&lt;-</span> <span class="fu">quantile</span>(X_i, <span class="at">probs =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">0.2</span>))</span>
<span id="cb23-7"><a href="#cb23-7" tabindex="-1"></a>observed <span class="ot">&lt;-</span> <span class="fu">hist</span>(X_i, <span class="at">breaks =</span> breaks, <span class="at">plot =</span> <span class="cn">FALSE</span>)<span class="sc">$</span>counts</span></code></pre></div>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" tabindex="-1"></a><span class="co"># ----------------------------</span></span>
<span id="cb24-2"><a href="#cb24-2" tabindex="-1"></a><span class="co"># 3. Log-verosimilitud categórica</span></span>
<span id="cb24-3"><a href="#cb24-3" tabindex="-1"></a><span class="co"># ----------------------------</span></span>
<span id="cb24-4"><a href="#cb24-4" tabindex="-1"></a>loglik_cat <span class="ot">&lt;-</span> <span class="cf">function</span>(par) {</span>
<span id="cb24-5"><a href="#cb24-5" tabindex="-1"></a>  alpha <span class="ot">&lt;-</span> par[<span class="dv">1</span>]</span>
<span id="cb24-6"><a href="#cb24-6" tabindex="-1"></a>  mu <span class="ot">&lt;-</span> par[<span class="dv">2</span>]</span>
<span id="cb24-7"><a href="#cb24-7" tabindex="-1"></a>  beta <span class="ot">&lt;-</span> par[<span class="dv">3</span>]</span>
<span id="cb24-8"><a href="#cb24-8" tabindex="-1"></a>  <span class="cf">if</span> (alpha <span class="sc">&lt;=</span> <span class="dv">0</span> <span class="sc">||</span> beta <span class="sc">&lt;=</span> <span class="dv">0</span>) <span class="fu">return</span>(<span class="fl">1e10</span>)  <span class="co"># penalizar fuera del dominio</span></span>
<span id="cb24-9"><a href="#cb24-9" tabindex="-1"></a>  p <span class="ot">&lt;-</span> <span class="fu">diff</span>(<span class="fu">frechet_cdf</span>(breaks, alpha, mu, beta))</span>
<span id="cb24-10"><a href="#cb24-10" tabindex="-1"></a>  p <span class="ot">&lt;-</span> <span class="fu">pmax</span>(p, <span class="fl">1e-10</span>)  <span class="co"># evitar log(0)</span></span>
<span id="cb24-11"><a href="#cb24-11" tabindex="-1"></a>  <span class="sc">-</span><span class="fu">sum</span>(observed <span class="sc">*</span> <span class="fu">log</span>(p))  <span class="co"># log-verosimilitud categórica negativa</span></span>
<span id="cb24-12"><a href="#cb24-12" tabindex="-1"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" tabindex="-1"></a><span class="co"># ----------------------------</span></span>
<span id="cb25-2"><a href="#cb25-2" tabindex="-1"></a><span class="co"># 4. Optimización de parámetros</span></span>
<span id="cb25-3"><a href="#cb25-3" tabindex="-1"></a><span class="co"># ----------------------------</span></span>
<span id="cb25-4"><a href="#cb25-4" tabindex="-1"></a><span class="co"># Valores iniciales: manual</span></span>
<span id="cb25-5"><a href="#cb25-5" tabindex="-1"></a>start_par <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="at">alpha =</span> <span class="fl">1.04</span>, <span class="at">mu =</span> <span class="sc">-</span><span class="fl">6.5</span>, <span class="at">beta =</span> <span class="dv">44</span>)</span>
<span id="cb25-6"><a href="#cb25-6" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">optim</span>(<span class="at">par =</span> start_par, <span class="at">fn =</span> loglik_cat, <span class="at">method =</span> <span class="st">&quot;L-BFGS-B&quot;</span>,</span>
<span id="cb25-7"><a href="#cb25-7" tabindex="-1"></a>             <span class="at">lower =</span> <span class="fu">c</span>(<span class="fl">0.01</span>, <span class="sc">-</span><span class="dv">100</span>, <span class="dv">1</span>), <span class="at">upper =</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">100</span>, <span class="dv">1000</span>))</span></code></pre></div>
<p>Estos son los parámetros estimados por MVC:</p>
<pre><code>##      alpha         mu       beta 
##  0.9095118  0.1325914 35.9094567</code></pre>
<p>Ahora con los parámetros estimados, se realiza el test <span class="math inline">\(\chi^2\)</span>:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" tabindex="-1"></a><span class="co"># Parámetros estimados por MVC</span></span>
<span id="cb27-2"><a href="#cb27-2" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.9095118</span></span>
<span id="cb27-3"><a href="#cb27-3" tabindex="-1"></a>mu    <span class="ot">&lt;-</span> <span class="fl">0.1325914</span></span>
<span id="cb27-4"><a href="#cb27-4" tabindex="-1"></a>beta  <span class="ot">&lt;-</span> <span class="fl">35.9094567</span></span>
<span id="cb27-5"><a href="#cb27-5" tabindex="-1"></a></span>
<span id="cb27-6"><a href="#cb27-6" tabindex="-1"></a><span class="co"># Probabilidades teóricas en cada intervalo (quintiles)</span></span>
<span id="cb27-7"><a href="#cb27-7" tabindex="-1"></a>p_expected <span class="ot">&lt;-</span> <span class="fu">diff</span>(<span class="fu">frechet_cdf</span>(breaks, alpha, mu, beta))</span>
<span id="cb27-8"><a href="#cb27-8" tabindex="-1"></a>expected <span class="ot">&lt;-</span> p_expected <span class="sc">*</span> n</span>
<span id="cb27-9"><a href="#cb27-9" tabindex="-1"></a></span>
<span id="cb27-10"><a href="#cb27-10" tabindex="-1"></a><span class="co"># Recalcular test Chi2</span></span>
<span id="cb27-11"><a href="#cb27-11" tabindex="-1"></a>chi_sq <span class="ot">&lt;-</span> <span class="fu">sum</span>((observed <span class="sc">-</span> expected)<span class="sc">^</span><span class="dv">2</span> <span class="sc">/</span> expected)</span>
<span id="cb27-12"><a href="#cb27-12" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">length</span>(observed) <span class="sc">-</span> <span class="dv">1</span> <span class="sc">-</span> <span class="dv">3</span></span>
<span id="cb27-13"><a href="#cb27-13" tabindex="-1"></a>p_val_chi <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> <span class="fu">pchisq</span>(chi_sq, df)</span></code></pre></div>
<p>Se obtiene como resultados:</p>
<pre><code>## Chi2: 2.961901 gl: 1 p-valor: 0.08524768</code></pre>
<p>Con los parámetros estimados por Máxima Verosimilitud Categórica (<span class="math inline">\(\alpha = 0{,}91\)</span>, <span class="math inline">\(\mu = 0{,}13\)</span>, <span class="math inline">\(\beta = 35{,}91\)</span>), el test <span class="math inline">\(\chi^2\)</span> de ajuste arroja un valor de <span class="math inline">\(2{,}96\)</span> con <span class="math inline">\(1\)</span> grado de libertad, lo que da un valor-<span class="math inline">\(p\)</span> de <span class="math inline">\(0{,}085\)</span>. Esto implica que:</p>
<ul>
<li>Para un nivel de significancia del <span class="math inline">\(10\%\)</span> (<span class="math inline">\(\alpha = 0{,}10\)</span>), no se rechaza la hipótesis nula, por lo tanto el modelo Fréchet es considerado adecuado.</li>
<li>Para un nivel más estricto del <span class="math inline">\(5\%\)</span> (<span class="math inline">\(\alpha = 0{,}05\)</span>), tampoco se rechaza la hipótesis, sin embargo el valor-<span class="math inline">\(p\)</span> se encuentra muy cerca del umbral.</li>
</ul>
<p>Por lo tanto, adoptaremos el modelo Fréchet ajustado por MVC como razonable para describir estos datos.</p>
<div style="page-break-after: always;"></div>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" tabindex="-1"></a><span class="co"># -------------------------------------</span></span>
<span id="cb29-2"><a href="#cb29-2" tabindex="-1"></a><span class="co"># Excedencia del nivel 50</span></span>
<span id="cb29-3"><a href="#cb29-3" tabindex="-1"></a><span class="co"># -------------------------------------</span></span>
<span id="cb29-4"><a href="#cb29-4" tabindex="-1"></a><span class="co"># 1. Proporción empírica de valores que superan 50</span></span>
<span id="cb29-5"><a href="#cb29-5" tabindex="-1"></a>empirical_prop <span class="ot">&lt;-</span> <span class="fu">mean</span>(X_i <span class="sc">&gt;</span> <span class="dv">50</span>)</span>
<span id="cb29-6"><a href="#cb29-6" tabindex="-1"></a><span class="co"># 2. Intervalo de confianza para proporción (binomial)</span></span>
<span id="cb29-7"><a href="#cb29-7" tabindex="-1"></a>exceed_count <span class="ot">&lt;-</span> <span class="fu">sum</span>(X_i <span class="sc">&gt;</span> <span class="dv">50</span>)</span>
<span id="cb29-8"><a href="#cb29-8" tabindex="-1"></a>CI <span class="ot">&lt;-</span> <span class="fu">prop.test</span>(exceed_count, n)<span class="sc">$</span>conf.int  <span class="co"># IC del 95%</span></span>
<span id="cb29-9"><a href="#cb29-9" tabindex="-1"></a><span class="co"># 3. Parámetros estimados previamente por Máxima Verosimilitud Categórica</span></span>
<span id="cb29-10"><a href="#cb29-10" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> fit<span class="sc">$</span>par[<span class="dv">1</span>]</span>
<span id="cb29-11"><a href="#cb29-11" tabindex="-1"></a>mu    <span class="ot">&lt;-</span> fit<span class="sc">$</span>par[<span class="dv">2</span>]</span>
<span id="cb29-12"><a href="#cb29-12" tabindex="-1"></a>beta  <span class="ot">&lt;-</span> fit<span class="sc">$</span>par[<span class="dv">3</span>]</span>
<span id="cb29-13"><a href="#cb29-13" tabindex="-1"></a><span class="co"># 4. Cálculo de la probabilidad de exceder 50 bajo Fréchet ajustada</span></span>
<span id="cb29-14"><a href="#cb29-14" tabindex="-1"></a>p_frechet <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> <span class="fu">frechet_cdf</span>(<span class="dv">50</span>, alpha, mu, beta)</span></code></pre></div>
<p>Resultados:</p>
<pre><code>## Proporción empírica de X_i &gt; 50: 0.5125</code></pre>
<pre><code>## IC (95%) para la proporción empírica: [ 0.3989 , 0.6248 ]</code></pre>
<pre><code>## Probabilidad bajo el modelo Fréchet ajustado: 0.5238</code></pre>
<p>La proporción empírica de excedencias del nivel 50 es <span class="math inline">\(\hat{p} = 0{,}5125\)</span>, con un intervalo de confianza del 95% igual a <span class="math inline">\([0{,}3989,\ 0{,}6248]\)</span>. Bajo el modelo Fréchet ajustado por máxima verosimilitud categórica, se estima una probabilidad de excedencia <span class="math inline">\(\mathbb{P}(X &gt; 50) = 0{,}5238\)</span>. Ambos valores son coherentes, lo que apoya la adecuación del modelo propuesto.</p>
<!--
Adoptando pues este modelo, un sencillo cálculo
muestra que la probabilidad de que el máximo
exceda 50 es 0.455, lo cual es absolutamente
consistente con lo observado en la muestra, donde
la proporción empírica de excedencia del nivel 50
es 0.5125 con un intervalo de confianza al 95%
para esta proporción de (0.403, 0.622).
-->
<!-- Análisis del Q-Q Plot

- Sección Inicial (Cuantiles Bajos): En los valores bajos, los puntos se alinean bien con la diagonal roja, indicando un buen ajuste en la parte central de la distribución.
Colas Extremas:

- Para los valores más extremos, se observan desviaciones importantes de la diagonal, especialmente en los cuantiles más altos.
Esto sugiere que la distribución Fréchet ajustada podría no estar capturando completamente la cola extrema de los datos observados.
-->
<!-- Análisis del Histograma con Densidad Ajustada (Fréchet)

- Ajuste General:La curva de densidad Fréchet (línea roja) sigue la tendencia general del histograma.
Sin embargo, la altura de la primera barra es significativamente mayor que la densidad esperada, lo que sugiere una mayor concentración de valores pequeños.

- Colas Pesadas: La distribución Fréchet modela bien las colas pesadas, aunque podría estar subestimando la frecuencia en las colas extremas.

------------------------

Conclusión: 
- El test de ajuste $\chi^2$ mostró un p-valor aceptable (0.3553), lo cual apoya la hipótesis de un buen ajuste.

Sin embargo, las visualizaciones gráficas indican que:

- Hay una sobreestimación de la densidad en la parte inicial (valores bajos).
- Hay una subestimación de la probabilidad de los valores extremadamente altos.

Entonces, podría ser beneficioso:

Probar otras distribuciones de colas pesadas, como Weibull o Pareto Generalizada (GPD).
Realizar un análisis de valores extremos específicamente en la cola superior.


------- ESTA ES LA CCL DE GONZA, COMO HIZO EL EJ? ------

Conclusión del libro a reveer ejercicio porque no tengo los calculos: 
Adoptando pues este modelo, un sencillo cálculo
muestra que la probabilidad de que el máximo
exceda 50 es 0.455, lo cual es absolutamente
consistente con lo observado en la muestra, donde
la proporción empírica de excedencia del nivel 50
es 0.5125 con un intervalo de confianza al 95%
para esta proporción de (0.403, 0.622). Se llega a la conclusión que hay una incidencia
muy seria de niveles moderados de riesgo (se
prevee que cerca de la mitad de los puntos estén
afectados). 
<!--- FIN EJEMPLO DEL LIBRO A REVEER -->
<p><strong>Observación 10.</strong> Una distribución <span class="math inline">\(H\)</span> se dice <strong>degenerada</strong> si <span class="math inline">\(H(t) = 0\)</span> o <span class="math inline">\(H(t) = 1\)</span> para todo <span class="math inline">\(t \in \mathbb{R}\)</span>. Este tipo de distribuciones representan variables aleatorias constantes. Es decir, si la distribución de <span class="math inline">\(X\)</span> es degenerada, entonces <span class="math inline">\(X = c\)</span> con probabilidad uno, para alguna constante <span class="math inline">\(c\)</span>. En tal caso, no tiene sentido realizar inferencia sobre <span class="math inline">\(X\)</span>, por lo que sólo consideramos de interés las distribuciones no degeneradas.</p>
<!---
Una distribución $H$ se dice degenerada si $H(t)=0 \text{ ó } 1$ para todo valor de $t$. Representan a variables que no son tales, si la distribución de $X$ es degenerada, entonces $X$ es una constante, y no tiene sentido hacer estadística sobre $X$, por lo tanto sólo tienen
interés para nosotros las distribuciones no-degeneradas.
-->
<div style="page-break-after: always;"></div>
</div>
</div>
<div id="distribución-extremal-asintótica-dea" class="section level2 hasAnchor" number="1.5">
<h2><span class="header-section-number">1.5</span> Distribución extremal asintótica (DEA)<a href="#distribución-extremal-asintótica-dea" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="definition">
<p><span id="def:dea" class="definition"><strong>Definición 1.1  (Distribución extremal asintótica (DEA)) </strong></span>Si <span class="math inline">\(X_1,\dots,X_n\)</span> es <span class="math inline">\(iid\)</span> con distribución <span class="math inline">\(F\)</span>, diremos que <span class="math inline">\(H\)</span> no-degenerada es la Distribución Extremal Asintótica (DEA) de <span class="math inline">\(F\)</span>, si existen dos sucesiones de números reales, <span class="math inline">\(d_n\)</span> y <span class="math inline">\(c_n&gt;0\)</span>, tales que la distribución de
<span class="math display">\[\begin{equation}
\frac{max(X_1,\dots,X_n)- d_n}{c_n}\;\text{ tiende a } H \text{ cuando } n \text{ tiende a infinito.}
\end{equation}\]</span></p>
<p>De manera equivalente, diremos que <span class="math inline">\(F\)</span> tiene DEA <span class="math inline">\(H\)</span>.</p>
</div>
<div class="definition">
<p><span id="def:supremo" class="definition"><strong>Definición 1.2  (Supremo esencial de una variable aleatoria o distribución) </strong></span>Si <span class="math inline">\(X\)</span> tiene distribución <span class="math inline">\(F\)</span>,
se llama <span class="math inline">\(M_X\)</span> al supremo esencial de <span class="math inline">\(X\)</span> o,
indistintamente, supremo esencial de <span class="math inline">\(F\)</span> (denotado
<span class="math inline">\(M_F\)</span>) a</p>
<p><span class="math display">\[\begin{equation}
M_X = M_F = \sup\{t \; / \; F(t) &lt; 1\}
\end{equation}\]</span></p>
</div>
<p><strong>Observación 11.</strong></p>
<ul>
<li>Si <span class="math inline">\(F\)</span> es <span class="math inline">\(U(a,b)\)</span>, <span class="math inline">\(M_F=b\)</span>.</li>
<li>Si <span class="math inline">\(F\)</span> es <span class="math inline">\(Bin(m,p)\)</span>, <span class="math inline">\(M_F=m\)</span>.</li>
<li>Si <span class="math inline">\(F\)</span> es Normal, Exponencial, Cauchy o Poisson entonces <span class="math inline">\(M_F\)</span> es infinito.</li>
</ul>
<div class="theorem">
<p><span id="thm:th4" class="theorem"><strong>Teorema 1.4  </strong></span>Si <span class="math inline">\(X_1,\dots,X_n\)</span> es <span class="math inline">\(iid\)</span> con distribución <span class="math inline">\(F\)</span> cualquiera, entonces, para <span class="math inline">\(n \rightarrow \infty\)</span>,</p>
<p><span class="math display">\[\begin{equation}
X_n^{\ast} =max(X_1,\dots,X_n) \rightarrow M_F
\end{equation}\]</span></p>
</div>
<p><strong>Observación 12.</strong> El resultado anterior vale incluso si <span class="math inline">\(M_F\)</span> es infinito, pero si <span class="math inline">\(M_F\)</span> es finito, como
<span class="math inline">\(Xn* - Mf\)</span> tiende a cero, por analogía con el Teorema Central del Límite para promedios, buscaríamos
una sucesión <span class="math inline">\(c_n&gt;0\)</span> y que tienda a cero de modo tal que <span class="math inline">\((X_n^{\ast}- M_F )/ c_n\)</span> tienda a una distribución no-degenerada y de allí surge buscar la DEA.</p>
<div class="theorem">
<p><span id="thm:th5" class="theorem"><strong>Teorema 1.5  </strong></span>Si <span class="math inline">\(F\)</span> es una distribución con <span class="math inline">\(M_F\)</span> finito, y para <span class="math inline">\(X\)</span> con distribución <span class="math inline">\(F\)</span> se cumple que
<span class="math display">\[\begin{equation}
P(X=M_F)&gt;0
\end{equation}\]</span>
entonces <span class="math inline">\(F\)</span> no admite DEA.</p>
</div>
<p><strong>Observación 13.</strong> Si <span class="math inline">\(F\)</span> es <span class="math inline">\(Bin(m,p) \Rightarrow M_F=m\)</span>. Si <span class="math inline">\(X\)</span> tiene distribución <span class="math inline">\(F\)</span>, entonces
<span class="math inline">\(P( X=M_F)= P( X=m)= p^m&gt;0\)</span>, asi que la distribucion <span class="math inline">\(Bin(m,p)\)</span> no admite DEA, no se puede aproximar la distribución del máximo
de una muestra iid de variables <span class="math inline">\(Bin(m,p)\)</span>.</p>
<p>El Teorema anterior es un caso particular del próximo.</p>
<div class="theorem">
<p><span id="thm:th6" class="theorem"><strong>Teorema 1.6  </strong></span>Si <span class="math inline">\(F\)</span> es una distribución con <span class="math inline">\(M_F\)</span> finito o infinito que
admite DEA, y <span class="math inline">\(X\)</span> tiene distribución <span class="math inline">\(F\)</span>, entonces el
limite cuando <span class="math inline">\(t\)</span> tiende a <span class="math inline">\(M_F\)</span> por izquierda de</p>
<p><span class="math display">\[\begin{equation}
P(X&gt;t)/P(X \geq t) \;\text{debe ser}\;1.
\end{equation}\]</span></p>
</div>
<p><strong>Observación 13.</strong> Si <span class="math inline">\(F\)</span> es una distribución de Poisson de parámetro <span class="math inline">\(\lambda &gt;0\)</span>, <span class="math inline">\(M_F\)</span> es infinito. Si <span class="math inline">\(k\)</span> es un natural, entonces</p>
<p><span class="math display">\[\begin{align}
P(X&gt;t)/P(X \geq t)&amp; = P(X \geq k+1)/P(X \geq k)\\
&amp; = 1-\left\{ P(X=k)/P(X \geq k) \right\} \approx 1-(1- \lambda/k)
\end{align}\]</span></p>
<p>que tiende a 0 cuando <span class="math inline">\(k\)</span> tiende a infinito, por lo cual <span class="math inline">\(F\)</span> <strong>no</strong> admite DEA, o sea que no se puede aproximar el máximo de una sucesión <span class="math inline">\(iid\)</span> de variables de Poisson.</p>
<p><strong>Observación 14.</strong> El Teorema <a href="#thm:th6">1.6</a> brinda una condición <strong>necesaria</strong> pero <strong>no suficiente</strong>
para DEA. Un ejemplo de ello lo aportó <span class="citation">@vonmises1954</span>, mostrando que la distribución</p>
<p><span class="math display">\[\begin{equation}
F(x)= 1- e^{(-x-\sin(x))}
\end{equation}\]</span></p>
<p>cumple con la condicion del Teorema <a href="#thm:th6">1.6</a> pero no admite DEA. El tema será cerrado al estudiar los
dominios de atracción maximal, en breve.</p>
<p>Veamos ahora ejemplos donde la DEA resulta aplicable y que ratifican algunos hechos que anticipáramos.</p>
<p><strong>Observación 15.</strong> Si <span class="math inline">\(F\)</span> es <span class="math inline">\(U(0,1)\)</span> y consideramos
<span class="math inline">\(X_1,\dots,X_n\)</span> iid con distribución <span class="math inline">\(F\)</span>, resulta que
la distribución de <span class="math inline">\(n( X_n^{\ast} - 1)\)</span> tiende a <span class="math inline">\(\Psi_1\)</span> por lo cual la distribución uniforme tiene DEA
Weibull.</p>
<p><strong>Observación 16.</strong> Si <span class="math inline">\(F\)</span> es Exponencial de
parámetro 1 y consideramos <span class="math inline">\(X_1,\dots,X_n\)</span> <span class="math inline">\(iid\)</span> con
distribución <span class="math inline">\(F\)</span>, se tiene que la distribución de <span class="math inline">\(X_n^{\ast} - \log n\)</span> tiende a <span class="math inline">\(\Lambda\)</span> por lo cual la distribución exponencial tiene DEA Gumbel.</p>
<p><strong>Observación 17.</strong> Si <span class="math inline">\(F\)</span> es <span class="math inline">\(N(0,1)\)</span> y consideramos
<span class="math inline">\(X_1,\dots,X_n\)</span> iid con distribución <span class="math inline">\(F\)</span>, definimos la función continua y estrictamente decreciente (para <span class="math inline">\(u&gt;0\)</span>)</p>
<p><span class="math display">\[\begin{equation}
g(u)= \frac{e^{-u^2/4\pi}}{u}.
\end{equation}\]</span></p>
<p>Como <span class="math inline">\(\lim_{u \to 0}\; g(u) \rightarrow \infty\)</span> y <span class="math inline">\(\lim_{u \to \infty}\; g(u) \rightarrow 0\)</span>,
para todo natural <span class="math inline">\(n\)</span> existe un único valor <span class="math inline">\(u_n\)</span> tal que</p>
<p><span class="math display">\[\begin{equation}
g(u_n)=\frac{1}{n}
\end{equation}\]</span></p>
<p>y resulta que <span class="math inline">\(\frac{u_n}{\sqrt{2\pi} (X_n^{\ast}- u_n /\sqrt 2\pi)} \rightarrow \Lambda\)</span>, por lo cual la distribución normal tiene DEA Gumbel.</p>
<p><strong>Observación 18.</strong> Si <span class="math inline">\(F\)</span> es Cauchy standard que se expresa como <span class="math inline">\(C(0,1)\)</span>
y consideramos <span class="math inline">\(X_1,\dots,X_n\)</span> <span class="math inline">\(iid\)</span> con distribución <span class="math inline">\(F\)</span>, se tiene que
la distribución de <span class="math inline">\(\pi X_n^{\ast}/n\)</span> tiende a <span class="math inline">\(F_1\)</span> por lo cual la distribución Cauchy tiene DEA Fréchet.</p>
<p>Los ejemplos anteriores no son sorprendentes, en el sentido que aunque presentamos el Teorema <a href="#thm:FTG">1.3</a> en una versión simplificada,
dicho teorema sugiere que cuando <span class="math inline">\(F\)</span> admite DEA, la distribución <span class="math inline">\(H\)</span> deberá ser una distribución extremal. De hecho, el Teorema <a href="#thm:FTG">1.3</a>
resulta de combinar dos teoremas, basadas en una nueva definición: la de distribución <strong>max-estable</strong>.</p>
</div>
<div id="distribuciones-max-estables" class="section level2 hasAnchor" number="1.6">
<h2><span class="header-section-number">1.6</span> Distribuciones max-estables<a href="#distribuciones-max-estables" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="definition">
<p><span id="def:def3" class="definition"><strong>Definición 1.3  </strong></span>Se dice que una distribución <span class="math inline">\(F\)</span> es <strong>max-estable</strong> si, para todo natural <span class="math inline">\(k \geq 2\)</span>, existen las constantes <span class="math inline">\(a_k &gt; 0\)</span> y <span class="math inline">\(b_k \in \mathbb{R}\)</span> tales que:</p>
<p><span class="math display">\[
F^k(a_k x + b_k) = F(x), \quad \text{para todo } x \in \mathbb{R}.
\]</span></p>
<p>Dado que <span class="math inline">\(F^n\)</span> es la función de distribución de <span class="math inline">\(M_n = \max\{X_1, \dots, X_k\}\)</span>, donde las variables <span class="math inline">\(X_i\)</span> son <span class="math inline">\(iid\)</span> con distribución <span class="math inline">\(F\)</span>, la máx-estabilidad es una propiedad que caracteriza a aquellas distribuciones que se mantienen invariantes (salvo cambio de escala y traslación) bajo la operación de tomar máximos muestrales <span class="citation">[@coles2001introduction]</span>. Esto que implica que, bajo estas condiciones, <span class="math inline">\(max(X_1,...,X_k)\)</span> tiene la misma
distribución que <span class="math inline">\(a_k X+ b_k\)</span>.</p>
</div>
<p>El Teorema <a href="#thm:FTG">1.3</a> resulta de superponer los dos siguientes teoremas:</p>
<div class="theorem">
<p><span id="thm:teo7" class="theorem"><strong>Teorema 1.7  </strong></span></p>
<ol style="list-style-type: lower-alpha">
<li><p>Si <span class="math inline">\(F\)</span> admite DEA <span class="math inline">\(H\)</span> entonces <span class="math inline">\(H\)</span> es max-estable.</p></li>
<li><p>Si <span class="math inline">\(H\)</span> es max-estable, es la DEA de sí misma.</p></li>
</ol>
</div>
<div class="theorem">
<p><span id="thm:teo8" class="theorem"><strong>Teorema 1.8  </strong></span>Una distribución es max-estable si y solo si es extremal: Gumbel, Weibull, Fréchet.</p>
</div>
<p>El Teorema <a href="#thm:teo7">1.7</a> es bastante intuitivo y análogo a los Teoremas de Lévy sobre distribuciones estables en
aproximaciones asintóticas de las distribuciones de sumas. Para el Teorema <a href="#thm:teo8">1.8</a> haremos enseguida un ejercicio sencillo que nos ayudará a hacerlo creíble.</p>
<p>Luego precisaremos, para terminar con esta parte, cómo son las distribuciones que tienen por DEA cada uno de los tres tipos de distribuciones extremales. Para eso recordamos algunas definiciones, como la siguiente.</p>
<p><strong>Observación 19.</strong> Si <span class="math inline">\(F\)</span> y <span class="math inline">\(G\)</span> son dos distribuciones, van a tener colas equivalentes si <span class="math inline">\(M_F=M_G\)</span>, y cuando <span class="math inline">\(t\)</span>
tiende a <span class="math inline">\(M_F\)</span> por izquierda entonces <span class="math inline">\((1-F(t))/(1-G(t))\)</span> tiende a un valor <span class="math inline">\(c&gt;0\)</span>.</p>
<p>Recordando ahora cómo se calcula la distribución del máximo de dos variables independientes, es
muy sencillo calcular la distribución del <span class="math inline">\(max\left\{ X,Y \right\}\)</span>, cuando <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> son independientes y cada una de ellas es una distribución extremal. Considerando lo anterior, se lleg al siguiente resultado.</p>
<table>
<colgroup>
<col width="25%" />
<col width="25%" />
<col width="50%" />
</colgroup>
<thead>
<tr class="header">
<th><span class="math inline">\(X\)</span></th>
<th><span class="math inline">\(Y\)</span></th>
<th><span class="math inline">\(max(X,Y)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Además de la tabla anterior, se deduce lo siguiente.</p>
<div class="theorem">
<p><span id="thm:teo9" class="theorem"><strong>Teorema 1.9  </strong></span>Si <span class="math inline">\(X_1,\dots,X_n\)</span> independientes y cada <span class="math inline">\(X_i\)</span> tiene uno de los tres tipos de distribución extremal, entonces la distribución del <span class="math inline">\(max(X_1,\dots,X_n)\)</span> es:</p>
<ol style="list-style-type: lower-alpha">
<li><p>Cola equivalente a Fréchet, si alguna de las variables es Fréchet y alguna otra es Gumbel.</p></li>
<li><p>Fréchet, si alguna es Fréchet y ninguna es Gumbel.</p></li>
<li><p>Cola equivalente Gumbel ninguna es Fréchet pero algunas son Gumbel y otras Weibull.</p></li>
<li><p>Gumbel si todas son Gumbel.</p></li>
<li><p>Weibull si todas son Weibull.<br />
</p></li>
</ol>
</div>
</div>
<div id="dominio-de-atracción-maximal-dam" class="section level2 hasAnchor" number="1.7">
<h2><span class="header-section-number">1.7</span> Dominio de Atracción Maximal (DAM)<a href="#dominio-de-atracción-maximal-dam" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>¿Qué es el dominio de atracción máximal (DAM)?</strong> El dominio de atracción máximal de una distribución límite es el conjunto de todas las distribuciones cuyos valores extremos, como los máximos de muestras grandes, muestran un comportamiento similar en el límite. Esto ocurre después de aplicar un cambio adecuado de escala y ubicación. Aunque las distribuciones originales pueden ser muy distintas, si sus valores extremos se parecen en el límite, decimos que pertenecen al mismo dominio de atracción. Esta idea permite clasificar fenómenos extremos en solo tres tipos posibles (Weibull, Fréchet y Gumbel), según la forma de su cola: con tope, pesada o ligera <span class="citation">[@deHaanFerreira2006]</span>.</p>
<p>El artículo de <span class="citation">@gnedenko1943</span> es un trabajo fundacional de la teoría de valores extremos: establece de forma rigurosa los tres dominios de atracción posibles para los máximos de variables aleatorias independientes e idénticamente distribuidas (<span class="math inline">\(iid\)</span>).</p>
<p>Vamos ahora a ver el concepto de <em>Dominio de Atracción Maximal</em>. Las funciones de variación lenta y regular permiten cuantificar cómo se comporta la cola de una distribución. Ese comportamiento de la cola es lo que define a qué tipo de ley límite (Weibull, Fréchet, Gumbel) convergerán los máximos. Por eso, la teoría del valor extremo y la teoría de funciones de variación están profundamente conectadas.</p>
<p><strong>Observación 20.</strong> Se dice que una distribución <span class="math inline">\(F\)</span> tiene cola de <strong>variación regular</strong> de orden <span class="math inline">\(-\alpha\)</span> (con <span class="math inline">\(\alpha \geq 0\)</span>) si, para todo <span class="math inline">\(t &gt; 0\)</span>,
<span class="math display">\[
\lim_{x \to \infty} \frac{1 - F(tx)}{1 - F(x)} = t^{-\alpha}.
\]</span>
En tal caso se escribe que <span class="math inline">\(F \in R_{-\alpha}\)</span>.</p>
<div class="example">
<p><span id="exm:varregular" class="example"><strong>Ejemplo 1.2  </strong></span>Sea <span class="math inline">\(F(u) = 1 - \frac{1}{u^3}, \quad u \geq 1\)</span>.</p>
<p>Entonces
<span class="math display">\[
1 - F(u) = \frac{1}{u^3}, \quad \text{y} \quad
\frac{1 - F(tu)}{1 - F(u)} = \frac{1/(t^3 u^3)}{1/u^3} = \frac{1}{t^3}.
\]</span>
Por lo tanto
<span class="math display">\[
\lim_{u \to \infty} \frac{1 - F(tu)}{1 - F(u)} = t^{-3},
\]</span>
lo que muestra que <span class="math inline">\(F \in \mathcal{R}_{-3}\)</span>, es decir, tiene cola de variación regular de orden <span class="math inline">\(-3\)</span>.</p>
</div>
<p>Por otra parte, se dice que <span class="math inline">\(L\)</span> es una función de <strong>variación lenta</strong> si <span class="math inline">\(\forall t&gt;0\)</span></p>
<p><span class="math display">\[
\lim_{x \to \infty} \frac{L(tx)}{L(u)} = 1.
\]</span></p>
<div class="example">
<p><span id="exm:unlabeled-div-1" class="example"><strong>Ejemplo 1.3  </strong></span>La función <span class="math inline">\(L(u) = \log u\)</span> es de variación lenta, ya que cumple
<span class="math display">\[\frac{\log(tu)}{\log(u)} = \frac{\log t + \log u}{\log u} = 1 + \frac{\log t}{\log u} \longrightarrow 1 \quad \text{cuando } u \to \infty.\]</span></p>
</div>
<div class="definition">
<p><span id="def:d4" class="definition"><strong>Definición 1.4  (Dominio de Atracción Maximal) </strong></span>Si <span class="math inline">\(H\)</span> es una distribución extremal (Gumbel, Weibull o Fréchet) su Dominio de Atracción Maximal (<span class="math inline">\(DAM(H)\)</span>) está constituído por todas las distribuciones <span class="math inline">\(F\)</span> que tienen <span class="math inline">\(DEA\;H\)</span>.</p>
</div>
<div class="theorem">
<p><span id="thm:th9" class="theorem"><strong>Teorema 1.10  (DAM de la Fréchet) </strong></span>Sea <span class="math inline">\(F\)</span> una función de distribución. Entonces:</p>
<p><span class="math display">\[
F \in DAM(\Phi_{\alpha}) \quad \Leftrightarrow \quad 1 - F(x) = x^{-\alpha} L(x),
\]</span></p>
<p>para alguna <span class="math inline">\(\alpha &gt; 0\)</span> y alguna función <span class="math inline">\(L(x)\)</span> de variación lenta.</p>
<p>Esto es equivalente a decir que <span class="math inline">\(F \in R_{-\alpha}\)</span>, es decir, que <span class="math inline">\(F\)</span> tiene cola de variación regular de orden <span class="math inline">\(-\alpha\)</span>.</p>
</div>
<!-- Un ejemplo típico es $1 - F(x) = x^{-\alpha}, \quad x \geq 1$. En este caso, puede tomarse $d_n = 0, \quad c_n = n^{1/\alpha}$. -->
<div class="example">
<p><span id="exm:unlabeled-div-2" class="example"><strong>Ejemplo 1.4  (Ejemplo típico del DAM de Fréchet) </strong></span>Un caso típico donde se aplica el Teorema <a href="#thm:th9">1.10</a> es cuando la cola de la distribución tiene la forma
<span class="math display">\[
1 - F(x) = x^{-\alpha}, \quad x \geq 1,
\]</span>
para algún <span class="math inline">\(\alpha &gt; 0\)</span>. En este caso, la función <span class="math inline">\(L(x) \equiv 1\)</span> es constante, y por lo tanto, de variación lenta.</p>
<p>Esta distribución pertenece claramente al dominio de atracción de la Fréchet de parámetro <span class="math inline">\(\alpha\)</span>, es decir, <span class="math inline">\(F \in DAM(\Phi_{\alpha})\)</span>.</p>
<p>Además, para normalizar el máximo <span class="math inline">\(M_n = \max(X_1, \dots, X_n)\)</span>, se puede tomar
<span class="math display">\[
d_n = 0, \quad c_n = n^{1/\alpha}.
\]</span>
En particular, si <span class="math inline">\(\alpha = 1\)</span>, entonces <span class="math inline">\(c_n = n\)</span>.</p>
</div>
<!-- __Ejercicio 2 :__ Recompruebe en función de lo anterior que la distribución de Cauchy tiene DEA Fréchet. -->
<div class="exercise">
<p><span id="exr:ejercicio2" class="exercise"><strong>Ejercicio 1.1  </strong></span>Compruebe, en función de lo anterior, que la distribución de Cauchy tiene dominio de atracción máximo (DAM) de la distribución de Fréchet.</p>
</div>
<p>La solución del Ej. <a href="#exr:ejercicio2">1.1</a> se encuentra en el Apéndice <a href="#sec:soluciones"><strong>??</strong></a>.</p>
<div class="corollary">
<p><span id="cor:damfrechet" class="corollary"><strong>Corolario 1.1  (DAM de la Fréchet) </strong></span>Sea <span class="math inline">\(F\)</span> una distribución con densidad <span class="math inline">\(f\)</span>. Si se verifica que
<span class="math display">\[
\lim_{x \to \infty} \frac{x f(x)}{1 - F(x)} = \alpha,
\]</span>
se dice que <span class="math inline">\(F\)</span> cumple la <strong>Condición de Von Mises I</strong>.</p>
<p>En tal caso, <span class="math inline">\(F \in DAM(\Phi_\alpha)\)</span>. Más aún, el dominio de atracción de Fréchet de orden <span class="math inline">\(\alpha\)</span> (<span class="math inline">\(\Phi_{\alpha}\)</span>) está formado por todas las distribuciones cuya cola es equivalente a la de alguna distribución que satisface la Condición de Von Mises I (ver Apéndice <a href="#sec:vonmises"><strong>??</strong></a>).</p>
</div>
<!--

::: {.corollary #corollary1 name="DAM de la Fréchet"}
Si $F$ es una distribución con densidad $f$ que cumple
que $xf(x)/(1-F(x))$ tiende a $\alpha$ cuando $x \rightarrow \infty$, se dice que $F$ cumple la *Condición de Von Mises I*.
En tal caso, $F$ pertenece a la DAM de $\Phi_{\alpha}$ y mas aún, la $DAM$ de $\Phi_{\alpha}$ son todas las distribuciones que tienen cola equivalente a alguna distribución que
cumpla la Condición de Von Mises I.
:::
-->
<p>Del Colorario <a href="#cor:damfrechet">1.1</a> y del Teorema <a href="#thm:foo1">1.1</a> surge lo siguiente.</p>
<div class="theorem">
<p><span id="thm:th10" class="theorem"><strong>Teorema 1.11  (DAM de la Weibull) </strong></span></p>
<ol style="list-style-type: lower-alpha">
<li><p><span class="math inline">\(F\)</span> pertenece a la <span class="math inline">\(DAM\)</span> de <span class="math inline">\(\Psi_{\alpha}\)</span> si y solo si <span class="math inline">\(M_F\)</span> es finito y además <span class="math inline">\(1-F(M_F-1/x)=x^{-\alpha} L(x)\)</span> para alguna <span class="math inline">\(L\)</span> de variación lenta, es decir que pertenece a <span class="math inline">\(R_{-\alpha}\)</span>. Observar que con el cambio de variable <span class="math inline">\(u=M_F-1/x\)</span>, resulta que <span class="math inline">\(1-F(u)=(M_F-u)^{\alpha} L(1/(M_F-u))\)</span> para
alguna <span class="math inline">\(L\)</span> de variación lenta, para <span class="math inline">\(u&lt; M_F\)</span>. Un ejemplo típico sería <span class="math inline">\(1-F(u)=(M_F -u)^{\alpha} ,\; u&lt; MF\)</span>. Además puede tomarse <span class="math inline">\(d_n= M_F\)</span> y <span class="math inline">\(c_n= n^{-\alpha}\)</span>.</p></li>
<li><p>Si <span class="math inline">\(F\)</span> distribución con densidad <span class="math inline">\(f\)</span> positiva en
<span class="math inline">\((a,M_F)\)</span> para algun <span class="math inline">\(a&lt; M_F\)</span> y <span class="math inline">\((M_F -x)f(x)/(1-F(x))\)</span>
tiende a <span class="math inline">\(\alpha\)</span> cuando <span class="math inline">\(x \rightarrow M_F\)</span>, se dice que <span class="math inline">\(F\)</span> cumple la <em>Condición de Von Mises II</em>.
Esto implica que si <span class="math inline">\(F\)</span> es una distribución con densidad <span class="math inline">\(f\)</span> positiva en un intervalo <span class="math inline">\((a, M_F)\)</span>, para algún <span class="math inline">\(a &lt; M_F\)</span>, y además se cumple que:</p></li>
</ol>
<p><span class="math display">\[
\lim_{x \to M_F^-} \frac{(M_F - x) f(x)}{1 - F(x)} = \alpha,
\]</span></p>
<p>entonces <span class="math inline">\(F \in DAM(\Psi_{\alpha})\)</span>. Esta condición garantiza que la función de distribución se comporta como una potencia cerca del extremo superior, y por tanto pertenece al dominio de atracción de Weibull. Más aún, toda distribución cuya cola izquierda sea equivalente a una que cumpla esta condición también pertenece al <span class="math inline">\(DAM(\Psi_{\alpha})\)</span> <span class="citation">[@deHaanFerreira2006]</span></p>
<!--En tal caso, $F$ pertenece a la $DAM$ de $\Psi_{\alpha}$ y mas aún, la $DAM$ de $\Psi_{\alpha}$ son todas las distribuciones que tienen cola equivalente a alguna distribución que cumpla la Condición de
Von Mises II. -->
</div>
<div class="theorem">
<p><span id="thm:th11" class="theorem"><strong>Teorema 1.12  (DAM de la Gumbel) </strong></span>Una distribución <span class="math inline">\(F\)</span> se dice una Función de Von Mises con función auxiliar <span class="math inline">\(h\)</span> si existe <span class="math inline">\(a &lt; M_F\)</span> (<span class="math inline">\(M_F\)</span> puede ser finito o infinito) tal que para algún <span class="math inline">\(c&gt;0\)</span> se tiene</p>
<p><span class="math display" id="eq:th11">\[\begin{equation}
1-F(x)= c\; \exp{- \int_{a}^{x} 1/h(t) dt}
\tag{1.5}
\end{equation}\]</span></p>
<p>Se tiene entonces que la <span class="math inline">\(DAM\)</span> de <span class="math inline">\(\Lambda\)</span> son todas las distribuciones que tienen cola equivalente a alguna distribución que sea una Función de Von Mises.</p>
</div>
<p>Básicamente, se trata de colas más livianas que cualquier expresión del tipo <span class="math inline">\(1/x^k\)</span>, más aún, con decaimiento “del tipo exponencial”, en el sentido preciso siguiente. Si, como en el <a href="#thm:th11">1.12</a>, se tiene que</p>
<p><span class="math display">\[\begin{equation}
1-F(x)= c\; \exp{- \int_{a}^{x} \frac{1}{h(t)} dt},
\end{equation}\]</span></p>
<p>entonces se tiene <span class="math inline">\(1-F(x)\leq c\; \exp\{-(x-a)/h(x)\}\)</span>, donde la función auxiliar
<span class="math inline">\(h\)</span> es no-decreciente y con asíntota horizontal.</p>
<p>Además, <span class="math inline">\(d_n\)</span> y <span class="math inline">\(c_n\)</span> suelen involucrar expresiones logarítmicas. Más concretamente, <span class="math inline">\(dn = F^{-1}(1-1/n)\)</span> y,
<span class="math inline">\(c_n = h(d_n)\)</span>, donde <span class="math inline">\(F^{-1}\)</span> es la inversa generalizada (o función cuantil), definida por
<span class="math inline">\(F^{-1}(p)= \inf\{t / F(t)\geq p\}\)</span>, para <span class="math inline">\(0&lt;p&lt;1\)</span>.</p>
<div class="corollary">
<p><span id="cor:coll2" class="corollary"><strong>Corolario 1.2  </strong></span>Si <span class="math inline">\(F\)</span> pertenece al <span class="math inline">\(DAM\)</span> Gumbel, <span class="math inline">\(M_F\)</span>
es infinito, y se considera <span class="math inline">\(X\)</span> con distribucion <span class="math inline">\(F\)</span>,
entonces <span class="math inline">\(E(X+k)\)</span> es finito para todo <span class="math inline">\(k\)</span> natural.</p>
</div>
<p>Los resultados antes vistos nos permiten reconocer
qué distribuciones tienen <span class="math inline">\(DEA\)</span> y si la tienen, cual es. Cierran el tema. Adicionalmente, permiten ver con mucha precisión que el quid de esta teoría es el comportamiento de las colas de las distribuciones, que Fréchet corresponde a las colas más pesadas, luego la Gumbel y finalmente Weibull. Para terminar el capítulo presentaremos la distribución de valores extremos generalizada
(GEV, por sus siglas en inglés), que es una forma de compactar en una unica fórmula las tres
distribuciones extremales, debida a Jenkinson-Von Mises.</p>
<!-- __Observación 23.__ Tiempos y Valores de Retorno. -->
<div class="exercise">
<p><span id="exr:Ejercicio3" class="exercise"><strong>Ejercicio 1.2  </strong></span></p>
<ol style="list-style-type: lower-alpha">
<li><p>Recompruebe en función de lo
anterior que la distribución uniforme tiene <span class="math inline">\(DEA\)</span> Weibull.</p></li>
<li><p>Encuentre la fórmula explícita de
alguna distribución que no sea la uniforme y tenga
<span class="math inline">\(DEA\)</span> Weibull. Solo resta encontrar la <span class="math inline">\(DEA\)</span> Gumbel, y eso lo
aporta el próximo resultado.</p></li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:Ejercicio4" class="exercise"><strong>Ejercicio 1.3  </strong></span>Recompruebe en función de lo anterior que la distribución exponencial y la
distribución normal tienen <span class="math inline">\(DEA\)</span> Gumbel.</p>
</div>
<div class="exercise">
<p><span id="exr:Ejercicio5" class="exercise"><strong>Ejercicio 1.4  </strong></span></p>
<ol style="list-style-type: lower-alpha">
<li><p>Determinar si la distribución log-normal (<span class="math inline">\(\log X\)</span> es normal) tiene DEA y si la tiene,
determinar cuál es su DEA.</p></li>
<li><p>Con la ayuda de R
simular una muestra de 100 datos iid, cada uno de
los cuales es el máximo de 500 log-normales
standard <span class="math inline">\(iid\)</span>. Intente ajustar la distribución de la
muestra de 100 datos de acuerdo a lo obtenido en
la parte a).</p></li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:Ejercicio6" class="exercise"><strong>Ejercicio 1.5  (Variable acotada en DAM Gumbel) </strong></span>Tomemos tres constantes estrictamente positivas <span class="math inline">\(\alpha,\; M, \;K\)</span> y definamos <span class="math inline">\(F(x)= 1 – K \exp\{-\alpha /(M-x)\}\)</span> para <span class="math inline">\(x&lt;M\)</span>. Mostrar que <span class="math inline">\(F\)</span> es una distribución y que <span class="math inline">\(M_F= M\)</span>.</p>
<p>Probar que <span class="math inline">\(F\)</span> es una función de Von Mises con
función auxiliar <span class="math inline">\(h(t)= (M-t)^2/\alpha\)</span> y que por lo tanto
está en el <span class="math inline">\(DAM\)</span> Gumbel. Finalmente, si <span class="math inline">\(X_1,\dots,X_k\)</span>
<span class="math inline">\(iid\)</span> con distribución <span class="math inline">\(F\)</span>, calcular las sucesiones de
reales, <span class="math inline">\(d_n\)</span> y <span class="math inline">\(c_n&gt;0\)</span>, tales que la distribución de
<span class="math inline">\(\frac{max(X_1,\dots,X_n)- d_n}{c_n}\rightarrow \Lambda\)</span> cuando <span class="math inline">\(n\rightarrow \infty\)</span>.</p>
</div>
<p>Las soluciones de todos los ejercicios se encuentran en el Capítulo <a href="#sec:soluciones"><strong>??</strong></a>.</p>
<!---  comentarios -->
<div style="page-break-after: always;"></div>
</div>
<div id="distribución-generalizada-de-valores-extremos-gev" class="section level2 hasAnchor" number="1.8">
<h2><span class="header-section-number">1.8</span> Distribución Generalizada de valores extremos (GEV)<a href="#distribución-generalizada-de-valores-extremos-gev" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Las familias de distribuciones Gumbel, Fréchet y Weibull se pueden combinar en una única familia de modelos con función de distribucion (GEV) bajo la forma ,</p>
<p><span class="math display" id="eq:Gz">\[\begin{equation}
G\left( z \right)=\exp\left\{ -\left[ 1+ \xi\left( \frac{z-\mu}{\beta} \right) \right]^{-1/\xi} \right\}
\tag{1.6}
\end{equation}\]</span></p>
<p>definida en el conjunto <span class="math inline">\(\left\{ z: 1+\xi\left( z-\mu \right)/\beta&gt;0 \right\}\)</span> donde los parámetros satisfacen <span class="math inline">\(-\infty &lt; \mu &lt; \infty\)</span>, <span class="math inline">\(\beta&gt;0\)</span> y <span class="math inline">\(-\infty &lt; \xi &lt; \infty\)</span> <span class="citation">[@coles2001introduction]</span>.</p>
<p>Tomando en consideración los disintos valores que puede tomar <span class="math inline">\(\xi\)</span>, se expresa la siguiente definición.</p>
<div class="definition">
<p><span id="def:def5" class="definition"><strong>Definición 1.5  (Distribución Generalizada de valores extremos (GEV)) </strong></span>Se define la GEV como
<span class="math display">\[\begin{equation}
G(z;\mu,\beta,\xi) = \left\{ \begin{array}{cl}
e^{\left( 1+\frac{\xi(z-\mu)}{\beta} \right)^{-\frac{1}{\xi}}}, &amp; \text{si}\;\xi \neq 0,\\
e^{ -\exp\left( -\frac{(z-\mu)}{\beta} \right) }, &amp; \text{si}\;\xi = 0
\end{array} \right.
\end{equation}\]</span>
para todo <span class="math inline">\(z\)</span>, con parámetros de posición <span class="math inline">\(\mu\)</span>, escala <span class="math inline">\(\beta\)</span> e índice <span class="math inline">\(\xi\)</span>.
<span class="math display">\[
\text{Cuando }
\begin{cases}
\xi=0 &amp; \text{: corresponde a Gumbel} \\
\xi&lt; 0 &amp; \text{: corresponde a Weibull} \\
\xi&gt; 0 &amp; \text{: corresponde a Fréchet}
\end{cases}
\]</span></p>
</div>
<p>En <code>R</code> existen rutinas para estimar <span class="math inline">\(\xi\)</span> con intervalos de confianza (por máxima verosimilitud, etc.) lo cual da formas de testear si una extremal es Gumbel, Weibull o Fréchet.</p>
<p><strong>Observación 21.</strong> En algunas situaciones los datos extremales pueden ajustarse a más de un modelo. Por ejemplo, puede ocurrir que tanto ajusten los datos una Gumbel como una Weibull. Frente a estas situaciones, no hay una receta única de cómo proceder sino que quien está modelando debe tener claro si corresponde volcarse hacia cálculos más pesimistas (que dan mayor probabilidad a eventos extremos muy severos) o más optimistas.</p>
<p>Usualmente la opción pesimista implica privilegiar la seguridad y la optimista la economía de recursos, pero insistimos en que la reflexión ante cada caso es indispensable. Un poquito más delante veremos, al comparar un modelo Gumbel con un modelo Fréchet, que las diferencias pueden ser sumamente drásticas.</p>
<p><strong>Observación 22.</strong> Antes de seguir adelante, demos la respuesta a la parte a) del Ejercicio 5. Es un
ejercicio de Cálculo Diferencial sencillo mostrar que la cola de un <span class="math inline">\(N(0,1)\)</span>, es decir <span class="math inline">\(Q(t)=P(X&gt;t)\)</span>,
donde <span class="math inline">\(X\)</span> tiene distribución <span class="math inline">\(N(0,1)\)</span>, es equivalente, para <span class="math inline">\(t\)</span> tendiendo a infinito, a la función <span class="math inline">\(\phi(t)/t\)</span>, donde <span class="math inline">\(\phi\)</span> representa la densidad normal típica (campana de Gauss). Basándose en esto, si se considera ahora una variable log-normal <span class="math inline">\(Y\)</span>, tal que <span class="math inline">\(\log(Y)\)</span> es una <span class="math inline">\(N(0,1)\)</span>, puede probarse que su cola <span class="math inline">\(R(t)=P(Y&gt;t)\)</span>, es equivalente, para t tendiendo a
infinito, a la función <span class="math inline">\(\phi(\log(t))/\log(t)\)</span>. Con un poco más de Cálculo, esta última función puede
escribirse para <span class="math inline">\(a&gt;e\)</span> (por ejemplo <span class="math inline">\(a=3\)</span>), como <span class="math inline">\(c\;\exp\{-\int_a^{t} \frac{1}{h(s)}ds \}\)</span> para <span class="math inline">\(t&gt;a\)</span>, donde <span class="math inline">\(c\)</span> se expresa
en función de <span class="math inline">\(a\)</span> y <span class="math inline">\(h(s)=\frac{s\log(s)}{(\log(s))^2}\)</span>, la cual cumple las hipótesis del Teo. <a href="#thm:th11">1.12</a>.</p>
<p>Se concluye entonces que la log-normal está en el DAM Gumbel, o, lo que es lo mismo, que la log-normal admite DEA Gumbel.</p>
<!---  transicion a  Tiempos y Valores de Retorno --->
<div class="example">
<p><span id="exm:unlabeled-div-3" class="example"><strong>Ejemplo 1.5  (Máximos de abundancia poblacional de fitoplancton) </strong></span>Una aplicación relevante del enfoque de valores extremos generalizados (GEV) se presenta en <span class="citation">@segura2023metabolic</span>, donde se modelan máximos de abundancia poblacional de fitoplancton como función del tamaño corporal y recursos ambientales. El ajuste de modelos GEV por clases de tamaño permitió evidenciar escalamiento negativo de la abundancia máxima con el tamaño corporal, en línea con predicciones teóricas basadas en restricciones metabólicas.</p>
<p>Además, se modelaron los parámetros de la distribución GEV como funciones de temperatura y nutrientes, permitiendo capturar la variabilidad residual con mayor precisión que usando modelos gaussianos. Este enfoque ilustra cómo incorporar covariables ecológicas relevantes en el modelado de extremos y cómo evitar sesgos importantes en la estimación de tiempos de retorno.</p>
</div>
</div>
<div id="estimación-por-máxima-verosimilitud-mv" class="section level2 hasAnchor" number="1.9">
<h2><span class="header-section-number">1.9</span> Estimación por Máxima Verosimilitud (MV)<a href="#estimación-por-máxima-verosimilitud-mv" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Una vez que decidimos usar una distribución GEV para modelar los máximos por bloques (por ejemplo, las máximas anuales de temperatura o precipitación), el siguiente paso es ajustar el modelo a los datos. Esto significa estimar los tres parámetros de la GEV:</p>
<ul>
<li><p><span class="math inline">\(\mu\)</span>: de localización</p></li>
<li><p><span class="math inline">\(\sigma\)</span>: de escala</p></li>
<li><p><span class="math inline">\(\xi\)</span>: parámetro de forma</p></li>
</ul>
<p>Estos parámetros determinan completamente la forma y el comportamiento de la distribución.</p>
<p>El método más utilizado es el de Máxima Verosimilitud (MV). La idea central consiste en buscar los valores de los parámetros que hacen que los datos observados sean “lo más probables posible” bajo el modelo (ver Apéndice <a href="#sec:ap"><strong>??</strong></a>, sección <a href="#sec:mv"><strong>??</strong></a>).</p>
<p>Este procedimiento se realiza mediante optimización numérica. En la práctica, existen funciones en R (como <code>fgev()</code> del paquete <code>ismev</code>, o <code>fevd()</code> del paquete <code>extRemes</code>) que implementan este ajuste de manera automática.</p>
<p>Pero este método no siempre funciona bien. El método de máxima verosimilitud tiene muy buenas propiedades si se cumplen ciertas condiciones:</p>
<ol style="list-style-type: lower-alpha">
<li><p>Cuando el parámetro de forma <span class="math inline">\(\xi &gt; -0.5\)</span>, los estimadores son regulares y se comportan bien en muestras grandes.</p></li>
<li><p>Si <span class="math inline">\(-1 &lt; \xi &lt; -0.5\)</span>, los estimadores existen, pero no tienen las propiedades asintóticas habituales.</p></li>
<li><p>Si <span class="math inline">\(\xi &lt; -1\)</span>, los estimadores por máxima verosimilitud pueden no existir.</p></li>
</ol>
<p>En gerenal, en la práctica, vamos a estar en el caso a (<span class="citation">@coles2001introduction</span>).</p>
<div style="page-break-after: always;"></div>
<div class="example">
<p><span id="exm:mv" class="example"><strong>Ejemplo 1.6  (Estimación por MV) </strong></span>Cuando disponemos de una muestra y asumimos que sigue un cierto modelo probabilístico, el paso siguiente consiste en determinar los parámetros de dicho modelo. Como estos parámetros son desconocidos, deben ser estimados a partir de los datos. Existen diversos métodos de estimación, pero el enfoque más utilizado y recomendado es el de máxima verosimilitud, por sus buenas propiedades estadísticas y su aplicabilidad general.</p>
<p>Con los siguientes datos vamos ajustar y estimar por MV una GEV y una distribución Gumbel para luego analizar la bondad de ajuste en cada caso.</p>
</div>
<p>Vamos a usar el paquete <code>evd</code> de <code>R</code> y de los datos <code>uccle</code> tomamos la columna <code>day</code> que contiene el máximo anual de precipitaciones diarias. Es decir, para cada año, se tomó el día con la lluvia más alta registrada, y ese valor es el que se guarda en la columna <code>day</code>.</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" tabindex="-1"></a><span class="fu">library</span>(evd)</span>
<span id="cb33-2"><a href="#cb33-2" tabindex="-1"></a><span class="fu">data</span>(uccle)</span></code></pre></div>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" tabindex="-1"></a><span class="fu">head</span>(uccle, <span class="dv">5</span>)</span></code></pre></div>
<pre><code>##       day hour tmin min
## 1938 33.8 14.0  6.5 2.5
## 1939 27.7 12.8  8.5 1.0
## 1940 60.0 12.9  5.0 0.5
## 1941 24.0 11.9  8.4 0.9
## 1942 72.3 20.6 13.2 1.5</code></pre>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" tabindex="-1"></a>datos<span class="ot">=</span>uccle<span class="sc">$</span>day</span>
<span id="cb36-2"><a href="#cb36-2" tabindex="-1"></a><span class="fu">class</span>(datos)</span></code></pre></div>
<pre><code>## [1] &quot;numeric&quot;</code></pre>
<p>Vamos a emplear la función <code>fgev</code> que ajusta los parámetros por MV a una distribución de valores
extremos generalizada, <span class="math inline">\(GEV(\mu,\beta,\xi)\)</span>.</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" tabindex="-1"></a>fit_gev <span class="ot">&lt;-</span> evd<span class="sc">::</span><span class="fu">fgev</span>(datos)</span>
<span id="cb38-2"><a href="#cb38-2" tabindex="-1"></a>fit_gev<span class="sc">$</span>estimate</span></code></pre></div>
<pre><code>##       loc     scale     shape 
## 28.382361  9.029078  0.231600</code></pre>
<p>Para ajustar una distribución de Gumbel, imponemos <span class="math inline">\(shape=0\)</span>.</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" tabindex="-1"></a>fit_gumbel <span class="ot">&lt;-</span> evd<span class="sc">::</span><span class="fu">fgev</span>(datos,<span class="at">shape=</span><span class="dv">0</span>)</span>
<span id="cb40-2"><a href="#cb40-2" tabindex="-1"></a>fit_gumbel<span class="sc">$</span>estimate</span></code></pre></div>
<pre><code>##      loc    scale 
## 29.57536 10.14995</code></pre>
<p>Se suelen utilizar gráficos de niveles de retorno para visualizar la relación entre los niveles estimados y sus correspondientes periodos de retorno, los cuales suelen representarse en escala logarítmica. Estos gráficos permiten obtener una estimación visual de los valores extremos esperados para distintos horizontes temporales. Sin embargo, para una mayor precisión, se recomienda realizar los cálculos numéricamente.</p>
<p>Además, existen diversos <strong>gráficos de diagnóstico</strong> que permiten evaluar de forma cualitativa la <strong>bondad del ajuste</strong> del modelo a los datos observados como se presentan en las siguientes figuras, para el caso del ajuste <code>fit_gev</code>.</p>
<div class="figure"><span style="display:block;" id="fig:diagnosticofgev-1"></span>
<img src="01-asint_files/figure-html/diagnosticofgev-1.png" alt="Gráfico de cuantiles (Q–Q)" width="1152" />
<p class="caption">
Figura 1.7: Gráfico de cuantiles (Q–Q)
</p>
</div>
<div class="figure"><span style="display:block;" id="fig:diagnosticofgev-2"></span>
<img src="01-asint_files/figure-html/diagnosticofgev-2.png" alt="Gráfico de probabilidades (P–P)" width="1152" />
<p class="caption">
Figura 1.8: Gráfico de probabilidades (P–P)
</p>
</div>
<div class="figure"><span style="display:block;" id="fig:diagnosticofgev-3"></span>
<img src="01-asint_files/figure-html/diagnosticofgev-3.png" alt="Densidad ajustada vs empírica" width="1152" />
<p class="caption">
Figura 1.9: Densidad ajustada vs empírica
</p>
</div>
<div class="figure"><span style="display:block;" id="fig:diagnosticofgev-4"></span>
<img src="01-asint_files/figure-html/diagnosticofgev-4.png" alt="Niveles de retorno" width="1152" />
<p class="caption">
Figura 1.10: Niveles de retorno
</p>
</div>
<ul>
<li><p>Gráfico P–P: este gráfico compara las probabilidades empíricas (representadas por cruces) con las probabilidades teóricas que predice el modelo GEV. Si el ajuste es bueno, los puntos deben alinearse cerca de la diagonal (la línea de 45°). Cuanto más cerca estén los puntos de esa línea, mejor es la concordancia entre los datos y el modelo. Además, el gráfico suele incluir bandas de tolerancia: si la mayoría de los puntos cae dentro de esas bandas, eso indica que el modelo ajusta adecuadamente los datos.</p></li>
<li><p>Grafico Q-Q plot: el ajuste será mejor cuanto más se aproximen los puntos a la recta y estén entre los límites.</p></li>
<li><p>Gráfico de la función de densidad empírica y la función de valores extremos generalizada estimada. El análisis en este caso es visual.</p></li>
<li><p>Gráfico de niveles y periodos de retorno: calcularlos permite concluir respecto al ajuste (Veremos estos conceptos en la próxima sección.).</p></li>
</ul>
<p>Otra herramienta útil para evaluar la bondad del ajuste de un modelo es el test de Kolmogorov–Smirnov (KS). Este test está implementado en R mediante la función <code>ks.test()</code>. El objetivo del test es comparar si una distribución empírica (obtenida a partir de los datos) se ajusta razonablemente bien a una distribución teórica especificada previamente.</p>
<p>Se plantea un contraste de hipótesis</p>
<ul>
<li><span class="math inline">\(H_0\)</span>: los datos provienen de una determinada distribución teórica (por ejemplo, normal o GEV).</li>
<li><span class="math inline">\(H_1\)</span>: los datos no provienen de esa distribución.</li>
</ul>
<p>Al aplicar el test, se obtiene</p>
<ul>
<li><p>Un valor estadístico <span class="math inline">\(D\)</span>, que representa la máxima diferencia absoluta entre la función de distribución acumulada empírica y la teórica.</p></li>
<li><p>Un p-valor, que permite decidir si hay evidencia suficiente para rechazar <span class="math inline">\(H_0\)</span>.</p></li>
</ul>
<p>Si <span class="math inline">\(D\)</span> es pequeño (y el p-valor es grande), eso indica que no hay una diferencia significativa entre los datos y la distribución teórica, y por tanto el modelo podría ser adecuado.</p>
<p>El critorio de decisión consiste en comparar el estadístico <span class="math inline">\(D\)</span> con un valor crítico <span class="math inline">\(D_\alpha\)</span>, determinado por el nivel de significación <span class="math inline">\(\alpha\)</span>:</p>
<ul>
<li>Si <span class="math inline">\(D &gt; D_\alpha\)</span>, se rechaza <span class="math inline">\(H_0\)</span>: los datos no se ajustan a la distribución propuesta.</li>
<li>Si <span class="math inline">\(D \leq D_\alpha\)</span>, no se rechaza <span class="math inline">\(H_0\)</span>: no hay evidencia para descartar el modelo.</li>
</ul>
<p>En resumen, el test KS proporciona una forma cuantitativa y no paramétrica de evaluar si una distribución teórica es compatible con los datos observados.</p>
<p>Una forma práctica y habitual de tomar decisiones con el test de Kolmogorov–Smirnov es a través del p-valor que devuelve el test</p>
<ul>
<li>Si el p-valor es mayor que <span class="math inline">\(\alpha\)</span> entonces no se rechaza la hipótesis nula. El modelo podría ajustarse bien.</li>
<li>Si el p-valor es menor que <span class="math inline">\(\alpha\)</span> entonces se rechaza la hipótesis nula. Hay evidencia de que el modelo no se ajusta.</li>
</ul>
<p>El valor de <span class="math inline">\(\alpha\)</span> más común es 0.05.</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" tabindex="-1"></a><span class="co"># Aplico el test sobre fit_gev:</span></span>
<span id="cb42-2"><a href="#cb42-2" tabindex="-1"></a><span class="fu">ks.test</span>(uccle<span class="sc">$</span>day, <span class="st">&quot;pgev&quot;</span>, </span>
<span id="cb42-3"><a href="#cb42-3" tabindex="-1"></a>        fit_gev<span class="sc">$</span>estimate[<span class="dv">1</span>], </span>
<span id="cb42-4"><a href="#cb42-4" tabindex="-1"></a>        fit_gev<span class="sc">$</span>estimate[<span class="dv">2</span>], </span>
<span id="cb42-5"><a href="#cb42-5" tabindex="-1"></a>        fit_gev<span class="sc">$</span>estimate[<span class="dv">3</span>])</span></code></pre></div>
<pre><code>## Warning in ks.test.default(uccle$day, &quot;pgev&quot;, fit_gev$estimate[1],
## fit_gev$estimate[2], : ties should not be present for the Kolmogorov-Smirnov
## test</code></pre>
<pre><code>## 
##  Asymptotic one-sample Kolmogorov-Smirnov test
## 
## data:  uccle$day
## D = 0.079718, p-value = 0.9793
## alternative hypothesis: two-sided</code></pre>
<ul>
<li><p>Advertencia sobre “ties”: El mensaje <code>"ties should not be present"</code> indica que hay valores repetidos (empates) en los datos (<code>uccle$day</code>). El test de Kolmogorov–Smirnov asume que los datos provienen de una distribución continua, sin empates exactos. Aunque el test se puede ejecutar, la presencia de empates puede afectar la precisión del valor-p, especialmente si son muchos. Esto es común cuando los datos se redondean a valores discretos (por ejemplo, a milímetros enteros).</p></li>
<li><p><span class="math inline">\(D = 0.0797\)</span> : Este valor representa la máxima diferencia absoluta entre la función de distribución empírica y la función acumulada de la GEV ajustada. Cuanto menor sea <span class="math inline">\(D\)</span>, mejor es el ajuste del modelo a los datos.</p></li>
<li><p><span class="math inline">\(\text{p-valor} = 0.9793\)</span>: Este valor es muy alto, lo que indica que no hay evidencia suficiente para rechazar la hipótesis nula de que los datos provienen de la distribución GEV ajustada.</p></li>
</ul>
<p>Entonces, según el test de Kolmogorov–Smirnov, el modelo GEV se ajusta adecuadamente a los datos analizados.</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" tabindex="-1"></a><span class="co">#Aplico el test sobre fit_gumbel:</span></span>
<span id="cb45-2"><a href="#cb45-2" tabindex="-1"></a><span class="fu">ks.test</span>(uccle<span class="sc">$</span>day, <span class="st">&quot;pgev&quot;</span>, </span>
<span id="cb45-3"><a href="#cb45-3" tabindex="-1"></a>        fit_gumbel<span class="sc">$</span>estimate[<span class="dv">1</span>], </span>
<span id="cb45-4"><a href="#cb45-4" tabindex="-1"></a>        fit_gumbel<span class="sc">$</span>estimate[<span class="dv">2</span>])</span></code></pre></div>
<pre><code>## Warning in ks.test.default(uccle$day, &quot;pgev&quot;, fit_gumbel$estimate[1],
## fit_gumbel$estimate[2]): ties should not be present for the Kolmogorov-Smirnov
## test</code></pre>
<pre><code>## 
##  Asymptotic one-sample Kolmogorov-Smirnov test
## 
## data:  uccle$day
## D = 0.11038, p-value = 0.7873
## alternative hypothesis: two-sided</code></pre>
<p>Según el test de Kolmogorov–Smirnov, el modelo Gumbel se ajusta adecuadamente a los datos analizados.</p>
<div style="page-break-after: always;"></div>
</div>
<div id="tiempos-y-valores-de-retorno" class="section level2 hasAnchor" number="1.10">
<h2><span class="header-section-number">1.10</span> Tiempos y Valores de Retorno<a href="#tiempos-y-valores-de-retorno" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Siguiendo a <span class="citation">@coles2001introduction</span>, vamos a ver la relación que existe entre GEV y los conceptos de <strong>valor de retorno</strong> (VR) y <strong>tiempo de retorno</strong> (T) de la presente sección. La Definición <a href="#def:def5">1.5</a> implica que se puede aproximar a la Eq.<a href="#eq:Mnr">(1.4)</a> como una integrante de la familia de GEV cuando <span class="math inline">\(n\)</span> es grande. Esto conlleva al siguiente enfoque para modelar las observaciones de datos extremos <span class="math inline">\(X_1,X_2,\dots\)</span> : se forman bloques de observaciones de largo <span class="math inline">\(n\)</span> (para <span class="math inline">\(n\)</span> grande) lo que permite crear bloques de máximos <span class="math inline">\(M_{n,1},\dots, M_{n,m}\)</span>. Con esto va a ser posible ajustar una distibución GEV.</p>
<p>A menudo, los bloques se eligen para que correspondan a un período de tiempo de un año de duración, en cuyo caso <span class="math inline">\(n\)</span> es el número de observaciones en un año y los máximos por bloque son máximos anuales. Considerando lo anterior, al invertir la Ec. <a href="#eq:Gz">(1.6)</a> obtenermos las expresiones para estimar los cuantiles extremos de la distribución del máximo anual, dadas por</p>
<p><span class="math display" id="eq:rv">\[\begin{equation}
z_p=\left\{ \begin{array}{cl}
\mu-\frac{\beta}{\xi}\left[ 1-\left\{ -\log\left( 1-p \right) \right\}^{-\xi} \right], &amp;  \xi \neq 0 \\
\mu-\beta\log\left\{ -\log\left( 1-p \right) \right\}, &amp;  \xi = 0
\end{array} \right.
\tag{1.7}
\end{equation}\]</span></p>
<p>donde <span class="math inline">\(P(X&gt;z_p)=1/p\; \Rightarrow G(z_p)=1-p\)</span>. Con los parámetros estimados por MV <span class="math inline">\(\hat{\mu}, \hat{\beta}, \hat{\xi}\)</span> sustituimos en <a href="#eq:rv">(1.7)</a> y obtenermos <span class="math inline">\(z_p\)</span>.</p>
<p>Decimos que <span class="math inline">\(z_p\)</span> es el valor de retorno (<span class="math inline">\(VR\)</span>) asociado al tiempo de retorno (<span class="math inline">\(T\)</span>) expresado como <span class="math inline">\(1/p\)</span> y se espera que el valor <span class="math inline">\(z_p\)</span> sea excedido en media una vez cada <span class="math inline">\(1/p\)</span> años. Es decir, para un año cualquiera, existe una probabilidad <span class="math inline">\(p\)</span> de que el valor máximo supere el nivel <span class="math inline">\(z_p\)</span>.</p>
<p>Como los cuantiles permiten trabajar en la misma escala que los datos, es más fácil entender cómo los parámetros del modelo GEV afectan al modelo usando las fórmulas de los cuantiles <a href="#eq:rv">(1.7)</a>. En particular, si <span class="math inline">\(y_p=-\log\left(1-p\right)\)</span>, entonces</p>
<p><span class="math display">\[\begin{equation}
z_p=\left\{ \begin{array}{cl}
\mu-\frac{\beta}{\xi}\left[ 1-y_p^{-\xi} \right], &amp;  \xi \neq 0 \\
\mu-\beta\log y_p, &amp;  \xi = 0
\end{array} \right.
\end{equation}\]</span></p>
<p>Si se grafica <span class="math inline">\(z_p\)</span> contra <span class="math inline">\(\log y_p\)</span>:</p>
<ul>
<li><p>si <span class="math inline">\(\xi = 0\)</span> entonces se tiene una recta. Implica que los eventos extremos aumentan lentamente con el tiempo. Los eventos extremos son posibles, pero crecen de manera moderada y predecible.</p></li>
<li><p>si <span class="math inline">\(\xi &lt;0\)</span>, la curva es convexa con límite asintótico a medida que <span class="math inline">\(p \to 0\;\)</span> en <span class="math inline">\(\mu - \beta / \xi\)</span>. No importa cuánto tiempo pase, el valor extremo no supera cierto límite. Hay un tope físico o natural. Por ejemplo, si estamos midiendo velocidad del viento, quizá físicamente no puede superar cierto umbral.</p></li>
<li><p>si <span class="math inline">\(\xi &gt;0\)</span>, la curva es cóncava y no tiene un límite finito. No hay límite para los extremos. A medida que el tiempo de retorno aumenta, los eventos extremos se vuelven cada vez más grandes y más peligrosos. Esto es típico en fenómenos con colas pesadas, como catástrofes financieras o terremotos extremos.</p></li>
</ul>
<p>Debido a la simplicidad en su interpretación, y a que la elección de la escala comprime la cola de la distribución, resaltando así el efecto de la extrapolación, las gráficas de niveles de retorno son especialmente útiles para presentar los datos y para validar. En la siguiente Figura <a href="#fig:nr">1.11</a> se presentan las curvas de valores de retorno para distintos valores de <span class="math inline">\(\xi\)</span>.</p>
<div class="figure"><span style="display:block;" id="fig:nr"></span>
<img src="01-asint_files/figure-html/nr-1.png" alt="Curvas de VR para distintos valores del parámetro de forma" width="576" />
<p class="caption">
Figura 1.11: Curvas de VR para distintos valores del parámetro de forma
</p>
</div>
<p><strong>¿Por qué son importantes estos conceptos?</strong></p>
<p>En Ingeniería y Ciencias Ambientales, suele pensarse a los eventos extremos, en términos de tiempos de retorno, es decir, el tiempo que se espera para que ocurra un evento. En este sentido, bajo las hipótesis de datos <span class="math inline">\(iid\)</span>, se dice que el tiempo de retorno <span class="math inline">\(T\)</span> tiene una distribución <span class="math inline">\(Geo(p)\)</span>, con <span class="math inline">\(p = P(evento)\)</span>. Por lo tanto, el tiempo de retorno medio es <span class="math inline">\(E(T)=1/p\)</span> y pueden hacerse intervalos de confianza para <span class="math inline">\(E(T)\)</span>, en la medida que exista información de <span class="math inline">\(P(evento)\)</span>.</p>
<p>Cabe observar que muchas veces se utiliza la expresión Tiempo de Retorno (TR) para <span class="math inline">\(E(T)\)</span>. Más precisamente, <span class="math inline">\(TR(u)\)</span>, el tiempo de retorno del valor <span class="math inline">\(u\)</span>, es el valor esperado (o la media) del tiempo que se debe esperar para que la variable en estudio supere el valor <span class="math inline">\(u\)</span>. Esto implica que <span class="math inline">\(TR(u) =1/P(X&gt;u)\)</span>, si <span class="math inline">\(X\)</span> es la variable en estudio.</p>
<p>Por otro lado, y de manera inversa, el Valor de Retorno a tiempo <span class="math inline">\(t\)</span>, <span class="math inline">\(VR(t)\)</span> es el valor de <span class="math inline">\(u\)</span> para el cual <span class="math inline">\(TR(u)=t\)</span>, es decir que <span class="math inline">\(TR(VR(t))=t\)</span> (y también <span class="math inline">\(VR(TR(u))=u\)</span>), es decir que TR y VR se pueden considerar funciones inversas una de la otra.</p>
<p>En suma:</p>
<ul>
<li>El tiempo de retorno (TR) permite cuantificar cuán raro o extremo es un evento. Por ejemplo, si se espera exceder un cierto nivel del río una vez cada 100 años, decimos que el tiempo de retorno <span class="math inline">\(T=100\)</span>.</li>
<li>El TR se basa en la probabilidad de excedencia <span class="math inline">\(p\)</span>, es decir, la probabilidad de que un evento supere cierto umbral <span class="math inline">\(z\)</span> en un año <span class="math inline">\(T=1/p\)</span> entonces <span class="math inline">\(p=1/T\)</span>.</li>
<li>Para un nivel <span class="math inline">\(z_p\)</span> su valor de retorno en <span class="math inline">\(T\)</span> años es tal que <span class="math inline">\(P(X&gt;z_p)=1/T\)</span>.</li>
<li>La forma de la curva de valores de retorno <span class="math inline">\(z_p\)</span> vs el tiempo <span class="math inline">\(T\)</span>, o su equivalente <span class="math inline">\(y_p=-\log(1-p)\)</span> nos indica cómo crecen los valores extremos con el tiempo TR.</li>
</ul>
<p>En la siguiente tabla se detalla la evolución del valor de retorno <span class="math inline">\(z_T\)</span> a largo plazo según cada una de las distribuciones extremales ya conocidas.</p>
<!--

| Tipo de GEV | $\xi$     | Forma               | Implicación sobre el valor de retorno $z_T$ a largo plazo                       |
| ----------- | --------- | ------------------- | ------------------------------------------------------------------------------- |
| **Gumbel**  | 0         | lineal en $\log T$  | Crece lentamente                                                                |
| **Weibull** | $\xi < 0$ | se aplana (convexa) | Tiene un **máximo**: no importa cuánto esperes, no pasa de ahí                  |
| **Fréchet** | $\xi > 0$ | cóncava             | Crece **sin límite**: cuanto mayor el $T$, **más extremo** es el valor esperado |



Table: Características de los tres tipos de la distribución GEV

| Tipo de GEV   | $\xi$     | Forma               | Implicación sobre el valor de retorno $z_T$ a largo plazo                       |
| ------------- | --------- | ------------------- | ------------------------------------------------------------------------------- |
| **Weibull**   | $\xi < 0$ | se aplana (convexa) | Tiene un **máximo**: no importa cuánto esperes, no pasa de ahí                  |
| **Gumbel**    | 0         | lineal en $\log T$  | Crece lentamente                                                                |
| **Fréchet**   | $\xi > 0$ | cóncava             | Crece **sin límite**: cuanto mayor el $T$, **más extremo** es el valor esperado |

-->
<div class="example">
<p><span id="exm:unlabeled-div-4" class="example"><strong>Ejemplo 1.7  </strong></span>Para “bajar un poco a tierra” estos conceptos, vamos a calcularlos y compararlos cuando la variable <span class="math inline">\(X\)</span> es Gumbel y cuando es Fréchet (con los mismos valores de posición <span class="math inline">\(\mu\)</span> y escala <span class="math inline">\(\beta&gt;0\)</span>).</p>
</div>
<ul>
<li>Comencemos por la <strong>Gumbel</strong>: <span class="math inline">\(X\)</span> tiene distribución <span class="math inline">\(\Lambda^{( \mu,\beta)}\)</span> si <span class="math inline">\(X= \mu+\beta Y\)</span>, donde <span class="math inline">\(Y\)</span> tiene distribución <span class="math inline">\(\Lambda\)</span>.</li>
</ul>
<p>Dado entonces un valor <span class="math inline">\(u&gt;0\)</span>, otro valor <span class="math inline">\(t&gt;0\)</span> resulta que</p>
<div class="definition">
<p><span id="def:defg" class="definition"><strong>Definición 1.6  (Ecuaciones G) </strong></span><span class="math display">\[\begin{align}
&amp;P(X&gt;u)=1-\exp\left\{ -\exp\left\{ -\frac{(u-\mu)}{\beta} \right\} \right\} \\
&amp;TR(u)=1/P(X&gt;u)\\
&amp;VR(t)= \mu+\beta \log\left\{ \frac{t}{t-1} \right\}
\end{align}\]</span></p>
</div>
<p>Cabe observar que si se supone que las observaciones son diarias (o enteras en la unidad que corresponda), los tiempos de retorno (TR) se redondean a enteros y los valores de <span class="math inline">\(t\)</span> en la última ecuación se toman enteros.</p>
<ul>
<li>Sigamos ahora por la Fréchet, recordemos que <span class="math inline">\(X\)</span> tiene distribución <span class="math inline">\(\Phi_{\alpha}^{\mu,\beta}\)</span> si <span class="math inline">\(x=\mu+\beta Y\)</span>, donde <span class="math inline">\(Y\)</span> tiene distribución <span class="math inline">\(\Phi_{\alpha}\)</span>.</li>
</ul>
<div style="page-break-after: always;"></div>
<p>Dado entonces un valor <span class="math inline">\(u&gt;0\)</span>, otro valor <span class="math inline">\(t\)</span> entero, resulta que</p>
<div class="definition">
<p><span id="def:deff" class="definition"><strong>Definición 1.7  (Ecuaciones F) </strong></span><span class="math display">\[\begin{align}
&amp;P(X&gt;u)= 1-\exp\left\{ -\left\{ \frac{\left( u-\mu \right)}{\beta} \right\}^{-\alpha} \right\} \\
&amp; TR(u)=1/P(X&gt;u)\\
&amp;VR(t)= \mu+\beta \left\{ \log\left\{\frac{t}{t-1} \right\} \right\}^{-1/\alpha}
\end{align}\]</span></p>
</div>
<p>Se realizan las siguientes simulaciones empleando en ambos casos <span class="math inline">\(\mu=15\)</span>, <span class="math inline">\(\beta=10\)</span> y <span class="math inline">\(\alpha= 2.5\)</span> (<span class="math inline">\(\xi =0.4\)</span>, no muy distante del <span class="math inline">\(\xi=0\)</span> de la Gumbel).</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" tabindex="-1"></a><span class="co"># Parámetros comunes</span></span>
<span id="cb48-2"><a href="#cb48-2" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="dv">15</span></span>
<span id="cb48-3"><a href="#cb48-3" tabindex="-1"></a>beta <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb48-4"><a href="#cb48-4" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">2.5</span></span>
<span id="cb48-5"><a href="#cb48-5" tabindex="-1"></a></span>
<span id="cb48-6"><a href="#cb48-6" tabindex="-1"></a><span class="co"># Secuencia de valores u (nivel) y t (retorno)</span></span>
<span id="cb48-7"><a href="#cb48-7" tabindex="-1"></a>u_vals <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">15</span>, <span class="dv">250</span>, <span class="at">by =</span> <span class="dv">5</span>)</span>
<span id="cb48-8"><a href="#cb48-8" tabindex="-1"></a>t_vals <span class="ot">&lt;-</span> <span class="dv">90</span><span class="sc">:</span><span class="dv">4140</span></span>
<span id="cb48-9"><a href="#cb48-9" tabindex="-1"></a></span>
<span id="cb48-10"><a href="#cb48-10" tabindex="-1"></a><span class="co"># Funciones para la Gumbel</span></span>
<span id="cb48-11"><a href="#cb48-11" tabindex="-1"></a>P_exceed_gumbel <span class="ot">&lt;-</span> <span class="cf">function</span>(u, mu, beta) {</span>
<span id="cb48-12"><a href="#cb48-12" tabindex="-1"></a>  <span class="dv">1</span> <span class="sc">-</span> <span class="fu">exp</span>(<span class="sc">-</span><span class="fu">exp</span>(<span class="sc">-</span>(u <span class="sc">-</span> mu) <span class="sc">/</span> beta))</span>
<span id="cb48-13"><a href="#cb48-13" tabindex="-1"></a>}</span>
<span id="cb48-14"><a href="#cb48-14" tabindex="-1"></a></span>
<span id="cb48-15"><a href="#cb48-15" tabindex="-1"></a>TR_gumbel <span class="ot">&lt;-</span> <span class="cf">function</span>(u, mu, beta) {</span>
<span id="cb48-16"><a href="#cb48-16" tabindex="-1"></a>  <span class="dv">1</span> <span class="sc">/</span> <span class="fu">P_exceed_gumbel</span>(u, mu, beta)</span>
<span id="cb48-17"><a href="#cb48-17" tabindex="-1"></a>}</span>
<span id="cb48-18"><a href="#cb48-18" tabindex="-1"></a></span>
<span id="cb48-19"><a href="#cb48-19" tabindex="-1"></a>VR_gumbel <span class="ot">&lt;-</span> <span class="cf">function</span>(t, mu, beta) {</span>
<span id="cb48-20"><a href="#cb48-20" tabindex="-1"></a>  mu <span class="sc">+</span> beta <span class="sc">*</span> <span class="fu">log</span>(t <span class="sc">/</span> (t <span class="sc">-</span> <span class="dv">1</span>))</span>
<span id="cb48-21"><a href="#cb48-21" tabindex="-1"></a>}</span>
<span id="cb48-22"><a href="#cb48-22" tabindex="-1"></a></span>
<span id="cb48-23"><a href="#cb48-23" tabindex="-1"></a><span class="co"># Funciones para la Fréchet</span></span>
<span id="cb48-24"><a href="#cb48-24" tabindex="-1"></a>P_exceed_frechet <span class="ot">&lt;-</span> <span class="cf">function</span>(u, mu, beta, alpha) {</span>
<span id="cb48-25"><a href="#cb48-25" tabindex="-1"></a>  <span class="dv">1</span> <span class="sc">-</span> <span class="fu">exp</span>(<span class="sc">-</span>((u <span class="sc">-</span> mu) <span class="sc">/</span> beta)<span class="sc">^</span>(<span class="sc">-</span>alpha))</span>
<span id="cb48-26"><a href="#cb48-26" tabindex="-1"></a>}</span>
<span id="cb48-27"><a href="#cb48-27" tabindex="-1"></a></span>
<span id="cb48-28"><a href="#cb48-28" tabindex="-1"></a>TR_frechet <span class="ot">&lt;-</span> <span class="cf">function</span>(u, mu, beta, alpha) {</span>
<span id="cb48-29"><a href="#cb48-29" tabindex="-1"></a>  <span class="dv">1</span> <span class="sc">/</span> <span class="fu">P_exceed_frechet</span>(u, mu, beta, alpha)</span>
<span id="cb48-30"><a href="#cb48-30" tabindex="-1"></a>}</span>
<span id="cb48-31"><a href="#cb48-31" tabindex="-1"></a></span>
<span id="cb48-32"><a href="#cb48-32" tabindex="-1"></a>VR_frechet <span class="ot">&lt;-</span> <span class="cf">function</span>(t, mu, beta, alpha) {</span>
<span id="cb48-33"><a href="#cb48-33" tabindex="-1"></a>  mu <span class="sc">+</span> beta <span class="sc">*</span> (<span class="fu">log</span>(t <span class="sc">/</span> (t <span class="sc">-</span> <span class="dv">1</span>)))<span class="sc">^</span>(<span class="sc">-</span><span class="dv">1</span> <span class="sc">/</span> alpha)</span>
<span id="cb48-34"><a href="#cb48-34" tabindex="-1"></a>}</span>
<span id="cb48-35"><a href="#cb48-35" tabindex="-1"></a></span>
<span id="cb48-36"><a href="#cb48-36" tabindex="-1"></a><span class="co"># Cálculos</span></span>
<span id="cb48-37"><a href="#cb48-37" tabindex="-1"></a>tr_gumbel_vals <span class="ot">&lt;-</span> <span class="fu">TR_gumbel</span>(u_vals, mu, beta)</span>
<span id="cb48-38"><a href="#cb48-38" tabindex="-1"></a>tr_frechet_vals <span class="ot">&lt;-</span> <span class="fu">TR_frechet</span>(u_vals, mu, beta, alpha)</span>
<span id="cb48-39"><a href="#cb48-39" tabindex="-1"></a></span>
<span id="cb48-40"><a href="#cb48-40" tabindex="-1"></a>vr_gumbel_vals <span class="ot">&lt;-</span> <span class="fu">VR_gumbel</span>(t_vals, mu, beta)</span>
<span id="cb48-41"><a href="#cb48-41" tabindex="-1"></a>vr_frechet_vals <span class="ot">&lt;-</span> <span class="fu">VR_frechet</span>(t_vals, mu, beta, alpha)</span></code></pre></div>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" tabindex="-1"></a><span class="co"># Cálculo de probabilidades de excedencia</span></span>
<span id="cb49-2"><a href="#cb49-2" tabindex="-1"></a>p_gumbel <span class="ot">&lt;-</span> <span class="fu">P_exceed_gumbel</span>(u_vals, mu, beta)</span>
<span id="cb49-3"><a href="#cb49-3" tabindex="-1"></a>p_frechet <span class="ot">&lt;-</span> <span class="fu">P_exceed_frechet</span>(u_vals, mu, beta, alpha)</span></code></pre></div>
<p>Se pueden visualizar claramente los resultados en la Fig.<a href="#fig:trioplot">1.12</a>:</p>
<ul>
<li><p>De la Fig. <a href="#fig:trioplot">1.12</a> (a) se desprende que el modelo Fréchet da probabilidades mucho mayores a valores muy elevados: es más pesimista, si los
valores mayores representan mayores esfuerzos o problemas .</p></li>
<li><p>En cuanto a los TR de la Fig. <a href="#fig:trioplot">1.12</a> (b): Es claro que, siguiendo la lógica anterior, va a ser más pesimista_el modelo que de tiempos de retorno menores en valores elevados. Y eso es lo que ocurre con el modelo Fréchet.</p></li>
<li><p>En cuanto a los VR de la Fig. <a href="#fig:trioplot">1.12</a> (b): será más pesimista quien dé mayores VR. Resulta evidente el mayor pesimismo del modelo Fréchet.</p></li>
</ul>
<div style="page-break-after: always;"></div>
<div class="figure"><span style="display:block;" id="fig:trioplot"></span>
<img src="01-asint_files/figure-html/trioplot-1.png" alt="Excedencias, tiempos y valores de retorno" width="1536" />
<p class="caption">
Figura 1.12: Excedencias, tiempos y valores de retorno
</p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-5" class="example"><strong>Ejemplo 1.8  (Valores y tiempos de retorno) </strong></span>Con los datos del Ej. <a href="#exm:mv">1.6</a>, vamos ahora a calcular los valores de retorno (VR) y los tiempos de retorno (TR).</p>
</div>
<p>Para calcular los valores de retorno, primero definimos un vector con los periodos de retorno (en años) para los que queremos estimar dichos niveles. Por ejemplo: 2, 5, 10, 15, 25, 50, 100, 150 y 200 años.</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" tabindex="-1"></a><span class="co"># Años para los que vamos a calcular los valores de retorno</span></span>
<span id="cb50-2"><a href="#cb50-2" tabindex="-1"></a>tpo <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">15</span>, <span class="dv">25</span>, <span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">150</span>, <span class="dv">200</span>)</span></code></pre></div>
<p>A partir de estos valores, calculamos las probabilidades asociadas:</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" tabindex="-1"></a><span class="co"># Probabilidades asociadas a los periodos de retorno</span></span>
<span id="cb51-2"><a href="#cb51-2" tabindex="-1"></a>prob <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">/</span> tpo</span></code></pre></div>
<p>Utilizamos los parámetros estimados para la distribución de Gumbel ajustada:</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" tabindex="-1"></a><span class="co"># Parámetros del ajuste Gumbel: loc, scale</span></span>
<span id="cb52-2"><a href="#cb52-2" tabindex="-1"></a>z <span class="ot">&lt;-</span> fit_gumbel<span class="sc">$</span>estimate</span></code></pre></div>
<p>Y finalmente, calculamos los valores de retorno mediante la función cuantílica <code>qgumbel</code>:</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" tabindex="-1"></a><span class="co"># Cálculo directo usando lower.tail = FALSE</span></span>
<span id="cb53-2"><a href="#cb53-2" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">qgumbel</span>(prob, z[<span class="dv">1</span>], z[<span class="dv">2</span>], <span class="at">lower.tail =</span> <span class="cn">FALSE</span>), <span class="dv">1</span>)</span></code></pre></div>
<pre><code>## [1] 33.3 44.8 52.4 56.7 62.0 69.2 76.3 80.4 83.3</code></pre>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" tabindex="-1"></a><span class="co"># Alternativamente, usando 1 - prob</span></span>
<span id="cb55-2"><a href="#cb55-2" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">qgumbel</span>(<span class="dv">1</span> <span class="sc">-</span> prob, z[<span class="dv">1</span>], z[<span class="dv">2</span>]), <span class="dv">1</span>)</span></code></pre></div>
<pre><code>## [1] 33.3 44.8 52.4 56.7 62.0 69.2 76.3 80.4 83.3</code></pre>
<p>Obtenemos así los valores máximos diarios esperados para cada uno de los periodos de retorno definidos.</p>
<p>Queremos ahora calcular el TR para una precipitación máxima concreta:</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" tabindex="-1"></a><span class="co"># Calcular el valor máximo observado</span></span>
<span id="cb57-2"><a href="#cb57-2" tabindex="-1"></a>maximo_obs <span class="ot">&lt;-</span> <span class="fu">max</span>(datos)</span>
<span id="cb57-3"><a href="#cb57-3" tabindex="-1"></a><span class="fu">round</span>(maximo_obs,<span class="dv">0</span>)</span></code></pre></div>
<pre><code>## [1] 72</code></pre>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" tabindex="-1"></a><span class="co"># Extraer parámetros estimados del ajuste Gumbel</span></span>
<span id="cb59-2"><a href="#cb59-2" tabindex="-1"></a>z <span class="ot">&lt;-</span> fit_gumbel<span class="sc">$</span>estimate  <span class="co"># z[1] = loc, z[2] = scale</span></span>
<span id="cb59-3"><a href="#cb59-3" tabindex="-1"></a></span>
<span id="cb59-4"><a href="#cb59-4" tabindex="-1"></a><span class="co"># Calcular el periodo de retorno correspondiente a ese valor máximo</span></span>
<span id="cb59-5"><a href="#cb59-5" tabindex="-1"></a>periodo_retorno <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">-</span> <span class="fu">pgumbel</span>(maximo_obs, z[<span class="dv">1</span>], z[<span class="dv">2</span>]))</span>
<span id="cb59-6"><a href="#cb59-6" tabindex="-1"></a></span>
<span id="cb59-7"><a href="#cb59-7" tabindex="-1"></a><span class="co"># Mostrar el resultado redondeado</span></span>
<span id="cb59-8"><a href="#cb59-8" tabindex="-1"></a><span class="fu">round</span>(periodo_retorno, <span class="dv">0</span>)</span></code></pre></div>
<pre><code>## loc 
##  68</code></pre>
<p>O sea que, podríamos esperar una precipitación máxima diaria de 72 mm, por término medio, cada 68 años.</p>
<!--

Ahora, salvando las ligeras diferencias fruto de que $t$ es discreto y hay redondeos, se tiene que:

- $TR(VR(t))\approx t$ para cada modelo,

- $VR(TR(u))\approx u$ para cada modelo.

Ejemplo para Gumbel

Tomamos \( t = 90 \) y calculamos $VR(90) = 15 + 10 \cdot \log\left( \frac{90}{89} \right) \approx 15.11$


Luego aplicamos la función de tiempo de retorno

\[
TR(15.11) = \frac{1}{1 - \exp\left( -\exp\left( -\frac{15.11 - 15}{10} \right) \right)} \approx 90
\]

Por tanto, $TR(VR(90)) \approx 90$.





``` r
# Tabla de valores de retorno (primeros 5 días)
tabla_vr <- data.frame(
  t = t_vals,  # ← nombre correcto aquí
  Gumbel = vr_gumbel_vals,
  Fréchet = vr_frechet_vals
)

# Mostrar con kable
knitr::kable(tabla_vr, digits = 1, caption = "VR para Gumbel y Fréchet")
```



Table: (\#tab:tablaVR)VR para Gumbel y Fréchet

|    t| Gumbel| Fréchet|
|----:|------:|-------:|
|   90|   15.1|    75.4|
|   91|   15.1|    75.6|
|   92|   15.1|    75.9|
|   93|   15.1|    76.2|
|   94|   15.1|    76.4|
|   95|   15.1|    76.7|
|   96|   15.1|    76.9|
|   97|   15.1|    77.2|
|   98|   15.1|    77.5|
|   99|   15.1|    77.7|
|  100|   15.1|    78.0|
|  101|   15.1|    78.2|
|  102|   15.1|    78.5|
|  103|   15.1|    78.7|
|  104|   15.1|    79.0|
|  105|   15.1|    79.2|
|  106|   15.1|    79.5|
|  107|   15.1|    79.7|
|  108|   15.1|    79.9|
|  109|   15.1|    80.2|
|  110|   15.1|    80.4|
|  111|   15.1|    80.7|
|  112|   15.1|    80.9|
|  113|   15.1|    81.1|
|  114|   15.1|    81.4|
|  115|   15.1|    81.6|
|  116|   15.1|    81.8|
|  117|   15.1|    82.1|
|  118|   15.1|    82.3|
|  119|   15.1|    82.5|
|  120|   15.1|    82.8|
|  121|   15.1|    83.0|
|  122|   15.1|    83.2|
|  123|   15.1|    83.4|
|  124|   15.1|    83.7|
|  125|   15.1|    83.9|
|  126|   15.1|    84.1|
|  127|   15.1|    84.3|
|  128|   15.1|    84.5|
|  129|   15.1|    84.8|
|  130|   15.1|    85.0|
|  131|   15.1|    85.2|
|  132|   15.1|    85.4|
|  133|   15.1|    85.6|
|  134|   15.1|    85.8|
|  135|   15.1|    86.0|
|  136|   15.1|    86.2|
|  137|   15.1|    86.5|
|  138|   15.1|    86.7|
|  139|   15.1|    86.9|
|  140|   15.1|    87.1|
|  141|   15.1|    87.3|
|  142|   15.1|    87.5|
|  143|   15.1|    87.7|
|  144|   15.1|    87.9|
|  145|   15.1|    88.1|
|  146|   15.1|    88.3|
|  147|   15.1|    88.5|
|  148|   15.1|    88.7|
|  149|   15.1|    88.9|
|  150|   15.1|    89.1|
|  151|   15.1|    89.3|
|  152|   15.1|    89.5|
|  153|   15.1|    89.7|
|  154|   15.1|    89.9|
|  155|   15.1|    90.1|
|  156|   15.1|    90.3|
|  157|   15.1|    90.5|
|  158|   15.1|    90.7|
|  159|   15.1|    90.9|
|  160|   15.1|    91.1|
|  161|   15.1|    91.2|
|  162|   15.1|    91.4|
|  163|   15.1|    91.6|
|  164|   15.1|    91.8|
|  165|   15.1|    92.0|
|  166|   15.1|    92.2|
|  167|   15.1|    92.4|
|  168|   15.1|    92.6|
|  169|   15.1|    92.7|
|  170|   15.1|    92.9|
|  171|   15.1|    93.1|
|  172|   15.1|    93.3|
|  173|   15.1|    93.5|
|  174|   15.1|    93.7|
|  175|   15.1|    93.8|
|  176|   15.1|    94.0|
|  177|   15.1|    94.2|
|  178|   15.1|    94.4|
|  179|   15.1|    94.6|
|  180|   15.1|    94.7|
|  181|   15.1|    94.9|
|  182|   15.1|    95.1|
|  183|   15.1|    95.3|
|  184|   15.1|    95.4|
|  185|   15.1|    95.6|
|  186|   15.1|    95.8|
|  187|   15.1|    96.0|
|  188|   15.1|    96.1|
|  189|   15.1|    96.3|
|  190|   15.1|    96.5|
|  191|   15.1|    96.7|
|  192|   15.1|    96.8|
|  193|   15.1|    97.0|
|  194|   15.1|    97.2|
|  195|   15.1|    97.3|
|  196|   15.1|    97.5|
|  197|   15.1|    97.7|
|  198|   15.1|    97.8|
|  199|   15.1|    98.0|
|  200|   15.1|    98.2|
|  201|   15.0|    98.3|
|  202|   15.0|    98.5|
|  203|   15.0|    98.7|
|  204|   15.0|    98.8|
|  205|   15.0|    99.0|
|  206|   15.0|    99.2|
|  207|   15.0|    99.3|
|  208|   15.0|    99.5|
|  209|   15.0|    99.7|
|  210|   15.0|    99.8|
|  211|   15.0|   100.0|
|  212|   15.0|   100.1|
|  213|   15.0|   100.3|
|  214|   15.0|   100.5|
|  215|   15.0|   100.6|
|  216|   15.0|   100.8|
|  217|   15.0|   100.9|
|  218|   15.0|   101.1|
|  219|   15.0|   101.3|
|  220|   15.0|   101.4|
|  221|   15.0|   101.6|
|  222|   15.0|   101.7|
|  223|   15.0|   101.9|
|  224|   15.0|   102.0|
|  225|   15.0|   102.2|
|  226|   15.0|   102.3|
|  227|   15.0|   102.5|
|  228|   15.0|   102.7|
|  229|   15.0|   102.8|
|  230|   15.0|   103.0|
|  231|   15.0|   103.1|
|  232|   15.0|   103.3|
|  233|   15.0|   103.4|
|  234|   15.0|   103.6|
|  235|   15.0|   103.7|
|  236|   15.0|   103.9|
|  237|   15.0|   104.0|
|  238|   15.0|   104.2|
|  239|   15.0|   104.3|
|  240|   15.0|   104.5|
|  241|   15.0|   104.6|
|  242|   15.0|   104.8|
|  243|   15.0|   104.9|
|  244|   15.0|   105.1|
|  245|   15.0|   105.2|
|  246|   15.0|   105.4|
|  247|   15.0|   105.5|
|  248|   15.0|   105.7|
|  249|   15.0|   105.8|
|  250|   15.0|   106.0|
|  251|   15.0|   106.1|
|  252|   15.0|   106.2|
|  253|   15.0|   106.4|
|  254|   15.0|   106.5|
|  255|   15.0|   106.7|
|  256|   15.0|   106.8|
|  257|   15.0|   107.0|
|  258|   15.0|   107.1|
|  259|   15.0|   107.3|
|  260|   15.0|   107.4|
|  261|   15.0|   107.5|
|  262|   15.0|   107.7|
|  263|   15.0|   107.8|
|  264|   15.0|   108.0|
|  265|   15.0|   108.1|
|  266|   15.0|   108.2|
|  267|   15.0|   108.4|
|  268|   15.0|   108.5|
|  269|   15.0|   108.7|
|  270|   15.0|   108.8|
|  271|   15.0|   108.9|
|  272|   15.0|   109.1|
|  273|   15.0|   109.2|
|  274|   15.0|   109.4|
|  275|   15.0|   109.5|
|  276|   15.0|   109.6|
|  277|   15.0|   109.8|
|  278|   15.0|   109.9|
|  279|   15.0|   110.0|
|  280|   15.0|   110.2|
|  281|   15.0|   110.3|
|  282|   15.0|   110.5|
|  283|   15.0|   110.6|
|  284|   15.0|   110.7|
|  285|   15.0|   110.9|
|  286|   15.0|   111.0|
|  287|   15.0|   111.1|
|  288|   15.0|   111.3|
|  289|   15.0|   111.4|
|  290|   15.0|   111.5|
|  291|   15.0|   111.7|
|  292|   15.0|   111.8|
|  293|   15.0|   111.9|
|  294|   15.0|   112.1|
|  295|   15.0|   112.2|
|  296|   15.0|   112.3|
|  297|   15.0|   112.5|
|  298|   15.0|   112.6|
|  299|   15.0|   112.7|
|  300|   15.0|   112.8|
|  301|   15.0|   113.0|
|  302|   15.0|   113.1|
|  303|   15.0|   113.2|
|  304|   15.0|   113.4|
|  305|   15.0|   113.5|
|  306|   15.0|   113.6|
|  307|   15.0|   113.8|
|  308|   15.0|   113.9|
|  309|   15.0|   114.0|
|  310|   15.0|   114.1|
|  311|   15.0|   114.3|
|  312|   15.0|   114.4|
|  313|   15.0|   114.5|
|  314|   15.0|   114.7|
|  315|   15.0|   114.8|
|  316|   15.0|   114.9|
|  317|   15.0|   115.0|
|  318|   15.0|   115.2|
|  319|   15.0|   115.3|
|  320|   15.0|   115.4|
|  321|   15.0|   115.5|
|  322|   15.0|   115.7|
|  323|   15.0|   115.8|
|  324|   15.0|   115.9|
|  325|   15.0|   116.0|
|  326|   15.0|   116.2|
|  327|   15.0|   116.3|
|  328|   15.0|   116.4|
|  329|   15.0|   116.5|
|  330|   15.0|   116.7|
|  331|   15.0|   116.8|
|  332|   15.0|   116.9|
|  333|   15.0|   117.0|
|  334|   15.0|   117.1|
|  335|   15.0|   117.3|
|  336|   15.0|   117.4|
|  337|   15.0|   117.5|
|  338|   15.0|   117.6|
|  339|   15.0|   117.8|
|  340|   15.0|   117.9|
|  341|   15.0|   118.0|
|  342|   15.0|   118.1|
|  343|   15.0|   118.2|
|  344|   15.0|   118.4|
|  345|   15.0|   118.5|
|  346|   15.0|   118.6|
|  347|   15.0|   118.7|
|  348|   15.0|   118.8|
|  349|   15.0|   119.0|
|  350|   15.0|   119.1|
|  351|   15.0|   119.2|
|  352|   15.0|   119.3|
|  353|   15.0|   119.4|
|  354|   15.0|   119.6|
|  355|   15.0|   119.7|
|  356|   15.0|   119.8|
|  357|   15.0|   119.9|
|  358|   15.0|   120.0|
|  359|   15.0|   120.1|
|  360|   15.0|   120.3|
|  361|   15.0|   120.4|
|  362|   15.0|   120.5|
|  363|   15.0|   120.6|
|  364|   15.0|   120.7|
|  365|   15.0|   120.8|
|  366|   15.0|   121.0|
|  367|   15.0|   121.1|
|  368|   15.0|   121.2|
|  369|   15.0|   121.3|
|  370|   15.0|   121.4|
|  371|   15.0|   121.5|
|  372|   15.0|   121.7|
|  373|   15.0|   121.8|
|  374|   15.0|   121.9|
|  375|   15.0|   122.0|
|  376|   15.0|   122.1|
|  377|   15.0|   122.2|
|  378|   15.0|   122.3|
|  379|   15.0|   122.5|
|  380|   15.0|   122.6|
|  381|   15.0|   122.7|
|  382|   15.0|   122.8|
|  383|   15.0|   122.9|
|  384|   15.0|   123.0|
|  385|   15.0|   123.1|
|  386|   15.0|   123.2|
|  387|   15.0|   123.4|
|  388|   15.0|   123.5|
|  389|   15.0|   123.6|
|  390|   15.0|   123.7|
|  391|   15.0|   123.8|
|  392|   15.0|   123.9|
|  393|   15.0|   124.0|
|  394|   15.0|   124.1|
|  395|   15.0|   124.2|
|  396|   15.0|   124.4|
|  397|   15.0|   124.5|
|  398|   15.0|   124.6|
|  399|   15.0|   124.7|
|  400|   15.0|   124.8|
|  401|   15.0|   124.9|
|  402|   15.0|   125.0|
|  403|   15.0|   125.1|
|  404|   15.0|   125.2|
|  405|   15.0|   125.3|
|  406|   15.0|   125.5|
|  407|   15.0|   125.6|
|  408|   15.0|   125.7|
|  409|   15.0|   125.8|
|  410|   15.0|   125.9|
|  411|   15.0|   126.0|
|  412|   15.0|   126.1|
|  413|   15.0|   126.2|
|  414|   15.0|   126.3|
|  415|   15.0|   126.4|
|  416|   15.0|   126.5|
|  417|   15.0|   126.6|
|  418|   15.0|   126.8|
|  419|   15.0|   126.9|
|  420|   15.0|   127.0|
|  421|   15.0|   127.1|
|  422|   15.0|   127.2|
|  423|   15.0|   127.3|
|  424|   15.0|   127.4|
|  425|   15.0|   127.5|
|  426|   15.0|   127.6|
|  427|   15.0|   127.7|
|  428|   15.0|   127.8|
|  429|   15.0|   127.9|
|  430|   15.0|   128.0|
|  431|   15.0|   128.1|
|  432|   15.0|   128.2|
|  433|   15.0|   128.3|
|  434|   15.0|   128.4|
|  435|   15.0|   128.6|
|  436|   15.0|   128.7|
|  437|   15.0|   128.8|
|  438|   15.0|   128.9|
|  439|   15.0|   129.0|
|  440|   15.0|   129.1|
|  441|   15.0|   129.2|
|  442|   15.0|   129.3|
|  443|   15.0|   129.4|
|  444|   15.0|   129.5|
|  445|   15.0|   129.6|
|  446|   15.0|   129.7|
|  447|   15.0|   129.8|
|  448|   15.0|   129.9|
|  449|   15.0|   130.0|
|  450|   15.0|   130.1|
|  451|   15.0|   130.2|
|  452|   15.0|   130.3|
|  453|   15.0|   130.4|
|  454|   15.0|   130.5|
|  455|   15.0|   130.6|
|  456|   15.0|   130.7|
|  457|   15.0|   130.8|
|  458|   15.0|   130.9|
|  459|   15.0|   131.0|
|  460|   15.0|   131.1|
|  461|   15.0|   131.2|
|  462|   15.0|   131.3|
|  463|   15.0|   131.4|
|  464|   15.0|   131.5|
|  465|   15.0|   131.6|
|  466|   15.0|   131.7|
|  467|   15.0|   131.8|
|  468|   15.0|   131.9|
|  469|   15.0|   132.0|
|  470|   15.0|   132.1|
|  471|   15.0|   132.2|
|  472|   15.0|   132.3|
|  473|   15.0|   132.4|
|  474|   15.0|   132.5|
|  475|   15.0|   132.6|
|  476|   15.0|   132.7|
|  477|   15.0|   132.8|
|  478|   15.0|   132.9|
|  479|   15.0|   133.0|
|  480|   15.0|   133.1|
|  481|   15.0|   133.2|
|  482|   15.0|   133.3|
|  483|   15.0|   133.4|
|  484|   15.0|   133.5|
|  485|   15.0|   133.6|
|  486|   15.0|   133.7|
|  487|   15.0|   133.8|
|  488|   15.0|   133.9|
|  489|   15.0|   134.0|
|  490|   15.0|   134.1|
|  491|   15.0|   134.2|
|  492|   15.0|   134.3|
|  493|   15.0|   134.4|
|  494|   15.0|   134.5|
|  495|   15.0|   134.6|
|  496|   15.0|   134.7|
|  497|   15.0|   134.8|
|  498|   15.0|   134.9|
|  499|   15.0|   135.0|
|  500|   15.0|   135.1|
|  501|   15.0|   135.2|
|  502|   15.0|   135.3|
|  503|   15.0|   135.4|
|  504|   15.0|   135.4|
|  505|   15.0|   135.5|
|  506|   15.0|   135.6|
|  507|   15.0|   135.7|
|  508|   15.0|   135.8|
|  509|   15.0|   135.9|
|  510|   15.0|   136.0|
|  511|   15.0|   136.1|
|  512|   15.0|   136.2|
|  513|   15.0|   136.3|
|  514|   15.0|   136.4|
|  515|   15.0|   136.5|
|  516|   15.0|   136.6|
|  517|   15.0|   136.7|
|  518|   15.0|   136.8|
|  519|   15.0|   136.9|
|  520|   15.0|   137.0|
|  521|   15.0|   137.1|
|  522|   15.0|   137.2|
|  523|   15.0|   137.2|
|  524|   15.0|   137.3|
|  525|   15.0|   137.4|
|  526|   15.0|   137.5|
|  527|   15.0|   137.6|
|  528|   15.0|   137.7|
|  529|   15.0|   137.8|
|  530|   15.0|   137.9|
|  531|   15.0|   138.0|
|  532|   15.0|   138.1|
|  533|   15.0|   138.2|
|  534|   15.0|   138.3|
|  535|   15.0|   138.4|
|  536|   15.0|   138.5|
|  537|   15.0|   138.5|
|  538|   15.0|   138.6|
|  539|   15.0|   138.7|
|  540|   15.0|   138.8|
|  541|   15.0|   138.9|
|  542|   15.0|   139.0|
|  543|   15.0|   139.1|
|  544|   15.0|   139.2|
|  545|   15.0|   139.3|
|  546|   15.0|   139.4|
|  547|   15.0|   139.5|
|  548|   15.0|   139.6|
|  549|   15.0|   139.6|
|  550|   15.0|   139.7|
|  551|   15.0|   139.8|
|  552|   15.0|   139.9|
|  553|   15.0|   140.0|
|  554|   15.0|   140.1|
|  555|   15.0|   140.2|
|  556|   15.0|   140.3|
|  557|   15.0|   140.4|
|  558|   15.0|   140.5|
|  559|   15.0|   140.5|
|  560|   15.0|   140.6|
|  561|   15.0|   140.7|
|  562|   15.0|   140.8|
|  563|   15.0|   140.9|
|  564|   15.0|   141.0|
|  565|   15.0|   141.1|
|  566|   15.0|   141.2|
|  567|   15.0|   141.3|
|  568|   15.0|   141.4|
|  569|   15.0|   141.4|
|  570|   15.0|   141.5|
|  571|   15.0|   141.6|
|  572|   15.0|   141.7|
|  573|   15.0|   141.8|
|  574|   15.0|   141.9|
|  575|   15.0|   142.0|
|  576|   15.0|   142.1|
|  577|   15.0|   142.2|
|  578|   15.0|   142.2|
|  579|   15.0|   142.3|
|  580|   15.0|   142.4|
|  581|   15.0|   142.5|
|  582|   15.0|   142.6|
|  583|   15.0|   142.7|
|  584|   15.0|   142.8|
|  585|   15.0|   142.9|
|  586|   15.0|   142.9|
|  587|   15.0|   143.0|
|  588|   15.0|   143.1|
|  589|   15.0|   143.2|
|  590|   15.0|   143.3|
|  591|   15.0|   143.4|
|  592|   15.0|   143.5|
|  593|   15.0|   143.6|
|  594|   15.0|   143.6|
|  595|   15.0|   143.7|
|  596|   15.0|   143.8|
|  597|   15.0|   143.9|
|  598|   15.0|   144.0|
|  599|   15.0|   144.1|
|  600|   15.0|   144.2|
|  601|   15.0|   144.2|
|  602|   15.0|   144.3|
|  603|   15.0|   144.4|
|  604|   15.0|   144.5|
|  605|   15.0|   144.6|
|  606|   15.0|   144.7|
|  607|   15.0|   144.8|
|  608|   15.0|   144.8|
|  609|   15.0|   144.9|
|  610|   15.0|   145.0|
|  611|   15.0|   145.1|
|  612|   15.0|   145.2|
|  613|   15.0|   145.3|
|  614|   15.0|   145.4|
|  615|   15.0|   145.4|
|  616|   15.0|   145.5|
|  617|   15.0|   145.6|
|  618|   15.0|   145.7|
|  619|   15.0|   145.8|
|  620|   15.0|   145.9|
|  621|   15.0|   145.9|
|  622|   15.0|   146.0|
|  623|   15.0|   146.1|
|  624|   15.0|   146.2|
|  625|   15.0|   146.3|
|  626|   15.0|   146.4|
|  627|   15.0|   146.5|
|  628|   15.0|   146.5|
|  629|   15.0|   146.6|
|  630|   15.0|   146.7|
|  631|   15.0|   146.8|
|  632|   15.0|   146.9|
|  633|   15.0|   147.0|
|  634|   15.0|   147.0|
|  635|   15.0|   147.1|
|  636|   15.0|   147.2|
|  637|   15.0|   147.3|
|  638|   15.0|   147.4|
|  639|   15.0|   147.5|
|  640|   15.0|   147.5|
|  641|   15.0|   147.6|
|  642|   15.0|   147.7|
|  643|   15.0|   147.8|
|  644|   15.0|   147.9|
|  645|   15.0|   148.0|
|  646|   15.0|   148.0|
|  647|   15.0|   148.1|
|  648|   15.0|   148.2|
|  649|   15.0|   148.3|
|  650|   15.0|   148.4|
|  651|   15.0|   148.4|
|  652|   15.0|   148.5|
|  653|   15.0|   148.6|
|  654|   15.0|   148.7|
|  655|   15.0|   148.8|
|  656|   15.0|   148.9|
|  657|   15.0|   148.9|
|  658|   15.0|   149.0|
|  659|   15.0|   149.1|
|  660|   15.0|   149.2|
|  661|   15.0|   149.3|
|  662|   15.0|   149.3|
|  663|   15.0|   149.4|
|  664|   15.0|   149.5|
|  665|   15.0|   149.6|
|  666|   15.0|   149.7|
|  667|   15.0|   149.7|
|  668|   15.0|   149.8|
|  669|   15.0|   149.9|
|  670|   15.0|   150.0|
|  671|   15.0|   150.1|
|  672|   15.0|   150.2|
|  673|   15.0|   150.2|
|  674|   15.0|   150.3|
|  675|   15.0|   150.4|
|  676|   15.0|   150.5|
|  677|   15.0|   150.6|
|  678|   15.0|   150.6|
|  679|   15.0|   150.7|
|  680|   15.0|   150.8|
|  681|   15.0|   150.9|
|  682|   15.0|   151.0|
|  683|   15.0|   151.0|
|  684|   15.0|   151.1|
|  685|   15.0|   151.2|
|  686|   15.0|   151.3|
|  687|   15.0|   151.4|
|  688|   15.0|   151.4|
|  689|   15.0|   151.5|
|  690|   15.0|   151.6|
|  691|   15.0|   151.7|
|  692|   15.0|   151.7|
|  693|   15.0|   151.8|
|  694|   15.0|   151.9|
|  695|   15.0|   152.0|
|  696|   15.0|   152.1|
|  697|   15.0|   152.1|
|  698|   15.0|   152.2|
|  699|   15.0|   152.3|
|  700|   15.0|   152.4|
|  701|   15.0|   152.5|
|  702|   15.0|   152.5|
|  703|   15.0|   152.6|
|  704|   15.0|   152.7|
|  705|   15.0|   152.8|
|  706|   15.0|   152.8|
|  707|   15.0|   152.9|
|  708|   15.0|   153.0|
|  709|   15.0|   153.1|
|  710|   15.0|   153.2|
|  711|   15.0|   153.2|
|  712|   15.0|   153.3|
|  713|   15.0|   153.4|
|  714|   15.0|   153.5|
|  715|   15.0|   153.5|
|  716|   15.0|   153.6|
|  717|   15.0|   153.7|
|  718|   15.0|   153.8|
|  719|   15.0|   153.9|
|  720|   15.0|   153.9|
|  721|   15.0|   154.0|
|  722|   15.0|   154.1|
|  723|   15.0|   154.2|
|  724|   15.0|   154.2|
|  725|   15.0|   154.3|
|  726|   15.0|   154.4|
|  727|   15.0|   154.5|
|  728|   15.0|   154.6|
|  729|   15.0|   154.6|
|  730|   15.0|   154.7|
|  731|   15.0|   154.8|
|  732|   15.0|   154.9|
|  733|   15.0|   154.9|
|  734|   15.0|   155.0|
|  735|   15.0|   155.1|
|  736|   15.0|   155.2|
|  737|   15.0|   155.2|
|  738|   15.0|   155.3|
|  739|   15.0|   155.4|
|  740|   15.0|   155.5|
|  741|   15.0|   155.5|
|  742|   15.0|   155.6|
|  743|   15.0|   155.7|
|  744|   15.0|   155.8|
|  745|   15.0|   155.8|
|  746|   15.0|   155.9|
|  747|   15.0|   156.0|
|  748|   15.0|   156.1|
|  749|   15.0|   156.1|
|  750|   15.0|   156.2|
|  751|   15.0|   156.3|
|  752|   15.0|   156.4|
|  753|   15.0|   156.4|
|  754|   15.0|   156.5|
|  755|   15.0|   156.6|
|  756|   15.0|   156.7|
|  757|   15.0|   156.8|
|  758|   15.0|   156.8|
|  759|   15.0|   156.9|
|  760|   15.0|   157.0|
|  761|   15.0|   157.0|
|  762|   15.0|   157.1|
|  763|   15.0|   157.2|
|  764|   15.0|   157.3|
|  765|   15.0|   157.3|
|  766|   15.0|   157.4|
|  767|   15.0|   157.5|
|  768|   15.0|   157.6|
|  769|   15.0|   157.6|
|  770|   15.0|   157.7|
|  771|   15.0|   157.8|
|  772|   15.0|   157.9|
|  773|   15.0|   157.9|
|  774|   15.0|   158.0|
|  775|   15.0|   158.1|
|  776|   15.0|   158.2|
|  777|   15.0|   158.2|
|  778|   15.0|   158.3|
|  779|   15.0|   158.4|
|  780|   15.0|   158.5|
|  781|   15.0|   158.5|
|  782|   15.0|   158.6|
|  783|   15.0|   158.7|
|  784|   15.0|   158.8|
|  785|   15.0|   158.8|
|  786|   15.0|   158.9|
|  787|   15.0|   159.0|
|  788|   15.0|   159.0|
|  789|   15.0|   159.1|
|  790|   15.0|   159.2|
|  791|   15.0|   159.3|
|  792|   15.0|   159.3|
|  793|   15.0|   159.4|
|  794|   15.0|   159.5|
|  795|   15.0|   159.6|
|  796|   15.0|   159.6|
|  797|   15.0|   159.7|
|  798|   15.0|   159.8|
|  799|   15.0|   159.8|
|  800|   15.0|   159.9|
|  801|   15.0|   160.0|
|  802|   15.0|   160.1|
|  803|   15.0|   160.1|
|  804|   15.0|   160.2|
|  805|   15.0|   160.3|
|  806|   15.0|   160.4|
|  807|   15.0|   160.4|
|  808|   15.0|   160.5|
|  809|   15.0|   160.6|
|  810|   15.0|   160.6|
|  811|   15.0|   160.7|
|  812|   15.0|   160.8|
|  813|   15.0|   160.9|
|  814|   15.0|   160.9|
|  815|   15.0|   161.0|
|  816|   15.0|   161.1|
|  817|   15.0|   161.1|
|  818|   15.0|   161.2|
|  819|   15.0|   161.3|
|  820|   15.0|   161.4|
|  821|   15.0|   161.4|
|  822|   15.0|   161.5|
|  823|   15.0|   161.6|
|  824|   15.0|   161.6|
|  825|   15.0|   161.7|
|  826|   15.0|   161.8|
|  827|   15.0|   161.9|
|  828|   15.0|   161.9|
|  829|   15.0|   162.0|
|  830|   15.0|   162.1|
|  831|   15.0|   162.1|
|  832|   15.0|   162.2|
|  833|   15.0|   162.3|
|  834|   15.0|   162.4|
|  835|   15.0|   162.4|
|  836|   15.0|   162.5|
|  837|   15.0|   162.6|
|  838|   15.0|   162.6|
|  839|   15.0|   162.7|
|  840|   15.0|   162.8|
|  841|   15.0|   162.8|
|  842|   15.0|   162.9|
|  843|   15.0|   163.0|
|  844|   15.0|   163.1|
|  845|   15.0|   163.1|
|  846|   15.0|   163.2|
|  847|   15.0|   163.3|
|  848|   15.0|   163.3|
|  849|   15.0|   163.4|
|  850|   15.0|   163.5|
|  851|   15.0|   163.5|
|  852|   15.0|   163.6|
|  853|   15.0|   163.7|
|  854|   15.0|   163.8|
|  855|   15.0|   163.8|
|  856|   15.0|   163.9|
|  857|   15.0|   164.0|
|  858|   15.0|   164.0|
|  859|   15.0|   164.1|
|  860|   15.0|   164.2|
|  861|   15.0|   164.2|
|  862|   15.0|   164.3|
|  863|   15.0|   164.4|
|  864|   15.0|   164.5|
|  865|   15.0|   164.5|
|  866|   15.0|   164.6|
|  867|   15.0|   164.7|
|  868|   15.0|   164.7|
|  869|   15.0|   164.8|
|  870|   15.0|   164.9|
|  871|   15.0|   164.9|
|  872|   15.0|   165.0|
|  873|   15.0|   165.1|
|  874|   15.0|   165.1|
|  875|   15.0|   165.2|
|  876|   15.0|   165.3|
|  877|   15.0|   165.3|
|  878|   15.0|   165.4|
|  879|   15.0|   165.5|
|  880|   15.0|   165.6|
|  881|   15.0|   165.6|
|  882|   15.0|   165.7|
|  883|   15.0|   165.8|
|  884|   15.0|   165.8|
|  885|   15.0|   165.9|
|  886|   15.0|   166.0|
|  887|   15.0|   166.0|
|  888|   15.0|   166.1|
|  889|   15.0|   166.2|
|  890|   15.0|   166.2|
|  891|   15.0|   166.3|
|  892|   15.0|   166.4|
|  893|   15.0|   166.4|
|  894|   15.0|   166.5|
|  895|   15.0|   166.6|
|  896|   15.0|   166.6|
|  897|   15.0|   166.7|
|  898|   15.0|   166.8|
|  899|   15.0|   166.8|
|  900|   15.0|   166.9|
|  901|   15.0|   167.0|
|  902|   15.0|   167.0|
|  903|   15.0|   167.1|
|  904|   15.0|   167.2|
|  905|   15.0|   167.3|
|  906|   15.0|   167.3|
|  907|   15.0|   167.4|
|  908|   15.0|   167.5|
|  909|   15.0|   167.5|
|  910|   15.0|   167.6|
|  911|   15.0|   167.7|
|  912|   15.0|   167.7|
|  913|   15.0|   167.8|
|  914|   15.0|   167.9|
|  915|   15.0|   167.9|
|  916|   15.0|   168.0|
|  917|   15.0|   168.1|
|  918|   15.0|   168.1|
|  919|   15.0|   168.2|
|  920|   15.0|   168.3|
|  921|   15.0|   168.3|
|  922|   15.0|   168.4|
|  923|   15.0|   168.5|
|  924|   15.0|   168.5|
|  925|   15.0|   168.6|
|  926|   15.0|   168.7|
|  927|   15.0|   168.7|
|  928|   15.0|   168.8|
|  929|   15.0|   168.9|
|  930|   15.0|   168.9|
|  931|   15.0|   169.0|
|  932|   15.0|   169.1|
|  933|   15.0|   169.1|
|  934|   15.0|   169.2|
|  935|   15.0|   169.3|
|  936|   15.0|   169.3|
|  937|   15.0|   169.4|
|  938|   15.0|   169.5|
|  939|   15.0|   169.5|
|  940|   15.0|   169.6|
|  941|   15.0|   169.6|
|  942|   15.0|   169.7|
|  943|   15.0|   169.8|
|  944|   15.0|   169.8|
|  945|   15.0|   169.9|
|  946|   15.0|   170.0|
|  947|   15.0|   170.0|
|  948|   15.0|   170.1|
|  949|   15.0|   170.2|
|  950|   15.0|   170.2|
|  951|   15.0|   170.3|
|  952|   15.0|   170.4|
|  953|   15.0|   170.4|
|  954|   15.0|   170.5|
|  955|   15.0|   170.6|
|  956|   15.0|   170.6|
|  957|   15.0|   170.7|
|  958|   15.0|   170.8|
|  959|   15.0|   170.8|
|  960|   15.0|   170.9|
|  961|   15.0|   171.0|
|  962|   15.0|   171.0|
|  963|   15.0|   171.1|
|  964|   15.0|   171.1|
|  965|   15.0|   171.2|
|  966|   15.0|   171.3|
|  967|   15.0|   171.3|
|  968|   15.0|   171.4|
|  969|   15.0|   171.5|
|  970|   15.0|   171.5|
|  971|   15.0|   171.6|
|  972|   15.0|   171.7|
|  973|   15.0|   171.7|
|  974|   15.0|   171.8|
|  975|   15.0|   171.9|
|  976|   15.0|   171.9|
|  977|   15.0|   172.0|
|  978|   15.0|   172.1|
|  979|   15.0|   172.1|
|  980|   15.0|   172.2|
|  981|   15.0|   172.2|
|  982|   15.0|   172.3|
|  983|   15.0|   172.4|
|  984|   15.0|   172.4|
|  985|   15.0|   172.5|
|  986|   15.0|   172.6|
|  987|   15.0|   172.6|
|  988|   15.0|   172.7|
|  989|   15.0|   172.8|
|  990|   15.0|   172.8|
|  991|   15.0|   172.9|
|  992|   15.0|   172.9|
|  993|   15.0|   173.0|
|  994|   15.0|   173.1|
|  995|   15.0|   173.1|
|  996|   15.0|   173.2|
|  997|   15.0|   173.3|
|  998|   15.0|   173.3|
|  999|   15.0|   173.4|
| 1000|   15.0|   173.5|
| 1001|   15.0|   173.5|
| 1002|   15.0|   173.6|
| 1003|   15.0|   173.6|
| 1004|   15.0|   173.7|
| 1005|   15.0|   173.8|
| 1006|   15.0|   173.8|
| 1007|   15.0|   173.9|
| 1008|   15.0|   174.0|
| 1009|   15.0|   174.0|
| 1010|   15.0|   174.1|
| 1011|   15.0|   174.2|
| 1012|   15.0|   174.2|
| 1013|   15.0|   174.3|
| 1014|   15.0|   174.3|
| 1015|   15.0|   174.4|
| 1016|   15.0|   174.5|
| 1017|   15.0|   174.5|
| 1018|   15.0|   174.6|
| 1019|   15.0|   174.7|
| 1020|   15.0|   174.7|
| 1021|   15.0|   174.8|
| 1022|   15.0|   174.8|
| 1023|   15.0|   174.9|
| 1024|   15.0|   175.0|
| 1025|   15.0|   175.0|
| 1026|   15.0|   175.1|
| 1027|   15.0|   175.2|
| 1028|   15.0|   175.2|
| 1029|   15.0|   175.3|
| 1030|   15.0|   175.3|
| 1031|   15.0|   175.4|
| 1032|   15.0|   175.5|
| 1033|   15.0|   175.5|
| 1034|   15.0|   175.6|
| 1035|   15.0|   175.7|
| 1036|   15.0|   175.7|
| 1037|   15.0|   175.8|
| 1038|   15.0|   175.8|
| 1039|   15.0|   175.9|
| 1040|   15.0|   176.0|
| 1041|   15.0|   176.0|
| 1042|   15.0|   176.1|
| 1043|   15.0|   176.2|
| 1044|   15.0|   176.2|
| 1045|   15.0|   176.3|
| 1046|   15.0|   176.3|
| 1047|   15.0|   176.4|
| 1048|   15.0|   176.5|
| 1049|   15.0|   176.5|
| 1050|   15.0|   176.6|
| 1051|   15.0|   176.6|
| 1052|   15.0|   176.7|
| 1053|   15.0|   176.8|
| 1054|   15.0|   176.8|
| 1055|   15.0|   176.9|
| 1056|   15.0|   177.0|
| 1057|   15.0|   177.0|
| 1058|   15.0|   177.1|
| 1059|   15.0|   177.1|
| 1060|   15.0|   177.2|
| 1061|   15.0|   177.3|
| 1062|   15.0|   177.3|
| 1063|   15.0|   177.4|
| 1064|   15.0|   177.4|
| 1065|   15.0|   177.5|
| 1066|   15.0|   177.6|
| 1067|   15.0|   177.6|
| 1068|   15.0|   177.7|
| 1069|   15.0|   177.7|
| 1070|   15.0|   177.8|
| 1071|   15.0|   177.9|
| 1072|   15.0|   177.9|
| 1073|   15.0|   178.0|
| 1074|   15.0|   178.1|
| 1075|   15.0|   178.1|
| 1076|   15.0|   178.2|
| 1077|   15.0|   178.2|
| 1078|   15.0|   178.3|
| 1079|   15.0|   178.4|
| 1080|   15.0|   178.4|
| 1081|   15.0|   178.5|
| 1082|   15.0|   178.5|
| 1083|   15.0|   178.6|
| 1084|   15.0|   178.7|
| 1085|   15.0|   178.7|
| 1086|   15.0|   178.8|
| 1087|   15.0|   178.8|
| 1088|   15.0|   178.9|
| 1089|   15.0|   179.0|
| 1090|   15.0|   179.0|
| 1091|   15.0|   179.1|
| 1092|   15.0|   179.1|
| 1093|   15.0|   179.2|
| 1094|   15.0|   179.3|
| 1095|   15.0|   179.3|
| 1096|   15.0|   179.4|
| 1097|   15.0|   179.4|
| 1098|   15.0|   179.5|
| 1099|   15.0|   179.6|
| 1100|   15.0|   179.6|
| 1101|   15.0|   179.7|
| 1102|   15.0|   179.7|
| 1103|   15.0|   179.8|
| 1104|   15.0|   179.9|
| 1105|   15.0|   179.9|
| 1106|   15.0|   180.0|
| 1107|   15.0|   180.0|
| 1108|   15.0|   180.1|
| 1109|   15.0|   180.2|
| 1110|   15.0|   180.2|
| 1111|   15.0|   180.3|
| 1112|   15.0|   180.3|
| 1113|   15.0|   180.4|
| 1114|   15.0|   180.5|
| 1115|   15.0|   180.5|
| 1116|   15.0|   180.6|
| 1117|   15.0|   180.6|
| 1118|   15.0|   180.7|
| 1119|   15.0|   180.8|
| 1120|   15.0|   180.8|
| 1121|   15.0|   180.9|
| 1122|   15.0|   180.9|
| 1123|   15.0|   181.0|
| 1124|   15.0|   181.0|
| 1125|   15.0|   181.1|
| 1126|   15.0|   181.2|
| 1127|   15.0|   181.2|
| 1128|   15.0|   181.3|
| 1129|   15.0|   181.3|
| 1130|   15.0|   181.4|
| 1131|   15.0|   181.5|
| 1132|   15.0|   181.5|
| 1133|   15.0|   181.6|
| 1134|   15.0|   181.6|
| 1135|   15.0|   181.7|
| 1136|   15.0|   181.8|
| 1137|   15.0|   181.8|
| 1138|   15.0|   181.9|
| 1139|   15.0|   181.9|
| 1140|   15.0|   182.0|
| 1141|   15.0|   182.0|
| 1142|   15.0|   182.1|
| 1143|   15.0|   182.2|
| 1144|   15.0|   182.2|
| 1145|   15.0|   182.3|
| 1146|   15.0|   182.3|
| 1147|   15.0|   182.4|
| 1148|   15.0|   182.5|
| 1149|   15.0|   182.5|
| 1150|   15.0|   182.6|
| 1151|   15.0|   182.6|
| 1152|   15.0|   182.7|
| 1153|   15.0|   182.7|
| 1154|   15.0|   182.8|
| 1155|   15.0|   182.9|
| 1156|   15.0|   182.9|
| 1157|   15.0|   183.0|
| 1158|   15.0|   183.0|
| 1159|   15.0|   183.1|
| 1160|   15.0|   183.2|
| 1161|   15.0|   183.2|
| 1162|   15.0|   183.3|
| 1163|   15.0|   183.3|
| 1164|   15.0|   183.4|
| 1165|   15.0|   183.4|
| 1166|   15.0|   183.5|
| 1167|   15.0|   183.6|
| 1168|   15.0|   183.6|
| 1169|   15.0|   183.7|
| 1170|   15.0|   183.7|
| 1171|   15.0|   183.8|
| 1172|   15.0|   183.8|
| 1173|   15.0|   183.9|
| 1174|   15.0|   184.0|
| 1175|   15.0|   184.0|
| 1176|   15.0|   184.1|
| 1177|   15.0|   184.1|
| 1178|   15.0|   184.2|
| 1179|   15.0|   184.3|
| 1180|   15.0|   184.3|
| 1181|   15.0|   184.4|
| 1182|   15.0|   184.4|
| 1183|   15.0|   184.5|
| 1184|   15.0|   184.5|
| 1185|   15.0|   184.6|
| 1186|   15.0|   184.7|
| 1187|   15.0|   184.7|
| 1188|   15.0|   184.8|
| 1189|   15.0|   184.8|
| 1190|   15.0|   184.9|
| 1191|   15.0|   184.9|
| 1192|   15.0|   185.0|
| 1193|   15.0|   185.1|
| 1194|   15.0|   185.1|
| 1195|   15.0|   185.2|
| 1196|   15.0|   185.2|
| 1197|   15.0|   185.3|
| 1198|   15.0|   185.3|
| 1199|   15.0|   185.4|
| 1200|   15.0|   185.5|
| 1201|   15.0|   185.5|
| 1202|   15.0|   185.6|
| 1203|   15.0|   185.6|
| 1204|   15.0|   185.7|
| 1205|   15.0|   185.7|
| 1206|   15.0|   185.8|
| 1207|   15.0|   185.8|
| 1208|   15.0|   185.9|
| 1209|   15.0|   186.0|
| 1210|   15.0|   186.0|
| 1211|   15.0|   186.1|
| 1212|   15.0|   186.1|
| 1213|   15.0|   186.2|
| 1214|   15.0|   186.2|
| 1215|   15.0|   186.3|
| 1216|   15.0|   186.4|
| 1217|   15.0|   186.4|
| 1218|   15.0|   186.5|
| 1219|   15.0|   186.5|
| 1220|   15.0|   186.6|
| 1221|   15.0|   186.6|
| 1222|   15.0|   186.7|
| 1223|   15.0|   186.8|
| 1224|   15.0|   186.8|
| 1225|   15.0|   186.9|
| 1226|   15.0|   186.9|
| 1227|   15.0|   187.0|
| 1228|   15.0|   187.0|
| 1229|   15.0|   187.1|
| 1230|   15.0|   187.1|
| 1231|   15.0|   187.2|
| 1232|   15.0|   187.3|
| 1233|   15.0|   187.3|
| 1234|   15.0|   187.4|
| 1235|   15.0|   187.4|
| 1236|   15.0|   187.5|
| 1237|   15.0|   187.5|
| 1238|   15.0|   187.6|
| 1239|   15.0|   187.6|
| 1240|   15.0|   187.7|
| 1241|   15.0|   187.8|
| 1242|   15.0|   187.8|
| 1243|   15.0|   187.9|
| 1244|   15.0|   187.9|
| 1245|   15.0|   188.0|
| 1246|   15.0|   188.0|
| 1247|   15.0|   188.1|
| 1248|   15.0|   188.1|
| 1249|   15.0|   188.2|
| 1250|   15.0|   188.3|
| 1251|   15.0|   188.3|
| 1252|   15.0|   188.4|
| 1253|   15.0|   188.4|
| 1254|   15.0|   188.5|
| 1255|   15.0|   188.5|
| 1256|   15.0|   188.6|
| 1257|   15.0|   188.6|
| 1258|   15.0|   188.7|
| 1259|   15.0|   188.8|
| 1260|   15.0|   188.8|
| 1261|   15.0|   188.9|
| 1262|   15.0|   188.9|
| 1263|   15.0|   189.0|
| 1264|   15.0|   189.0|
| 1265|   15.0|   189.1|
| 1266|   15.0|   189.1|
| 1267|   15.0|   189.2|
| 1268|   15.0|   189.3|
| 1269|   15.0|   189.3|
| 1270|   15.0|   189.4|
| 1271|   15.0|   189.4|
| 1272|   15.0|   189.5|
| 1273|   15.0|   189.5|
| 1274|   15.0|   189.6|
| 1275|   15.0|   189.6|
| 1276|   15.0|   189.7|
| 1277|   15.0|   189.7|
| 1278|   15.0|   189.8|
| 1279|   15.0|   189.9|
| 1280|   15.0|   189.9|
| 1281|   15.0|   190.0|
| 1282|   15.0|   190.0|
| 1283|   15.0|   190.1|
| 1284|   15.0|   190.1|
| 1285|   15.0|   190.2|
| 1286|   15.0|   190.2|
| 1287|   15.0|   190.3|
| 1288|   15.0|   190.3|
| 1289|   15.0|   190.4|
| 1290|   15.0|   190.5|
| 1291|   15.0|   190.5|
| 1292|   15.0|   190.6|
| 1293|   15.0|   190.6|
| 1294|   15.0|   190.7|
| 1295|   15.0|   190.7|
| 1296|   15.0|   190.8|
| 1297|   15.0|   190.8|
| 1298|   15.0|   190.9|
| 1299|   15.0|   190.9|
| 1300|   15.0|   191.0|
| 1301|   15.0|   191.1|
| 1302|   15.0|   191.1|
| 1303|   15.0|   191.2|
| 1304|   15.0|   191.2|
| 1305|   15.0|   191.3|
| 1306|   15.0|   191.3|
| 1307|   15.0|   191.4|
| 1308|   15.0|   191.4|
| 1309|   15.0|   191.5|
| 1310|   15.0|   191.5|
| 1311|   15.0|   191.6|
| 1312|   15.0|   191.6|
| 1313|   15.0|   191.7|
| 1314|   15.0|   191.8|
| 1315|   15.0|   191.8|
| 1316|   15.0|   191.9|
| 1317|   15.0|   191.9|
| 1318|   15.0|   192.0|
| 1319|   15.0|   192.0|
| 1320|   15.0|   192.1|
| 1321|   15.0|   192.1|
| 1322|   15.0|   192.2|
| 1323|   15.0|   192.2|
| 1324|   15.0|   192.3|
| 1325|   15.0|   192.3|
| 1326|   15.0|   192.4|
| 1327|   15.0|   192.5|
| 1328|   15.0|   192.5|
| 1329|   15.0|   192.6|
| 1330|   15.0|   192.6|
| 1331|   15.0|   192.7|
| 1332|   15.0|   192.7|
| 1333|   15.0|   192.8|
| 1334|   15.0|   192.8|
| 1335|   15.0|   192.9|
| 1336|   15.0|   192.9|
| 1337|   15.0|   193.0|
| 1338|   15.0|   193.0|
| 1339|   15.0|   193.1|
| 1340|   15.0|   193.1|
| 1341|   15.0|   193.2|
| 1342|   15.0|   193.3|
| 1343|   15.0|   193.3|
| 1344|   15.0|   193.4|
| 1345|   15.0|   193.4|
| 1346|   15.0|   193.5|
| 1347|   15.0|   193.5|
| 1348|   15.0|   193.6|
| 1349|   15.0|   193.6|
| 1350|   15.0|   193.7|
| 1351|   15.0|   193.7|
| 1352|   15.0|   193.8|
| 1353|   15.0|   193.8|
| 1354|   15.0|   193.9|
| 1355|   15.0|   193.9|
| 1356|   15.0|   194.0|
| 1357|   15.0|   194.0|
| 1358|   15.0|   194.1|
| 1359|   15.0|   194.2|
| 1360|   15.0|   194.2|
| 1361|   15.0|   194.3|
| 1362|   15.0|   194.3|
| 1363|   15.0|   194.4|
| 1364|   15.0|   194.4|
| 1365|   15.0|   194.5|
| 1366|   15.0|   194.5|
| 1367|   15.0|   194.6|
| 1368|   15.0|   194.6|
| 1369|   15.0|   194.7|
| 1370|   15.0|   194.7|
| 1371|   15.0|   194.8|
| 1372|   15.0|   194.8|
| 1373|   15.0|   194.9|
| 1374|   15.0|   194.9|
| 1375|   15.0|   195.0|
| 1376|   15.0|   195.0|
| 1377|   15.0|   195.1|
| 1378|   15.0|   195.2|
| 1379|   15.0|   195.2|
| 1380|   15.0|   195.3|
| 1381|   15.0|   195.3|
| 1382|   15.0|   195.4|
| 1383|   15.0|   195.4|
| 1384|   15.0|   195.5|
| 1385|   15.0|   195.5|
| 1386|   15.0|   195.6|
| 1387|   15.0|   195.6|
| 1388|   15.0|   195.7|
| 1389|   15.0|   195.7|
| 1390|   15.0|   195.8|
| 1391|   15.0|   195.8|
| 1392|   15.0|   195.9|
| 1393|   15.0|   195.9|
| 1394|   15.0|   196.0|
| 1395|   15.0|   196.0|
| 1396|   15.0|   196.1|
| 1397|   15.0|   196.1|
| 1398|   15.0|   196.2|
| 1399|   15.0|   196.2|
| 1400|   15.0|   196.3|
| 1401|   15.0|   196.3|
| 1402|   15.0|   196.4|
| 1403|   15.0|   196.5|
| 1404|   15.0|   196.5|
| 1405|   15.0|   196.6|
| 1406|   15.0|   196.6|
| 1407|   15.0|   196.7|
| 1408|   15.0|   196.7|
| 1409|   15.0|   196.8|
| 1410|   15.0|   196.8|
| 1411|   15.0|   196.9|
| 1412|   15.0|   196.9|
| 1413|   15.0|   197.0|
| 1414|   15.0|   197.0|
| 1415|   15.0|   197.1|
| 1416|   15.0|   197.1|
| 1417|   15.0|   197.2|
| 1418|   15.0|   197.2|
| 1419|   15.0|   197.3|
| 1420|   15.0|   197.3|
| 1421|   15.0|   197.4|
| 1422|   15.0|   197.4|
| 1423|   15.0|   197.5|
| 1424|   15.0|   197.5|
| 1425|   15.0|   197.6|
| 1426|   15.0|   197.6|
| 1427|   15.0|   197.7|
| 1428|   15.0|   197.7|
| 1429|   15.0|   197.8|
| 1430|   15.0|   197.8|
| 1431|   15.0|   197.9|
| 1432|   15.0|   197.9|
| 1433|   15.0|   198.0|
| 1434|   15.0|   198.0|
| 1435|   15.0|   198.1|
| 1436|   15.0|   198.1|
| 1437|   15.0|   198.2|
| 1438|   15.0|   198.2|
| 1439|   15.0|   198.3|
| 1440|   15.0|   198.4|
| 1441|   15.0|   198.4|
| 1442|   15.0|   198.5|
| 1443|   15.0|   198.5|
| 1444|   15.0|   198.6|
| 1445|   15.0|   198.6|
| 1446|   15.0|   198.7|
| 1447|   15.0|   198.7|
| 1448|   15.0|   198.8|
| 1449|   15.0|   198.8|
| 1450|   15.0|   198.9|
| 1451|   15.0|   198.9|
| 1452|   15.0|   199.0|
| 1453|   15.0|   199.0|
| 1454|   15.0|   199.1|
| 1455|   15.0|   199.1|
| 1456|   15.0|   199.2|
| 1457|   15.0|   199.2|
| 1458|   15.0|   199.3|
| 1459|   15.0|   199.3|
| 1460|   15.0|   199.4|
| 1461|   15.0|   199.4|
| 1462|   15.0|   199.5|
| 1463|   15.0|   199.5|
| 1464|   15.0|   199.6|
| 1465|   15.0|   199.6|
| 1466|   15.0|   199.7|
| 1467|   15.0|   199.7|
| 1468|   15.0|   199.8|
| 1469|   15.0|   199.8|
| 1470|   15.0|   199.9|
| 1471|   15.0|   199.9|
| 1472|   15.0|   200.0|
| 1473|   15.0|   200.0|
| 1474|   15.0|   200.1|
| 1475|   15.0|   200.1|
| 1476|   15.0|   200.2|
| 1477|   15.0|   200.2|
| 1478|   15.0|   200.3|
| 1479|   15.0|   200.3|
| 1480|   15.0|   200.4|
| 1481|   15.0|   200.4|
| 1482|   15.0|   200.5|
| 1483|   15.0|   200.5|
| 1484|   15.0|   200.6|
| 1485|   15.0|   200.6|
| 1486|   15.0|   200.7|
| 1487|   15.0|   200.7|
| 1488|   15.0|   200.8|
| 1489|   15.0|   200.8|
| 1490|   15.0|   200.9|
| 1491|   15.0|   200.9|
| 1492|   15.0|   201.0|
| 1493|   15.0|   201.0|
| 1494|   15.0|   201.1|
| 1495|   15.0|   201.1|
| 1496|   15.0|   201.2|
| 1497|   15.0|   201.2|
| 1498|   15.0|   201.3|
| 1499|   15.0|   201.3|
| 1500|   15.0|   201.4|
| 1501|   15.0|   201.4|
| 1502|   15.0|   201.5|
| 1503|   15.0|   201.5|
| 1504|   15.0|   201.6|
| 1505|   15.0|   201.6|
| 1506|   15.0|   201.7|
| 1507|   15.0|   201.7|
| 1508|   15.0|   201.8|
| 1509|   15.0|   201.8|
| 1510|   15.0|   201.9|
| 1511|   15.0|   201.9|
| 1512|   15.0|   202.0|
| 1513|   15.0|   202.0|
| 1514|   15.0|   202.1|
| 1515|   15.0|   202.1|
| 1516|   15.0|   202.2|
| 1517|   15.0|   202.2|
| 1518|   15.0|   202.3|
| 1519|   15.0|   202.3|
| 1520|   15.0|   202.4|
| 1521|   15.0|   202.4|
| 1522|   15.0|   202.5|
| 1523|   15.0|   202.5|
| 1524|   15.0|   202.6|
| 1525|   15.0|   202.6|
| 1526|   15.0|   202.7|
| 1527|   15.0|   202.7|
| 1528|   15.0|   202.8|
| 1529|   15.0|   202.8|
| 1530|   15.0|   202.9|
| 1531|   15.0|   202.9|
| 1532|   15.0|   203.0|
| 1533|   15.0|   203.0|
| 1534|   15.0|   203.1|
| 1535|   15.0|   203.1|
| 1536|   15.0|   203.1|
| 1537|   15.0|   203.2|
| 1538|   15.0|   203.2|
| 1539|   15.0|   203.3|
| 1540|   15.0|   203.3|
| 1541|   15.0|   203.4|
| 1542|   15.0|   203.4|
| 1543|   15.0|   203.5|
| 1544|   15.0|   203.5|
| 1545|   15.0|   203.6|
| 1546|   15.0|   203.6|
| 1547|   15.0|   203.7|
| 1548|   15.0|   203.7|
| 1549|   15.0|   203.8|
| 1550|   15.0|   203.8|
| 1551|   15.0|   203.9|
| 1552|   15.0|   203.9|
| 1553|   15.0|   204.0|
| 1554|   15.0|   204.0|
| 1555|   15.0|   204.1|
| 1556|   15.0|   204.1|
| 1557|   15.0|   204.2|
| 1558|   15.0|   204.2|
| 1559|   15.0|   204.3|
| 1560|   15.0|   204.3|
| 1561|   15.0|   204.4|
| 1562|   15.0|   204.4|
| 1563|   15.0|   204.5|
| 1564|   15.0|   204.5|
| 1565|   15.0|   204.6|
| 1566|   15.0|   204.6|
| 1567|   15.0|   204.7|
| 1568|   15.0|   204.7|
| 1569|   15.0|   204.8|
| 1570|   15.0|   204.8|
| 1571|   15.0|   204.9|
| 1572|   15.0|   204.9|
| 1573|   15.0|   204.9|
| 1574|   15.0|   205.0|
| 1575|   15.0|   205.0|
| 1576|   15.0|   205.1|
| 1577|   15.0|   205.1|
| 1578|   15.0|   205.2|
| 1579|   15.0|   205.2|
| 1580|   15.0|   205.3|
| 1581|   15.0|   205.3|
| 1582|   15.0|   205.4|
| 1583|   15.0|   205.4|
| 1584|   15.0|   205.5|
| 1585|   15.0|   205.5|
| 1586|   15.0|   205.6|
| 1587|   15.0|   205.6|
| 1588|   15.0|   205.7|
| 1589|   15.0|   205.7|
| 1590|   15.0|   205.8|
| 1591|   15.0|   205.8|
| 1592|   15.0|   205.9|
| 1593|   15.0|   205.9|
| 1594|   15.0|   206.0|
| 1595|   15.0|   206.0|
| 1596|   15.0|   206.1|
| 1597|   15.0|   206.1|
| 1598|   15.0|   206.2|
| 1599|   15.0|   206.2|
| 1600|   15.0|   206.2|
| 1601|   15.0|   206.3|
| 1602|   15.0|   206.3|
| 1603|   15.0|   206.4|
| 1604|   15.0|   206.4|
| 1605|   15.0|   206.5|
| 1606|   15.0|   206.5|
| 1607|   15.0|   206.6|
| 1608|   15.0|   206.6|
| 1609|   15.0|   206.7|
| 1610|   15.0|   206.7|
| 1611|   15.0|   206.8|
| 1612|   15.0|   206.8|
| 1613|   15.0|   206.9|
| 1614|   15.0|   206.9|
| 1615|   15.0|   207.0|
| 1616|   15.0|   207.0|
| 1617|   15.0|   207.1|
| 1618|   15.0|   207.1|
| 1619|   15.0|   207.2|
| 1620|   15.0|   207.2|
| 1621|   15.0|   207.2|
| 1622|   15.0|   207.3|
| 1623|   15.0|   207.3|
| 1624|   15.0|   207.4|
| 1625|   15.0|   207.4|
| 1626|   15.0|   207.5|
| 1627|   15.0|   207.5|
| 1628|   15.0|   207.6|
| 1629|   15.0|   207.6|
| 1630|   15.0|   207.7|
| 1631|   15.0|   207.7|
| 1632|   15.0|   207.8|
| 1633|   15.0|   207.8|
| 1634|   15.0|   207.9|
| 1635|   15.0|   207.9|
| 1636|   15.0|   208.0|
| 1637|   15.0|   208.0|
| 1638|   15.0|   208.1|
| 1639|   15.0|   208.1|
| 1640|   15.0|   208.1|
| 1641|   15.0|   208.2|
| 1642|   15.0|   208.2|
| 1643|   15.0|   208.3|
| 1644|   15.0|   208.3|
| 1645|   15.0|   208.4|
| 1646|   15.0|   208.4|
| 1647|   15.0|   208.5|
| 1648|   15.0|   208.5|
| 1649|   15.0|   208.6|
| 1650|   15.0|   208.6|
| 1651|   15.0|   208.7|
| 1652|   15.0|   208.7|
| 1653|   15.0|   208.8|
| 1654|   15.0|   208.8|
| 1655|   15.0|   208.9|
| 1656|   15.0|   208.9|
| 1657|   15.0|   208.9|
| 1658|   15.0|   209.0|
| 1659|   15.0|   209.0|
| 1660|   15.0|   209.1|
| 1661|   15.0|   209.1|
| 1662|   15.0|   209.2|
| 1663|   15.0|   209.2|
| 1664|   15.0|   209.3|
| 1665|   15.0|   209.3|
| 1666|   15.0|   209.4|
| 1667|   15.0|   209.4|
| 1668|   15.0|   209.5|
| 1669|   15.0|   209.5|
| 1670|   15.0|   209.6|
| 1671|   15.0|   209.6|
| 1672|   15.0|   209.6|
| 1673|   15.0|   209.7|
| 1674|   15.0|   209.7|
| 1675|   15.0|   209.8|
| 1676|   15.0|   209.8|
| 1677|   15.0|   209.9|
| 1678|   15.0|   209.9|
| 1679|   15.0|   210.0|
| 1680|   15.0|   210.0|
| 1681|   15.0|   210.1|
| 1682|   15.0|   210.1|
| 1683|   15.0|   210.2|
| 1684|   15.0|   210.2|
| 1685|   15.0|   210.2|
| 1686|   15.0|   210.3|
| 1687|   15.0|   210.3|
| 1688|   15.0|   210.4|
| 1689|   15.0|   210.4|
| 1690|   15.0|   210.5|
| 1691|   15.0|   210.5|
| 1692|   15.0|   210.6|
| 1693|   15.0|   210.6|
| 1694|   15.0|   210.7|
| 1695|   15.0|   210.7|
| 1696|   15.0|   210.8|
| 1697|   15.0|   210.8|
| 1698|   15.0|   210.9|
| 1699|   15.0|   210.9|
| 1700|   15.0|   210.9|
| 1701|   15.0|   211.0|
| 1702|   15.0|   211.0|
| 1703|   15.0|   211.1|
| 1704|   15.0|   211.1|
| 1705|   15.0|   211.2|
| 1706|   15.0|   211.2|
| 1707|   15.0|   211.3|
| 1708|   15.0|   211.3|
| 1709|   15.0|   211.4|
| 1710|   15.0|   211.4|
| 1711|   15.0|   211.4|
| 1712|   15.0|   211.5|
| 1713|   15.0|   211.5|
| 1714|   15.0|   211.6|
| 1715|   15.0|   211.6|
| 1716|   15.0|   211.7|
| 1717|   15.0|   211.7|
| 1718|   15.0|   211.8|
| 1719|   15.0|   211.8|
| 1720|   15.0|   211.9|
| 1721|   15.0|   211.9|
| 1722|   15.0|   212.0|
| 1723|   15.0|   212.0|
| 1724|   15.0|   212.0|
| 1725|   15.0|   212.1|
| 1726|   15.0|   212.1|
| 1727|   15.0|   212.2|
| 1728|   15.0|   212.2|
| 1729|   15.0|   212.3|
| 1730|   15.0|   212.3|
| 1731|   15.0|   212.4|
| 1732|   15.0|   212.4|
| 1733|   15.0|   212.5|
| 1734|   15.0|   212.5|
| 1735|   15.0|   212.5|
| 1736|   15.0|   212.6|
| 1737|   15.0|   212.6|
| 1738|   15.0|   212.7|
| 1739|   15.0|   212.7|
| 1740|   15.0|   212.8|
| 1741|   15.0|   212.8|
| 1742|   15.0|   212.9|
| 1743|   15.0|   212.9|
| 1744|   15.0|   213.0|
| 1745|   15.0|   213.0|
| 1746|   15.0|   213.0|
| 1747|   15.0|   213.1|
| 1748|   15.0|   213.1|
| 1749|   15.0|   213.2|
| 1750|   15.0|   213.2|
| 1751|   15.0|   213.3|
| 1752|   15.0|   213.3|
| 1753|   15.0|   213.4|
| 1754|   15.0|   213.4|
| 1755|   15.0|   213.5|
| 1756|   15.0|   213.5|
| 1757|   15.0|   213.5|
| 1758|   15.0|   213.6|
| 1759|   15.0|   213.6|
| 1760|   15.0|   213.7|
| 1761|   15.0|   213.7|
| 1762|   15.0|   213.8|
| 1763|   15.0|   213.8|
| 1764|   15.0|   213.9|
| 1765|   15.0|   213.9|
| 1766|   15.0|   214.0|
| 1767|   15.0|   214.0|
| 1768|   15.0|   214.0|
| 1769|   15.0|   214.1|
| 1770|   15.0|   214.1|
| 1771|   15.0|   214.2|
| 1772|   15.0|   214.2|
| 1773|   15.0|   214.3|
| 1774|   15.0|   214.3|
| 1775|   15.0|   214.4|
| 1776|   15.0|   214.4|
| 1777|   15.0|   214.4|
| 1778|   15.0|   214.5|
| 1779|   15.0|   214.5|
| 1780|   15.0|   214.6|
| 1781|   15.0|   214.6|
| 1782|   15.0|   214.7|
| 1783|   15.0|   214.7|
| 1784|   15.0|   214.8|
| 1785|   15.0|   214.8|
| 1786|   15.0|   214.8|
| 1787|   15.0|   214.9|
| 1788|   15.0|   214.9|
| 1789|   15.0|   215.0|
| 1790|   15.0|   215.0|
| 1791|   15.0|   215.1|
| 1792|   15.0|   215.1|
| 1793|   15.0|   215.2|
| 1794|   15.0|   215.2|
| 1795|   15.0|   215.3|
| 1796|   15.0|   215.3|
| 1797|   15.0|   215.3|
| 1798|   15.0|   215.4|
| 1799|   15.0|   215.4|
| 1800|   15.0|   215.5|
| 1801|   15.0|   215.5|
| 1802|   15.0|   215.6|
| 1803|   15.0|   215.6|
| 1804|   15.0|   215.7|
| 1805|   15.0|   215.7|
| 1806|   15.0|   215.7|
| 1807|   15.0|   215.8|
| 1808|   15.0|   215.8|
| 1809|   15.0|   215.9|
| 1810|   15.0|   215.9|
| 1811|   15.0|   216.0|
| 1812|   15.0|   216.0|
| 1813|   15.0|   216.1|
| 1814|   15.0|   216.1|
| 1815|   15.0|   216.1|
| 1816|   15.0|   216.2|
| 1817|   15.0|   216.2|
| 1818|   15.0|   216.3|
| 1819|   15.0|   216.3|
| 1820|   15.0|   216.4|
| 1821|   15.0|   216.4|
| 1822|   15.0|   216.5|
| 1823|   15.0|   216.5|
| 1824|   15.0|   216.5|
| 1825|   15.0|   216.6|
| 1826|   15.0|   216.6|
| 1827|   15.0|   216.7|
| 1828|   15.0|   216.7|
| 1829|   15.0|   216.8|
| 1830|   15.0|   216.8|
| 1831|   15.0|   216.8|
| 1832|   15.0|   216.9|
| 1833|   15.0|   216.9|
| 1834|   15.0|   217.0|
| 1835|   15.0|   217.0|
| 1836|   15.0|   217.1|
| 1837|   15.0|   217.1|
| 1838|   15.0|   217.2|
| 1839|   15.0|   217.2|
| 1840|   15.0|   217.2|
| 1841|   15.0|   217.3|
| 1842|   15.0|   217.3|
| 1843|   15.0|   217.4|
| 1844|   15.0|   217.4|
| 1845|   15.0|   217.5|
| 1846|   15.0|   217.5|
| 1847|   15.0|   217.6|
| 1848|   15.0|   217.6|
| 1849|   15.0|   217.6|
| 1850|   15.0|   217.7|
| 1851|   15.0|   217.7|
| 1852|   15.0|   217.8|
| 1853|   15.0|   217.8|
| 1854|   15.0|   217.9|
| 1855|   15.0|   217.9|
| 1856|   15.0|   217.9|
| 1857|   15.0|   218.0|
| 1858|   15.0|   218.0|
| 1859|   15.0|   218.1|
| 1860|   15.0|   218.1|
| 1861|   15.0|   218.2|
| 1862|   15.0|   218.2|
| 1863|   15.0|   218.3|
| 1864|   15.0|   218.3|
| 1865|   15.0|   218.3|
| 1866|   15.0|   218.4|
| 1867|   15.0|   218.4|
| 1868|   15.0|   218.5|
| 1869|   15.0|   218.5|
| 1870|   15.0|   218.6|
| 1871|   15.0|   218.6|
| 1872|   15.0|   218.6|
| 1873|   15.0|   218.7|
| 1874|   15.0|   218.7|
| 1875|   15.0|   218.8|
| 1876|   15.0|   218.8|
| 1877|   15.0|   218.9|
| 1878|   15.0|   218.9|
| 1879|   15.0|   219.0|
| 1880|   15.0|   219.0|
| 1881|   15.0|   219.0|
| 1882|   15.0|   219.1|
| 1883|   15.0|   219.1|
| 1884|   15.0|   219.2|
| 1885|   15.0|   219.2|
| 1886|   15.0|   219.3|
| 1887|   15.0|   219.3|
| 1888|   15.0|   219.3|
| 1889|   15.0|   219.4|
| 1890|   15.0|   219.4|
| 1891|   15.0|   219.5|
| 1892|   15.0|   219.5|
| 1893|   15.0|   219.6|
| 1894|   15.0|   219.6|
| 1895|   15.0|   219.6|
| 1896|   15.0|   219.7|
| 1897|   15.0|   219.7|
| 1898|   15.0|   219.8|
| 1899|   15.0|   219.8|
| 1900|   15.0|   219.9|
| 1901|   15.0|   219.9|
| 1902|   15.0|   219.9|
| 1903|   15.0|   220.0|
| 1904|   15.0|   220.0|
| 1905|   15.0|   220.1|
| 1906|   15.0|   220.1|
| 1907|   15.0|   220.2|
| 1908|   15.0|   220.2|
| 1909|   15.0|   220.2|
| 1910|   15.0|   220.3|
| 1911|   15.0|   220.3|
| 1912|   15.0|   220.4|
| 1913|   15.0|   220.4|
| 1914|   15.0|   220.5|
| 1915|   15.0|   220.5|
| 1916|   15.0|   220.5|
| 1917|   15.0|   220.6|
| 1918|   15.0|   220.6|
| 1919|   15.0|   220.7|
| 1920|   15.0|   220.7|
| 1921|   15.0|   220.8|
| 1922|   15.0|   220.8|
| 1923|   15.0|   220.8|
| 1924|   15.0|   220.9|
| 1925|   15.0|   220.9|
| 1926|   15.0|   221.0|
| 1927|   15.0|   221.0|
| 1928|   15.0|   221.1|
| 1929|   15.0|   221.1|
| 1930|   15.0|   221.1|
| 1931|   15.0|   221.2|
| 1932|   15.0|   221.2|
| 1933|   15.0|   221.3|
| 1934|   15.0|   221.3|
| 1935|   15.0|   221.4|
| 1936|   15.0|   221.4|
| 1937|   15.0|   221.4|
| 1938|   15.0|   221.5|
| 1939|   15.0|   221.5|
| 1940|   15.0|   221.6|
| 1941|   15.0|   221.6|
| 1942|   15.0|   221.7|
| 1943|   15.0|   221.7|
| 1944|   15.0|   221.7|
| 1945|   15.0|   221.8|
| 1946|   15.0|   221.8|
| 1947|   15.0|   221.9|
| 1948|   15.0|   221.9|
| 1949|   15.0|   222.0|
| 1950|   15.0|   222.0|
| 1951|   15.0|   222.0|
| 1952|   15.0|   222.1|
| 1953|   15.0|   222.1|
| 1954|   15.0|   222.2|
| 1955|   15.0|   222.2|
| 1956|   15.0|   222.3|
| 1957|   15.0|   222.3|
| 1958|   15.0|   222.3|
| 1959|   15.0|   222.4|
| 1960|   15.0|   222.4|
| 1961|   15.0|   222.5|
| 1962|   15.0|   222.5|
| 1963|   15.0|   222.6|
| 1964|   15.0|   222.6|
| 1965|   15.0|   222.6|
| 1966|   15.0|   222.7|
| 1967|   15.0|   222.7|
| 1968|   15.0|   222.8|
| 1969|   15.0|   222.8|
| 1970|   15.0|   222.8|
| 1971|   15.0|   222.9|
| 1972|   15.0|   222.9|
| 1973|   15.0|   223.0|
| 1974|   15.0|   223.0|
| 1975|   15.0|   223.1|
| 1976|   15.0|   223.1|
| 1977|   15.0|   223.1|
| 1978|   15.0|   223.2|
| 1979|   15.0|   223.2|
| 1980|   15.0|   223.3|
| 1981|   15.0|   223.3|
| 1982|   15.0|   223.4|
| 1983|   15.0|   223.4|
| 1984|   15.0|   223.4|
| 1985|   15.0|   223.5|
| 1986|   15.0|   223.5|
| 1987|   15.0|   223.6|
| 1988|   15.0|   223.6|
| 1989|   15.0|   223.6|
| 1990|   15.0|   223.7|
| 1991|   15.0|   223.7|
| 1992|   15.0|   223.8|
| 1993|   15.0|   223.8|
| 1994|   15.0|   223.9|
| 1995|   15.0|   223.9|
| 1996|   15.0|   223.9|
| 1997|   15.0|   224.0|
| 1998|   15.0|   224.0|
| 1999|   15.0|   224.1|
| 2000|   15.0|   224.1|
| 2001|   15.0|   224.1|
| 2002|   15.0|   224.2|
| 2003|   15.0|   224.2|
| 2004|   15.0|   224.3|
| 2005|   15.0|   224.3|
| 2006|   15.0|   224.4|
| 2007|   15.0|   224.4|
| 2008|   15.0|   224.4|
| 2009|   15.0|   224.5|
| 2010|   15.0|   224.5|
| 2011|   15.0|   224.6|
| 2012|   15.0|   224.6|
| 2013|   15.0|   224.6|
| 2014|   15.0|   224.7|
| 2015|   15.0|   224.7|
| 2016|   15.0|   224.8|
| 2017|   15.0|   224.8|
| 2018|   15.0|   224.9|
| 2019|   15.0|   224.9|
| 2020|   15.0|   224.9|
| 2021|   15.0|   225.0|
| 2022|   15.0|   225.0|
| 2023|   15.0|   225.1|
| 2024|   15.0|   225.1|
| 2025|   15.0|   225.1|
| 2026|   15.0|   225.2|
| 2027|   15.0|   225.2|
| 2028|   15.0|   225.3|
| 2029|   15.0|   225.3|
| 2030|   15.0|   225.4|
| 2031|   15.0|   225.4|
| 2032|   15.0|   225.4|
| 2033|   15.0|   225.5|
| 2034|   15.0|   225.5|
| 2035|   15.0|   225.6|
| 2036|   15.0|   225.6|
| 2037|   15.0|   225.6|
| 2038|   15.0|   225.7|
| 2039|   15.0|   225.7|
| 2040|   15.0|   225.8|
| 2041|   15.0|   225.8|
| 2042|   15.0|   225.9|
| 2043|   15.0|   225.9|
| 2044|   15.0|   225.9|
| 2045|   15.0|   226.0|
| 2046|   15.0|   226.0|
| 2047|   15.0|   226.1|
| 2048|   15.0|   226.1|
| 2049|   15.0|   226.1|
| 2050|   15.0|   226.2|
| 2051|   15.0|   226.2|
| 2052|   15.0|   226.3|
| 2053|   15.0|   226.3|
| 2054|   15.0|   226.3|
| 2055|   15.0|   226.4|
| 2056|   15.0|   226.4|
| 2057|   15.0|   226.5|
| 2058|   15.0|   226.5|
| 2059|   15.0|   226.6|
| 2060|   15.0|   226.6|
| 2061|   15.0|   226.6|
| 2062|   15.0|   226.7|
| 2063|   15.0|   226.7|
| 2064|   15.0|   226.8|
| 2065|   15.0|   226.8|
| 2066|   15.0|   226.8|
| 2067|   15.0|   226.9|
| 2068|   15.0|   226.9|
| 2069|   15.0|   227.0|
| 2070|   15.0|   227.0|
| 2071|   15.0|   227.0|
| 2072|   15.0|   227.1|
| 2073|   15.0|   227.1|
| 2074|   15.0|   227.2|
| 2075|   15.0|   227.2|
| 2076|   15.0|   227.3|
| 2077|   15.0|   227.3|
| 2078|   15.0|   227.3|
| 2079|   15.0|   227.4|
| 2080|   15.0|   227.4|
| 2081|   15.0|   227.5|
| 2082|   15.0|   227.5|
| 2083|   15.0|   227.5|
| 2084|   15.0|   227.6|
| 2085|   15.0|   227.6|
| 2086|   15.0|   227.7|
| 2087|   15.0|   227.7|
| 2088|   15.0|   227.7|
| 2089|   15.0|   227.8|
| 2090|   15.0|   227.8|
| 2091|   15.0|   227.9|
| 2092|   15.0|   227.9|
| 2093|   15.0|   227.9|
| 2094|   15.0|   228.0|
| 2095|   15.0|   228.0|
| 2096|   15.0|   228.1|
| 2097|   15.0|   228.1|
| 2098|   15.0|   228.1|
| 2099|   15.0|   228.2|
| 2100|   15.0|   228.2|
| 2101|   15.0|   228.3|
| 2102|   15.0|   228.3|
| 2103|   15.0|   228.4|
| 2104|   15.0|   228.4|
| 2105|   15.0|   228.4|
| 2106|   15.0|   228.5|
| 2107|   15.0|   228.5|
| 2108|   15.0|   228.6|
| 2109|   15.0|   228.6|
| 2110|   15.0|   228.6|
| 2111|   15.0|   228.7|
| 2112|   15.0|   228.7|
| 2113|   15.0|   228.8|
| 2114|   15.0|   228.8|
| 2115|   15.0|   228.8|
| 2116|   15.0|   228.9|
| 2117|   15.0|   228.9|
| 2118|   15.0|   229.0|
| 2119|   15.0|   229.0|
| 2120|   15.0|   229.0|
| 2121|   15.0|   229.1|
| 2122|   15.0|   229.1|
| 2123|   15.0|   229.2|
| 2124|   15.0|   229.2|
| 2125|   15.0|   229.2|
| 2126|   15.0|   229.3|
| 2127|   15.0|   229.3|
| 2128|   15.0|   229.4|
| 2129|   15.0|   229.4|
| 2130|   15.0|   229.4|
| 2131|   15.0|   229.5|
| 2132|   15.0|   229.5|
| 2133|   15.0|   229.6|
| 2134|   15.0|   229.6|
| 2135|   15.0|   229.6|
| 2136|   15.0|   229.7|
| 2137|   15.0|   229.7|
| 2138|   15.0|   229.8|
| 2139|   15.0|   229.8|
| 2140|   15.0|   229.8|
| 2141|   15.0|   229.9|
| 2142|   15.0|   229.9|
| 2143|   15.0|   230.0|
| 2144|   15.0|   230.0|
| 2145|   15.0|   230.0|
| 2146|   15.0|   230.1|
| 2147|   15.0|   230.1|
| 2148|   15.0|   230.2|
| 2149|   15.0|   230.2|
| 2150|   15.0|   230.2|
| 2151|   15.0|   230.3|
| 2152|   15.0|   230.3|
| 2153|   15.0|   230.4|
| 2154|   15.0|   230.4|
| 2155|   15.0|   230.4|
| 2156|   15.0|   230.5|
| 2157|   15.0|   230.5|
| 2158|   15.0|   230.6|
| 2159|   15.0|   230.6|
| 2160|   15.0|   230.6|
| 2161|   15.0|   230.7|
| 2162|   15.0|   230.7|
| 2163|   15.0|   230.8|
| 2164|   15.0|   230.8|
| 2165|   15.0|   230.8|
| 2166|   15.0|   230.9|
| 2167|   15.0|   230.9|
| 2168|   15.0|   231.0|
| 2169|   15.0|   231.0|
| 2170|   15.0|   231.0|
| 2171|   15.0|   231.1|
| 2172|   15.0|   231.1|
| 2173|   15.0|   231.2|
| 2174|   15.0|   231.2|
| 2175|   15.0|   231.2|
| 2176|   15.0|   231.3|
| 2177|   15.0|   231.3|
| 2178|   15.0|   231.4|
| 2179|   15.0|   231.4|
| 2180|   15.0|   231.4|
| 2181|   15.0|   231.5|
| 2182|   15.0|   231.5|
| 2183|   15.0|   231.6|
| 2184|   15.0|   231.6|
| 2185|   15.0|   231.6|
| 2186|   15.0|   231.7|
| 2187|   15.0|   231.7|
| 2188|   15.0|   231.8|
| 2189|   15.0|   231.8|
| 2190|   15.0|   231.8|
| 2191|   15.0|   231.9|
| 2192|   15.0|   231.9|
| 2193|   15.0|   232.0|
| 2194|   15.0|   232.0|
| 2195|   15.0|   232.0|
| 2196|   15.0|   232.1|
| 2197|   15.0|   232.1|
| 2198|   15.0|   232.2|
| 2199|   15.0|   232.2|
| 2200|   15.0|   232.2|
| 2201|   15.0|   232.3|
| 2202|   15.0|   232.3|
| 2203|   15.0|   232.4|
| 2204|   15.0|   232.4|
| 2205|   15.0|   232.4|
| 2206|   15.0|   232.5|
| 2207|   15.0|   232.5|
| 2208|   15.0|   232.6|
| 2209|   15.0|   232.6|
| 2210|   15.0|   232.6|
| 2211|   15.0|   232.7|
| 2212|   15.0|   232.7|
| 2213|   15.0|   232.7|
| 2214|   15.0|   232.8|
| 2215|   15.0|   232.8|
| 2216|   15.0|   232.9|
| 2217|   15.0|   232.9|
| 2218|   15.0|   232.9|
| 2219|   15.0|   233.0|
| 2220|   15.0|   233.0|
| 2221|   15.0|   233.1|
| 2222|   15.0|   233.1|
| 2223|   15.0|   233.1|
| 2224|   15.0|   233.2|
| 2225|   15.0|   233.2|
| 2226|   15.0|   233.3|
| 2227|   15.0|   233.3|
| 2228|   15.0|   233.3|
| 2229|   15.0|   233.4|
| 2230|   15.0|   233.4|
| 2231|   15.0|   233.5|
| 2232|   15.0|   233.5|
| 2233|   15.0|   233.5|
| 2234|   15.0|   233.6|
| 2235|   15.0|   233.6|
| 2236|   15.0|   233.7|
| 2237|   15.0|   233.7|
| 2238|   15.0|   233.7|
| 2239|   15.0|   233.8|
| 2240|   15.0|   233.8|
| 2241|   15.0|   233.8|
| 2242|   15.0|   233.9|
| 2243|   15.0|   233.9|
| 2244|   15.0|   234.0|
| 2245|   15.0|   234.0|
| 2246|   15.0|   234.0|
| 2247|   15.0|   234.1|
| 2248|   15.0|   234.1|
| 2249|   15.0|   234.2|
| 2250|   15.0|   234.2|
| 2251|   15.0|   234.2|
| 2252|   15.0|   234.3|
| 2253|   15.0|   234.3|
| 2254|   15.0|   234.4|
| 2255|   15.0|   234.4|
| 2256|   15.0|   234.4|
| 2257|   15.0|   234.5|
| 2258|   15.0|   234.5|
| 2259|   15.0|   234.5|
| 2260|   15.0|   234.6|
| 2261|   15.0|   234.6|
| 2262|   15.0|   234.7|
| 2263|   15.0|   234.7|
| 2264|   15.0|   234.7|
| 2265|   15.0|   234.8|
| 2266|   15.0|   234.8|
| 2267|   15.0|   234.9|
| 2268|   15.0|   234.9|
| 2269|   15.0|   234.9|
| 2270|   15.0|   235.0|
| 2271|   15.0|   235.0|
| 2272|   15.0|   235.1|
| 2273|   15.0|   235.1|
| 2274|   15.0|   235.1|
| 2275|   15.0|   235.2|
| 2276|   15.0|   235.2|
| 2277|   15.0|   235.2|
| 2278|   15.0|   235.3|
| 2279|   15.0|   235.3|
| 2280|   15.0|   235.4|
| 2281|   15.0|   235.4|
| 2282|   15.0|   235.4|
| 2283|   15.0|   235.5|
| 2284|   15.0|   235.5|
| 2285|   15.0|   235.6|
| 2286|   15.0|   235.6|
| 2287|   15.0|   235.6|
| 2288|   15.0|   235.7|
| 2289|   15.0|   235.7|
| 2290|   15.0|   235.7|
| 2291|   15.0|   235.8|
| 2292|   15.0|   235.8|
| 2293|   15.0|   235.9|
| 2294|   15.0|   235.9|
| 2295|   15.0|   235.9|
| 2296|   15.0|   236.0|
| 2297|   15.0|   236.0|
| 2298|   15.0|   236.1|
| 2299|   15.0|   236.1|
| 2300|   15.0|   236.1|
| 2301|   15.0|   236.2|
| 2302|   15.0|   236.2|
| 2303|   15.0|   236.2|
| 2304|   15.0|   236.3|
| 2305|   15.0|   236.3|
| 2306|   15.0|   236.4|
| 2307|   15.0|   236.4|
| 2308|   15.0|   236.4|
| 2309|   15.0|   236.5|
| 2310|   15.0|   236.5|
| 2311|   15.0|   236.6|
| 2312|   15.0|   236.6|
| 2313|   15.0|   236.6|
| 2314|   15.0|   236.7|
| 2315|   15.0|   236.7|
| 2316|   15.0|   236.7|
| 2317|   15.0|   236.8|
| 2318|   15.0|   236.8|
| 2319|   15.0|   236.9|
| 2320|   15.0|   236.9|
| 2321|   15.0|   236.9|
| 2322|   15.0|   237.0|
| 2323|   15.0|   237.0|
| 2324|   15.0|   237.1|
| 2325|   15.0|   237.1|
| 2326|   15.0|   237.1|
| 2327|   15.0|   237.2|
| 2328|   15.0|   237.2|
| 2329|   15.0|   237.2|
| 2330|   15.0|   237.3|
| 2331|   15.0|   237.3|
| 2332|   15.0|   237.4|
| 2333|   15.0|   237.4|
| 2334|   15.0|   237.4|
| 2335|   15.0|   237.5|
| 2336|   15.0|   237.5|
| 2337|   15.0|   237.5|
| 2338|   15.0|   237.6|
| 2339|   15.0|   237.6|
| 2340|   15.0|   237.7|
| 2341|   15.0|   237.7|
| 2342|   15.0|   237.7|
| 2343|   15.0|   237.8|
| 2344|   15.0|   237.8|
| 2345|   15.0|   237.9|
| 2346|   15.0|   237.9|
| 2347|   15.0|   237.9|
| 2348|   15.0|   238.0|
| 2349|   15.0|   238.0|
| 2350|   15.0|   238.0|
| 2351|   15.0|   238.1|
| 2352|   15.0|   238.1|
| 2353|   15.0|   238.2|
| 2354|   15.0|   238.2|
| 2355|   15.0|   238.2|
| 2356|   15.0|   238.3|
| 2357|   15.0|   238.3|
| 2358|   15.0|   238.3|
| 2359|   15.0|   238.4|
| 2360|   15.0|   238.4|
| 2361|   15.0|   238.5|
| 2362|   15.0|   238.5|
| 2363|   15.0|   238.5|
| 2364|   15.0|   238.6|
| 2365|   15.0|   238.6|
| 2366|   15.0|   238.7|
| 2367|   15.0|   238.7|
| 2368|   15.0|   238.7|
| 2369|   15.0|   238.8|
| 2370|   15.0|   238.8|
| 2371|   15.0|   238.8|
| 2372|   15.0|   238.9|
| 2373|   15.0|   238.9|
| 2374|   15.0|   239.0|
| 2375|   15.0|   239.0|
| 2376|   15.0|   239.0|
| 2377|   15.0|   239.1|
| 2378|   15.0|   239.1|
| 2379|   15.0|   239.1|
| 2380|   15.0|   239.2|
| 2381|   15.0|   239.2|
| 2382|   15.0|   239.3|
| 2383|   15.0|   239.3|
| 2384|   15.0|   239.3|
| 2385|   15.0|   239.4|
| 2386|   15.0|   239.4|
| 2387|   15.0|   239.4|
| 2388|   15.0|   239.5|
| 2389|   15.0|   239.5|
| 2390|   15.0|   239.6|
| 2391|   15.0|   239.6|
| 2392|   15.0|   239.6|
| 2393|   15.0|   239.7|
| 2394|   15.0|   239.7|
| 2395|   15.0|   239.7|
| 2396|   15.0|   239.8|
| 2397|   15.0|   239.8|
| 2398|   15.0|   239.9|
| 2399|   15.0|   239.9|
| 2400|   15.0|   239.9|
| 2401|   15.0|   240.0|
| 2402|   15.0|   240.0|
| 2403|   15.0|   240.0|
| 2404|   15.0|   240.1|
| 2405|   15.0|   240.1|
| 2406|   15.0|   240.2|
| 2407|   15.0|   240.2|
| 2408|   15.0|   240.2|
| 2409|   15.0|   240.3|
| 2410|   15.0|   240.3|
| 2411|   15.0|   240.3|
| 2412|   15.0|   240.4|
| 2413|   15.0|   240.4|
| 2414|   15.0|   240.5|
| 2415|   15.0|   240.5|
| 2416|   15.0|   240.5|
| 2417|   15.0|   240.6|
| 2418|   15.0|   240.6|
| 2419|   15.0|   240.6|
| 2420|   15.0|   240.7|
| 2421|   15.0|   240.7|
| 2422|   15.0|   240.8|
| 2423|   15.0|   240.8|
| 2424|   15.0|   240.8|
| 2425|   15.0|   240.9|
| 2426|   15.0|   240.9|
| 2427|   15.0|   240.9|
| 2428|   15.0|   241.0|
| 2429|   15.0|   241.0|
| 2430|   15.0|   241.1|
| 2431|   15.0|   241.1|
| 2432|   15.0|   241.1|
| 2433|   15.0|   241.2|
| 2434|   15.0|   241.2|
| 2435|   15.0|   241.2|
| 2436|   15.0|   241.3|
| 2437|   15.0|   241.3|
| 2438|   15.0|   241.3|
| 2439|   15.0|   241.4|
| 2440|   15.0|   241.4|
| 2441|   15.0|   241.5|
| 2442|   15.0|   241.5|
| 2443|   15.0|   241.5|
| 2444|   15.0|   241.6|
| 2445|   15.0|   241.6|
| 2446|   15.0|   241.6|
| 2447|   15.0|   241.7|
| 2448|   15.0|   241.7|
| 2449|   15.0|   241.8|
| 2450|   15.0|   241.8|
| 2451|   15.0|   241.8|
| 2452|   15.0|   241.9|
| 2453|   15.0|   241.9|
| 2454|   15.0|   241.9|
| 2455|   15.0|   242.0|
| 2456|   15.0|   242.0|
| 2457|   15.0|   242.1|
| 2458|   15.0|   242.1|
| 2459|   15.0|   242.1|
| 2460|   15.0|   242.2|
| 2461|   15.0|   242.2|
| 2462|   15.0|   242.2|
| 2463|   15.0|   242.3|
| 2464|   15.0|   242.3|
| 2465|   15.0|   242.3|
| 2466|   15.0|   242.4|
| 2467|   15.0|   242.4|
| 2468|   15.0|   242.5|
| 2469|   15.0|   242.5|
| 2470|   15.0|   242.5|
| 2471|   15.0|   242.6|
| 2472|   15.0|   242.6|
| 2473|   15.0|   242.6|
| 2474|   15.0|   242.7|
| 2475|   15.0|   242.7|
| 2476|   15.0|   242.8|
| 2477|   15.0|   242.8|
| 2478|   15.0|   242.8|
| 2479|   15.0|   242.9|
| 2480|   15.0|   242.9|
| 2481|   15.0|   242.9|
| 2482|   15.0|   243.0|
| 2483|   15.0|   243.0|
| 2484|   15.0|   243.0|
| 2485|   15.0|   243.1|
| 2486|   15.0|   243.1|
| 2487|   15.0|   243.2|
| 2488|   15.0|   243.2|
| 2489|   15.0|   243.2|
| 2490|   15.0|   243.3|
| 2491|   15.0|   243.3|
| 2492|   15.0|   243.3|
| 2493|   15.0|   243.4|
| 2494|   15.0|   243.4|
| 2495|   15.0|   243.5|
| 2496|   15.0|   243.5|
| 2497|   15.0|   243.5|
| 2498|   15.0|   243.6|
| 2499|   15.0|   243.6|
| 2500|   15.0|   243.6|
| 2501|   15.0|   243.7|
| 2502|   15.0|   243.7|
| 2503|   15.0|   243.7|
| 2504|   15.0|   243.8|
| 2505|   15.0|   243.8|
| 2506|   15.0|   243.9|
| 2507|   15.0|   243.9|
| 2508|   15.0|   243.9|
| 2509|   15.0|   244.0|
| 2510|   15.0|   244.0|
| 2511|   15.0|   244.0|
| 2512|   15.0|   244.1|
| 2513|   15.0|   244.1|
| 2514|   15.0|   244.1|
| 2515|   15.0|   244.2|
| 2516|   15.0|   244.2|
| 2517|   15.0|   244.3|
| 2518|   15.0|   244.3|
| 2519|   15.0|   244.3|
| 2520|   15.0|   244.4|
| 2521|   15.0|   244.4|
| 2522|   15.0|   244.4|
| 2523|   15.0|   244.5|
| 2524|   15.0|   244.5|
| 2525|   15.0|   244.5|
| 2526|   15.0|   244.6|
| 2527|   15.0|   244.6|
| 2528|   15.0|   244.7|
| 2529|   15.0|   244.7|
| 2530|   15.0|   244.7|
| 2531|   15.0|   244.8|
| 2532|   15.0|   244.8|
| 2533|   15.0|   244.8|
| 2534|   15.0|   244.9|
| 2535|   15.0|   244.9|
| 2536|   15.0|   244.9|
| 2537|   15.0|   245.0|
| 2538|   15.0|   245.0|
| 2539|   15.0|   245.1|
| 2540|   15.0|   245.1|
| 2541|   15.0|   245.1|
| 2542|   15.0|   245.2|
| 2543|   15.0|   245.2|
| 2544|   15.0|   245.2|
| 2545|   15.0|   245.3|
| 2546|   15.0|   245.3|
| 2547|   15.0|   245.3|
| 2548|   15.0|   245.4|
| 2549|   15.0|   245.4|
| 2550|   15.0|   245.5|
| 2551|   15.0|   245.5|
| 2552|   15.0|   245.5|
| 2553|   15.0|   245.6|
| 2554|   15.0|   245.6|
| 2555|   15.0|   245.6|
| 2556|   15.0|   245.7|
| 2557|   15.0|   245.7|
| 2558|   15.0|   245.7|
| 2559|   15.0|   245.8|
| 2560|   15.0|   245.8|
| 2561|   15.0|   245.9|
| 2562|   15.0|   245.9|
| 2563|   15.0|   245.9|
| 2564|   15.0|   246.0|
| 2565|   15.0|   246.0|
| 2566|   15.0|   246.0|
| 2567|   15.0|   246.1|
| 2568|   15.0|   246.1|
| 2569|   15.0|   246.1|
| 2570|   15.0|   246.2|
| 2571|   15.0|   246.2|
| 2572|   15.0|   246.2|
| 2573|   15.0|   246.3|
| 2574|   15.0|   246.3|
| 2575|   15.0|   246.4|
| 2576|   15.0|   246.4|
| 2577|   15.0|   246.4|
| 2578|   15.0|   246.5|
| 2579|   15.0|   246.5|
| 2580|   15.0|   246.5|
| 2581|   15.0|   246.6|
| 2582|   15.0|   246.6|
| 2583|   15.0|   246.6|
| 2584|   15.0|   246.7|
| 2585|   15.0|   246.7|
| 2586|   15.0|   246.7|
| 2587|   15.0|   246.8|
| 2588|   15.0|   246.8|
| 2589|   15.0|   246.9|
| 2590|   15.0|   246.9|
| 2591|   15.0|   246.9|
| 2592|   15.0|   247.0|
| 2593|   15.0|   247.0|
| 2594|   15.0|   247.0|
| 2595|   15.0|   247.1|
| 2596|   15.0|   247.1|
| 2597|   15.0|   247.1|
| 2598|   15.0|   247.2|
| 2599|   15.0|   247.2|
| 2600|   15.0|   247.3|
| 2601|   15.0|   247.3|
| 2602|   15.0|   247.3|
| 2603|   15.0|   247.4|
| 2604|   15.0|   247.4|
| 2605|   15.0|   247.4|
| 2606|   15.0|   247.5|
| 2607|   15.0|   247.5|
| 2608|   15.0|   247.5|
| 2609|   15.0|   247.6|
| 2610|   15.0|   247.6|
| 2611|   15.0|   247.6|
| 2612|   15.0|   247.7|
| 2613|   15.0|   247.7|
| 2614|   15.0|   247.7|
| 2615|   15.0|   247.8|
| 2616|   15.0|   247.8|
| 2617|   15.0|   247.9|
| 2618|   15.0|   247.9|
| 2619|   15.0|   247.9|
| 2620|   15.0|   248.0|
| 2621|   15.0|   248.0|
| 2622|   15.0|   248.0|
| 2623|   15.0|   248.1|
| 2624|   15.0|   248.1|
| 2625|   15.0|   248.1|
| 2626|   15.0|   248.2|
| 2627|   15.0|   248.2|
| 2628|   15.0|   248.2|
| 2629|   15.0|   248.3|
| 2630|   15.0|   248.3|
| 2631|   15.0|   248.4|
| 2632|   15.0|   248.4|
| 2633|   15.0|   248.4|
| 2634|   15.0|   248.5|
| 2635|   15.0|   248.5|
| 2636|   15.0|   248.5|
| 2637|   15.0|   248.6|
| 2638|   15.0|   248.6|
| 2639|   15.0|   248.6|
| 2640|   15.0|   248.7|
| 2641|   15.0|   248.7|
| 2642|   15.0|   248.7|
| 2643|   15.0|   248.8|
| 2644|   15.0|   248.8|
| 2645|   15.0|   248.9|
| 2646|   15.0|   248.9|
| 2647|   15.0|   248.9|
| 2648|   15.0|   249.0|
| 2649|   15.0|   249.0|
| 2650|   15.0|   249.0|
| 2651|   15.0|   249.1|
| 2652|   15.0|   249.1|
| 2653|   15.0|   249.1|
| 2654|   15.0|   249.2|
| 2655|   15.0|   249.2|
| 2656|   15.0|   249.2|
| 2657|   15.0|   249.3|
| 2658|   15.0|   249.3|
| 2659|   15.0|   249.3|
| 2660|   15.0|   249.4|
| 2661|   15.0|   249.4|
| 2662|   15.0|   249.5|
| 2663|   15.0|   249.5|
| 2664|   15.0|   249.5|
| 2665|   15.0|   249.6|
| 2666|   15.0|   249.6|
| 2667|   15.0|   249.6|
| 2668|   15.0|   249.7|
| 2669|   15.0|   249.7|
| 2670|   15.0|   249.7|
| 2671|   15.0|   249.8|
| 2672|   15.0|   249.8|
| 2673|   15.0|   249.8|
| 2674|   15.0|   249.9|
| 2675|   15.0|   249.9|
| 2676|   15.0|   249.9|
| 2677|   15.0|   250.0|
| 2678|   15.0|   250.0|
| 2679|   15.0|   250.0|
| 2680|   15.0|   250.1|
| 2681|   15.0|   250.1|
| 2682|   15.0|   250.2|
| 2683|   15.0|   250.2|
| 2684|   15.0|   250.2|
| 2685|   15.0|   250.3|
| 2686|   15.0|   250.3|
| 2687|   15.0|   250.3|
| 2688|   15.0|   250.4|
| 2689|   15.0|   250.4|
| 2690|   15.0|   250.4|
| 2691|   15.0|   250.5|
| 2692|   15.0|   250.5|
| 2693|   15.0|   250.5|
| 2694|   15.0|   250.6|
| 2695|   15.0|   250.6|
| 2696|   15.0|   250.6|
| 2697|   15.0|   250.7|
| 2698|   15.0|   250.7|
| 2699|   15.0|   250.7|
| 2700|   15.0|   250.8|
| 2701|   15.0|   250.8|
| 2702|   15.0|   250.9|
| 2703|   15.0|   250.9|
| 2704|   15.0|   250.9|
| 2705|   15.0|   251.0|
| 2706|   15.0|   251.0|
| 2707|   15.0|   251.0|
| 2708|   15.0|   251.1|
| 2709|   15.0|   251.1|
| 2710|   15.0|   251.1|
| 2711|   15.0|   251.2|
| 2712|   15.0|   251.2|
| 2713|   15.0|   251.2|
| 2714|   15.0|   251.3|
| 2715|   15.0|   251.3|
| 2716|   15.0|   251.3|
| 2717|   15.0|   251.4|
| 2718|   15.0|   251.4|
| 2719|   15.0|   251.4|
| 2720|   15.0|   251.5|
| 2721|   15.0|   251.5|
| 2722|   15.0|   251.6|
| 2723|   15.0|   251.6|
| 2724|   15.0|   251.6|
| 2725|   15.0|   251.7|
| 2726|   15.0|   251.7|
| 2727|   15.0|   251.7|
| 2728|   15.0|   251.8|
| 2729|   15.0|   251.8|
| 2730|   15.0|   251.8|
| 2731|   15.0|   251.9|
| 2732|   15.0|   251.9|
| 2733|   15.0|   251.9|
| 2734|   15.0|   252.0|
| 2735|   15.0|   252.0|
| 2736|   15.0|   252.0|
| 2737|   15.0|   252.1|
| 2738|   15.0|   252.1|
| 2739|   15.0|   252.1|
| 2740|   15.0|   252.2|
| 2741|   15.0|   252.2|
| 2742|   15.0|   252.2|
| 2743|   15.0|   252.3|
| 2744|   15.0|   252.3|
| 2745|   15.0|   252.3|
| 2746|   15.0|   252.4|
| 2747|   15.0|   252.4|
| 2748|   15.0|   252.5|
| 2749|   15.0|   252.5|
| 2750|   15.0|   252.5|
| 2751|   15.0|   252.6|
| 2752|   15.0|   252.6|
| 2753|   15.0|   252.6|
| 2754|   15.0|   252.7|
| 2755|   15.0|   252.7|
| 2756|   15.0|   252.7|
| 2757|   15.0|   252.8|
| 2758|   15.0|   252.8|
| 2759|   15.0|   252.8|
| 2760|   15.0|   252.9|
| 2761|   15.0|   252.9|
| 2762|   15.0|   252.9|
| 2763|   15.0|   253.0|
| 2764|   15.0|   253.0|
| 2765|   15.0|   253.0|
| 2766|   15.0|   253.1|
| 2767|   15.0|   253.1|
| 2768|   15.0|   253.1|
| 2769|   15.0|   253.2|
| 2770|   15.0|   253.2|
| 2771|   15.0|   253.2|
| 2772|   15.0|   253.3|
| 2773|   15.0|   253.3|
| 2774|   15.0|   253.3|
| 2775|   15.0|   253.4|
| 2776|   15.0|   253.4|
| 2777|   15.0|   253.5|
| 2778|   15.0|   253.5|
| 2779|   15.0|   253.5|
| 2780|   15.0|   253.6|
| 2781|   15.0|   253.6|
| 2782|   15.0|   253.6|
| 2783|   15.0|   253.7|
| 2784|   15.0|   253.7|
| 2785|   15.0|   253.7|
| 2786|   15.0|   253.8|
| 2787|   15.0|   253.8|
| 2788|   15.0|   253.8|
| 2789|   15.0|   253.9|
| 2790|   15.0|   253.9|
| 2791|   15.0|   253.9|
| 2792|   15.0|   254.0|
| 2793|   15.0|   254.0|
| 2794|   15.0|   254.0|
| 2795|   15.0|   254.1|
| 2796|   15.0|   254.1|
| 2797|   15.0|   254.1|
| 2798|   15.0|   254.2|
| 2799|   15.0|   254.2|
| 2800|   15.0|   254.2|
| 2801|   15.0|   254.3|
| 2802|   15.0|   254.3|
| 2803|   15.0|   254.3|
| 2804|   15.0|   254.4|
| 2805|   15.0|   254.4|
| 2806|   15.0|   254.4|
| 2807|   15.0|   254.5|
| 2808|   15.0|   254.5|
| 2809|   15.0|   254.5|
| 2810|   15.0|   254.6|
| 2811|   15.0|   254.6|
| 2812|   15.0|   254.6|
| 2813|   15.0|   254.7|
| 2814|   15.0|   254.7|
| 2815|   15.0|   254.8|
| 2816|   15.0|   254.8|
| 2817|   15.0|   254.8|
| 2818|   15.0|   254.9|
| 2819|   15.0|   254.9|
| 2820|   15.0|   254.9|
| 2821|   15.0|   255.0|
| 2822|   15.0|   255.0|
| 2823|   15.0|   255.0|
| 2824|   15.0|   255.1|
| 2825|   15.0|   255.1|
| 2826|   15.0|   255.1|
| 2827|   15.0|   255.2|
| 2828|   15.0|   255.2|
| 2829|   15.0|   255.2|
| 2830|   15.0|   255.3|
| 2831|   15.0|   255.3|
| 2832|   15.0|   255.3|
| 2833|   15.0|   255.4|
| 2834|   15.0|   255.4|
| 2835|   15.0|   255.4|
| 2836|   15.0|   255.5|
| 2837|   15.0|   255.5|
| 2838|   15.0|   255.5|
| 2839|   15.0|   255.6|
| 2840|   15.0|   255.6|
| 2841|   15.0|   255.6|
| 2842|   15.0|   255.7|
| 2843|   15.0|   255.7|
| 2844|   15.0|   255.7|
| 2845|   15.0|   255.8|
| 2846|   15.0|   255.8|
| 2847|   15.0|   255.8|
| 2848|   15.0|   255.9|
| 2849|   15.0|   255.9|
| 2850|   15.0|   255.9|
| 2851|   15.0|   256.0|
| 2852|   15.0|   256.0|
| 2853|   15.0|   256.0|
| 2854|   15.0|   256.1|
| 2855|   15.0|   256.1|
| 2856|   15.0|   256.1|
| 2857|   15.0|   256.2|
| 2858|   15.0|   256.2|
| 2859|   15.0|   256.2|
| 2860|   15.0|   256.3|
| 2861|   15.0|   256.3|
| 2862|   15.0|   256.3|
| 2863|   15.0|   256.4|
| 2864|   15.0|   256.4|
| 2865|   15.0|   256.4|
| 2866|   15.0|   256.5|
| 2867|   15.0|   256.5|
| 2868|   15.0|   256.5|
| 2869|   15.0|   256.6|
| 2870|   15.0|   256.6|
| 2871|   15.0|   256.6|
| 2872|   15.0|   256.7|
| 2873|   15.0|   256.7|
| 2874|   15.0|   256.7|
| 2875|   15.0|   256.8|
| 2876|   15.0|   256.8|
| 2877|   15.0|   256.8|
| 2878|   15.0|   256.9|
| 2879|   15.0|   256.9|
| 2880|   15.0|   257.0|
| 2881|   15.0|   257.0|
| 2882|   15.0|   257.0|
| 2883|   15.0|   257.1|
| 2884|   15.0|   257.1|
| 2885|   15.0|   257.1|
| 2886|   15.0|   257.2|
| 2887|   15.0|   257.2|
| 2888|   15.0|   257.2|
| 2889|   15.0|   257.3|
| 2890|   15.0|   257.3|
| 2891|   15.0|   257.3|
| 2892|   15.0|   257.4|
| 2893|   15.0|   257.4|
| 2894|   15.0|   257.4|
| 2895|   15.0|   257.5|
| 2896|   15.0|   257.5|
| 2897|   15.0|   257.5|
| 2898|   15.0|   257.6|
| 2899|   15.0|   257.6|
| 2900|   15.0|   257.6|
| 2901|   15.0|   257.7|
| 2902|   15.0|   257.7|
| 2903|   15.0|   257.7|
| 2904|   15.0|   257.8|
| 2905|   15.0|   257.8|
| 2906|   15.0|   257.8|
| 2907|   15.0|   257.9|
| 2908|   15.0|   257.9|
| 2909|   15.0|   257.9|
| 2910|   15.0|   258.0|
| 2911|   15.0|   258.0|
| 2912|   15.0|   258.0|
| 2913|   15.0|   258.1|
| 2914|   15.0|   258.1|
| 2915|   15.0|   258.1|
| 2916|   15.0|   258.2|
| 2917|   15.0|   258.2|
| 2918|   15.0|   258.2|
| 2919|   15.0|   258.3|
| 2920|   15.0|   258.3|
| 2921|   15.0|   258.3|
| 2922|   15.0|   258.4|
| 2923|   15.0|   258.4|
| 2924|   15.0|   258.4|
| 2925|   15.0|   258.5|
| 2926|   15.0|   258.5|
| 2927|   15.0|   258.5|
| 2928|   15.0|   258.6|
| 2929|   15.0|   258.6|
| 2930|   15.0|   258.6|
| 2931|   15.0|   258.7|
| 2932|   15.0|   258.7|
| 2933|   15.0|   258.7|
| 2934|   15.0|   258.8|
| 2935|   15.0|   258.8|
| 2936|   15.0|   258.8|
| 2937|   15.0|   258.9|
| 2938|   15.0|   258.9|
| 2939|   15.0|   258.9|
| 2940|   15.0|   259.0|
| 2941|   15.0|   259.0|
| 2942|   15.0|   259.0|
| 2943|   15.0|   259.1|
| 2944|   15.0|   259.1|
| 2945|   15.0|   259.1|
| 2946|   15.0|   259.2|
| 2947|   15.0|   259.2|
| 2948|   15.0|   259.2|
| 2949|   15.0|   259.3|
| 2950|   15.0|   259.3|
| 2951|   15.0|   259.3|
| 2952|   15.0|   259.4|
| 2953|   15.0|   259.4|
| 2954|   15.0|   259.4|
| 2955|   15.0|   259.5|
| 2956|   15.0|   259.5|
| 2957|   15.0|   259.5|
| 2958|   15.0|   259.6|
| 2959|   15.0|   259.6|
| 2960|   15.0|   259.6|
| 2961|   15.0|   259.7|
| 2962|   15.0|   259.7|
| 2963|   15.0|   259.7|
| 2964|   15.0|   259.7|
| 2965|   15.0|   259.8|
| 2966|   15.0|   259.8|
| 2967|   15.0|   259.8|
| 2968|   15.0|   259.9|
| 2969|   15.0|   259.9|
| 2970|   15.0|   259.9|
| 2971|   15.0|   260.0|
| 2972|   15.0|   260.0|
| 2973|   15.0|   260.0|
| 2974|   15.0|   260.1|
| 2975|   15.0|   260.1|
| 2976|   15.0|   260.1|
| 2977|   15.0|   260.2|
| 2978|   15.0|   260.2|
| 2979|   15.0|   260.2|
| 2980|   15.0|   260.3|
| 2981|   15.0|   260.3|
| 2982|   15.0|   260.3|
| 2983|   15.0|   260.4|
| 2984|   15.0|   260.4|
| 2985|   15.0|   260.4|
| 2986|   15.0|   260.5|
| 2987|   15.0|   260.5|
| 2988|   15.0|   260.5|
| 2989|   15.0|   260.6|
| 2990|   15.0|   260.6|
| 2991|   15.0|   260.6|
| 2992|   15.0|   260.7|
| 2993|   15.0|   260.7|
| 2994|   15.0|   260.7|
| 2995|   15.0|   260.8|
| 2996|   15.0|   260.8|
| 2997|   15.0|   260.8|
| 2998|   15.0|   260.9|
| 2999|   15.0|   260.9|
| 3000|   15.0|   260.9|
| 3001|   15.0|   261.0|
| 3002|   15.0|   261.0|
| 3003|   15.0|   261.0|
| 3004|   15.0|   261.1|
| 3005|   15.0|   261.1|
| 3006|   15.0|   261.1|
| 3007|   15.0|   261.2|
| 3008|   15.0|   261.2|
| 3009|   15.0|   261.2|
| 3010|   15.0|   261.3|
| 3011|   15.0|   261.3|
| 3012|   15.0|   261.3|
| 3013|   15.0|   261.4|
| 3014|   15.0|   261.4|
| 3015|   15.0|   261.4|
| 3016|   15.0|   261.5|
| 3017|   15.0|   261.5|
| 3018|   15.0|   261.5|
| 3019|   15.0|   261.6|
| 3020|   15.0|   261.6|
| 3021|   15.0|   261.6|
| 3022|   15.0|   261.7|
| 3023|   15.0|   261.7|
| 3024|   15.0|   261.7|
| 3025|   15.0|   261.8|
| 3026|   15.0|   261.8|
| 3027|   15.0|   261.8|
| 3028|   15.0|   261.9|
| 3029|   15.0|   261.9|
| 3030|   15.0|   261.9|
| 3031|   15.0|   261.9|
| 3032|   15.0|   262.0|
| 3033|   15.0|   262.0|
| 3034|   15.0|   262.0|
| 3035|   15.0|   262.1|
| 3036|   15.0|   262.1|
| 3037|   15.0|   262.1|
| 3038|   15.0|   262.2|
| 3039|   15.0|   262.2|
| 3040|   15.0|   262.2|
| 3041|   15.0|   262.3|
| 3042|   15.0|   262.3|
| 3043|   15.0|   262.3|
| 3044|   15.0|   262.4|
| 3045|   15.0|   262.4|
| 3046|   15.0|   262.4|
| 3047|   15.0|   262.5|
| 3048|   15.0|   262.5|
| 3049|   15.0|   262.5|
| 3050|   15.0|   262.6|
| 3051|   15.0|   262.6|
| 3052|   15.0|   262.6|
| 3053|   15.0|   262.7|
| 3054|   15.0|   262.7|
| 3055|   15.0|   262.7|
| 3056|   15.0|   262.8|
| 3057|   15.0|   262.8|
| 3058|   15.0|   262.8|
| 3059|   15.0|   262.9|
| 3060|   15.0|   262.9|
| 3061|   15.0|   262.9|
| 3062|   15.0|   263.0|
| 3063|   15.0|   263.0|
| 3064|   15.0|   263.0|
| 3065|   15.0|   263.1|
| 3066|   15.0|   263.1|
| 3067|   15.0|   263.1|
| 3068|   15.0|   263.1|
| 3069|   15.0|   263.2|
| 3070|   15.0|   263.2|
| 3071|   15.0|   263.2|
| 3072|   15.0|   263.3|
| 3073|   15.0|   263.3|
| 3074|   15.0|   263.3|
| 3075|   15.0|   263.4|
| 3076|   15.0|   263.4|
| 3077|   15.0|   263.4|
| 3078|   15.0|   263.5|
| 3079|   15.0|   263.5|
| 3080|   15.0|   263.5|
| 3081|   15.0|   263.6|
| 3082|   15.0|   263.6|
| 3083|   15.0|   263.6|
| 3084|   15.0|   263.7|
| 3085|   15.0|   263.7|
| 3086|   15.0|   263.7|
| 3087|   15.0|   263.8|
| 3088|   15.0|   263.8|
| 3089|   15.0|   263.8|
| 3090|   15.0|   263.9|
| 3091|   15.0|   263.9|
| 3092|   15.0|   263.9|
| 3093|   15.0|   264.0|
| 3094|   15.0|   264.0|
| 3095|   15.0|   264.0|
| 3096|   15.0|   264.1|
| 3097|   15.0|   264.1|
| 3098|   15.0|   264.1|
| 3099|   15.0|   264.1|
| 3100|   15.0|   264.2|
| 3101|   15.0|   264.2|
| 3102|   15.0|   264.2|
| 3103|   15.0|   264.3|
| 3104|   15.0|   264.3|
| 3105|   15.0|   264.3|
| 3106|   15.0|   264.4|
| 3107|   15.0|   264.4|
| 3108|   15.0|   264.4|
| 3109|   15.0|   264.5|
| 3110|   15.0|   264.5|
| 3111|   15.0|   264.5|
| 3112|   15.0|   264.6|
| 3113|   15.0|   264.6|
| 3114|   15.0|   264.6|
| 3115|   15.0|   264.7|
| 3116|   15.0|   264.7|
| 3117|   15.0|   264.7|
| 3118|   15.0|   264.8|
| 3119|   15.0|   264.8|
| 3120|   15.0|   264.8|
| 3121|   15.0|   264.9|
| 3122|   15.0|   264.9|
| 3123|   15.0|   264.9|
| 3124|   15.0|   265.0|
| 3125|   15.0|   265.0|
| 3126|   15.0|   265.0|
| 3127|   15.0|   265.0|
| 3128|   15.0|   265.1|
| 3129|   15.0|   265.1|
| 3130|   15.0|   265.1|
| 3131|   15.0|   265.2|
| 3132|   15.0|   265.2|
| 3133|   15.0|   265.2|
| 3134|   15.0|   265.3|
| 3135|   15.0|   265.3|
| 3136|   15.0|   265.3|
| 3137|   15.0|   265.4|
| 3138|   15.0|   265.4|
| 3139|   15.0|   265.4|
| 3140|   15.0|   265.5|
| 3141|   15.0|   265.5|
| 3142|   15.0|   265.5|
| 3143|   15.0|   265.6|
| 3144|   15.0|   265.6|
| 3145|   15.0|   265.6|
| 3146|   15.0|   265.7|
| 3147|   15.0|   265.7|
| 3148|   15.0|   265.7|
| 3149|   15.0|   265.8|
| 3150|   15.0|   265.8|
| 3151|   15.0|   265.8|
| 3152|   15.0|   265.8|
| 3153|   15.0|   265.9|
| 3154|   15.0|   265.9|
| 3155|   15.0|   265.9|
| 3156|   15.0|   266.0|
| 3157|   15.0|   266.0|
| 3158|   15.0|   266.0|
| 3159|   15.0|   266.1|
| 3160|   15.0|   266.1|
| 3161|   15.0|   266.1|
| 3162|   15.0|   266.2|
| 3163|   15.0|   266.2|
| 3164|   15.0|   266.2|
| 3165|   15.0|   266.3|
| 3166|   15.0|   266.3|
| 3167|   15.0|   266.3|
| 3168|   15.0|   266.4|
| 3169|   15.0|   266.4|
| 3170|   15.0|   266.4|
| 3171|   15.0|   266.4|
| 3172|   15.0|   266.5|
| 3173|   15.0|   266.5|
| 3174|   15.0|   266.5|
| 3175|   15.0|   266.6|
| 3176|   15.0|   266.6|
| 3177|   15.0|   266.6|
| 3178|   15.0|   266.7|
| 3179|   15.0|   266.7|
| 3180|   15.0|   266.7|
| 3181|   15.0|   266.8|
| 3182|   15.0|   266.8|
| 3183|   15.0|   266.8|
| 3184|   15.0|   266.9|
| 3185|   15.0|   266.9|
| 3186|   15.0|   266.9|
| 3187|   15.0|   267.0|
| 3188|   15.0|   267.0|
| 3189|   15.0|   267.0|
| 3190|   15.0|   267.1|
| 3191|   15.0|   267.1|
| 3192|   15.0|   267.1|
| 3193|   15.0|   267.1|
| 3194|   15.0|   267.2|
| 3195|   15.0|   267.2|
| 3196|   15.0|   267.2|
| 3197|   15.0|   267.3|
| 3198|   15.0|   267.3|
| 3199|   15.0|   267.3|
| 3200|   15.0|   267.4|
| 3201|   15.0|   267.4|
| 3202|   15.0|   267.4|
| 3203|   15.0|   267.5|
| 3204|   15.0|   267.5|
| 3205|   15.0|   267.5|
| 3206|   15.0|   267.6|
| 3207|   15.0|   267.6|
| 3208|   15.0|   267.6|
| 3209|   15.0|   267.7|
| 3210|   15.0|   267.7|
| 3211|   15.0|   267.7|
| 3212|   15.0|   267.7|
| 3213|   15.0|   267.8|
| 3214|   15.0|   267.8|
| 3215|   15.0|   267.8|
| 3216|   15.0|   267.9|
| 3217|   15.0|   267.9|
| 3218|   15.0|   267.9|
| 3219|   15.0|   268.0|
| 3220|   15.0|   268.0|
| 3221|   15.0|   268.0|
| 3222|   15.0|   268.1|
| 3223|   15.0|   268.1|
| 3224|   15.0|   268.1|
| 3225|   15.0|   268.2|
| 3226|   15.0|   268.2|
| 3227|   15.0|   268.2|
| 3228|   15.0|   268.2|
| 3229|   15.0|   268.3|
| 3230|   15.0|   268.3|
| 3231|   15.0|   268.3|
| 3232|   15.0|   268.4|
| 3233|   15.0|   268.4|
| 3234|   15.0|   268.4|
| 3235|   15.0|   268.5|
| 3236|   15.0|   268.5|
| 3237|   15.0|   268.5|
| 3238|   15.0|   268.6|
| 3239|   15.0|   268.6|
| 3240|   15.0|   268.6|
| 3241|   15.0|   268.7|
| 3242|   15.0|   268.7|
| 3243|   15.0|   268.7|
| 3244|   15.0|   268.7|
| 3245|   15.0|   268.8|
| 3246|   15.0|   268.8|
| 3247|   15.0|   268.8|
| 3248|   15.0|   268.9|
| 3249|   15.0|   268.9|
| 3250|   15.0|   268.9|
| 3251|   15.0|   269.0|
| 3252|   15.0|   269.0|
| 3253|   15.0|   269.0|
| 3254|   15.0|   269.1|
| 3255|   15.0|   269.1|
| 3256|   15.0|   269.1|
| 3257|   15.0|   269.2|
| 3258|   15.0|   269.2|
| 3259|   15.0|   269.2|
| 3260|   15.0|   269.2|
| 3261|   15.0|   269.3|
| 3262|   15.0|   269.3|
| 3263|   15.0|   269.3|
| 3264|   15.0|   269.4|
| 3265|   15.0|   269.4|
| 3266|   15.0|   269.4|
| 3267|   15.0|   269.5|
| 3268|   15.0|   269.5|
| 3269|   15.0|   269.5|
| 3270|   15.0|   269.6|
| 3271|   15.0|   269.6|
| 3272|   15.0|   269.6|
| 3273|   15.0|   269.7|
| 3274|   15.0|   269.7|
| 3275|   15.0|   269.7|
| 3276|   15.0|   269.7|
| 3277|   15.0|   269.8|
| 3278|   15.0|   269.8|
| 3279|   15.0|   269.8|
| 3280|   15.0|   269.9|
| 3281|   15.0|   269.9|
| 3282|   15.0|   269.9|
| 3283|   15.0|   270.0|
| 3284|   15.0|   270.0|
| 3285|   15.0|   270.0|
| 3286|   15.0|   270.1|
| 3287|   15.0|   270.1|
| 3288|   15.0|   270.1|
| 3289|   15.0|   270.2|
| 3290|   15.0|   270.2|
| 3291|   15.0|   270.2|
| 3292|   15.0|   270.2|
| 3293|   15.0|   270.3|
| 3294|   15.0|   270.3|
| 3295|   15.0|   270.3|
| 3296|   15.0|   270.4|
| 3297|   15.0|   270.4|
| 3298|   15.0|   270.4|
| 3299|   15.0|   270.5|
| 3300|   15.0|   270.5|
| 3301|   15.0|   270.5|
| 3302|   15.0|   270.6|
| 3303|   15.0|   270.6|
| 3304|   15.0|   270.6|
| 3305|   15.0|   270.6|
| 3306|   15.0|   270.7|
| 3307|   15.0|   270.7|
| 3308|   15.0|   270.7|
| 3309|   15.0|   270.8|
| 3310|   15.0|   270.8|
| 3311|   15.0|   270.8|
| 3312|   15.0|   270.9|
| 3313|   15.0|   270.9|
| 3314|   15.0|   270.9|
| 3315|   15.0|   271.0|
| 3316|   15.0|   271.0|
| 3317|   15.0|   271.0|
| 3318|   15.0|   271.0|
| 3319|   15.0|   271.1|
| 3320|   15.0|   271.1|
| 3321|   15.0|   271.1|
| 3322|   15.0|   271.2|
| 3323|   15.0|   271.2|
| 3324|   15.0|   271.2|
| 3325|   15.0|   271.3|
| 3326|   15.0|   271.3|
| 3327|   15.0|   271.3|
| 3328|   15.0|   271.4|
| 3329|   15.0|   271.4|
| 3330|   15.0|   271.4|
| 3331|   15.0|   271.5|
| 3332|   15.0|   271.5|
| 3333|   15.0|   271.5|
| 3334|   15.0|   271.5|
| 3335|   15.0|   271.6|
| 3336|   15.0|   271.6|
| 3337|   15.0|   271.6|
| 3338|   15.0|   271.7|
| 3339|   15.0|   271.7|
| 3340|   15.0|   271.7|
| 3341|   15.0|   271.8|
| 3342|   15.0|   271.8|
| 3343|   15.0|   271.8|
| 3344|   15.0|   271.9|
| 3345|   15.0|   271.9|
| 3346|   15.0|   271.9|
| 3347|   15.0|   271.9|
| 3348|   15.0|   272.0|
| 3349|   15.0|   272.0|
| 3350|   15.0|   272.0|
| 3351|   15.0|   272.1|
| 3352|   15.0|   272.1|
| 3353|   15.0|   272.1|
| 3354|   15.0|   272.2|
| 3355|   15.0|   272.2|
| 3356|   15.0|   272.2|
| 3357|   15.0|   272.2|
| 3358|   15.0|   272.3|
| 3359|   15.0|   272.3|
| 3360|   15.0|   272.3|
| 3361|   15.0|   272.4|
| 3362|   15.0|   272.4|
| 3363|   15.0|   272.4|
| 3364|   15.0|   272.5|
| 3365|   15.0|   272.5|
| 3366|   15.0|   272.5|
| 3367|   15.0|   272.6|
| 3368|   15.0|   272.6|
| 3369|   15.0|   272.6|
| 3370|   15.0|   272.6|
| 3371|   15.0|   272.7|
| 3372|   15.0|   272.7|
| 3373|   15.0|   272.7|
| 3374|   15.0|   272.8|
| 3375|   15.0|   272.8|
| 3376|   15.0|   272.8|
| 3377|   15.0|   272.9|
| 3378|   15.0|   272.9|
| 3379|   15.0|   272.9|
| 3380|   15.0|   273.0|
| 3381|   15.0|   273.0|
| 3382|   15.0|   273.0|
| 3383|   15.0|   273.0|
| 3384|   15.0|   273.1|
| 3385|   15.0|   273.1|
| 3386|   15.0|   273.1|
| 3387|   15.0|   273.2|
| 3388|   15.0|   273.2|
| 3389|   15.0|   273.2|
| 3390|   15.0|   273.3|
| 3391|   15.0|   273.3|
| 3392|   15.0|   273.3|
| 3393|   15.0|   273.3|
| 3394|   15.0|   273.4|
| 3395|   15.0|   273.4|
| 3396|   15.0|   273.4|
| 3397|   15.0|   273.5|
| 3398|   15.0|   273.5|
| 3399|   15.0|   273.5|
| 3400|   15.0|   273.6|
| 3401|   15.0|   273.6|
| 3402|   15.0|   273.6|
| 3403|   15.0|   273.7|
| 3404|   15.0|   273.7|
| 3405|   15.0|   273.7|
| 3406|   15.0|   273.7|
| 3407|   15.0|   273.8|
| 3408|   15.0|   273.8|
| 3409|   15.0|   273.8|
| 3410|   15.0|   273.9|
| 3411|   15.0|   273.9|
| 3412|   15.0|   273.9|
| 3413|   15.0|   274.0|
| 3414|   15.0|   274.0|
| 3415|   15.0|   274.0|
| 3416|   15.0|   274.0|
| 3417|   15.0|   274.1|
| 3418|   15.0|   274.1|
| 3419|   15.0|   274.1|
| 3420|   15.0|   274.2|
| 3421|   15.0|   274.2|
| 3422|   15.0|   274.2|
| 3423|   15.0|   274.3|
| 3424|   15.0|   274.3|
| 3425|   15.0|   274.3|
| 3426|   15.0|   274.4|
| 3427|   15.0|   274.4|
| 3428|   15.0|   274.4|
| 3429|   15.0|   274.4|
| 3430|   15.0|   274.5|
| 3431|   15.0|   274.5|
| 3432|   15.0|   274.5|
| 3433|   15.0|   274.6|
| 3434|   15.0|   274.6|
| 3435|   15.0|   274.6|
| 3436|   15.0|   274.7|
| 3437|   15.0|   274.7|
| 3438|   15.0|   274.7|
| 3439|   15.0|   274.7|
| 3440|   15.0|   274.8|
| 3441|   15.0|   274.8|
| 3442|   15.0|   274.8|
| 3443|   15.0|   274.9|
| 3444|   15.0|   274.9|
| 3445|   15.0|   274.9|
| 3446|   15.0|   275.0|
| 3447|   15.0|   275.0|
| 3448|   15.0|   275.0|
| 3449|   15.0|   275.0|
| 3450|   15.0|   275.1|
| 3451|   15.0|   275.1|
| 3452|   15.0|   275.1|
| 3453|   15.0|   275.2|
| 3454|   15.0|   275.2|
| 3455|   15.0|   275.2|
| 3456|   15.0|   275.3|
| 3457|   15.0|   275.3|
| 3458|   15.0|   275.3|
| 3459|   15.0|   275.3|
| 3460|   15.0|   275.4|
| 3461|   15.0|   275.4|
| 3462|   15.0|   275.4|
| 3463|   15.0|   275.5|
| 3464|   15.0|   275.5|
| 3465|   15.0|   275.5|
| 3466|   15.0|   275.6|
| 3467|   15.0|   275.6|
| 3468|   15.0|   275.6|
| 3469|   15.0|   275.6|
| 3470|   15.0|   275.7|
| 3471|   15.0|   275.7|
| 3472|   15.0|   275.7|
| 3473|   15.0|   275.8|
| 3474|   15.0|   275.8|
| 3475|   15.0|   275.8|
| 3476|   15.0|   275.9|
| 3477|   15.0|   275.9|
| 3478|   15.0|   275.9|
| 3479|   15.0|   275.9|
| 3480|   15.0|   276.0|
| 3481|   15.0|   276.0|
| 3482|   15.0|   276.0|
| 3483|   15.0|   276.1|
| 3484|   15.0|   276.1|
| 3485|   15.0|   276.1|
| 3486|   15.0|   276.2|
| 3487|   15.0|   276.2|
| 3488|   15.0|   276.2|
| 3489|   15.0|   276.2|
| 3490|   15.0|   276.3|
| 3491|   15.0|   276.3|
| 3492|   15.0|   276.3|
| 3493|   15.0|   276.4|
| 3494|   15.0|   276.4|
| 3495|   15.0|   276.4|
| 3496|   15.0|   276.5|
| 3497|   15.0|   276.5|
| 3498|   15.0|   276.5|
| 3499|   15.0|   276.5|
| 3500|   15.0|   276.6|
| 3501|   15.0|   276.6|
| 3502|   15.0|   276.6|
| 3503|   15.0|   276.7|
| 3504|   15.0|   276.7|
| 3505|   15.0|   276.7|
| 3506|   15.0|   276.8|
| 3507|   15.0|   276.8|
| 3508|   15.0|   276.8|
| 3509|   15.0|   276.8|
| 3510|   15.0|   276.9|
| 3511|   15.0|   276.9|
| 3512|   15.0|   276.9|
| 3513|   15.0|   277.0|
| 3514|   15.0|   277.0|
| 3515|   15.0|   277.0|
| 3516|   15.0|   277.1|
| 3517|   15.0|   277.1|
| 3518|   15.0|   277.1|
| 3519|   15.0|   277.1|
| 3520|   15.0|   277.2|
| 3521|   15.0|   277.2|
| 3522|   15.0|   277.2|
| 3523|   15.0|   277.3|
| 3524|   15.0|   277.3|
| 3525|   15.0|   277.3|
| 3526|   15.0|   277.4|
| 3527|   15.0|   277.4|
| 3528|   15.0|   277.4|
| 3529|   15.0|   277.4|
| 3530|   15.0|   277.5|
| 3531|   15.0|   277.5|
| 3532|   15.0|   277.5|
| 3533|   15.0|   277.6|
| 3534|   15.0|   277.6|
| 3535|   15.0|   277.6|
| 3536|   15.0|   277.7|
| 3537|   15.0|   277.7|
| 3538|   15.0|   277.7|
| 3539|   15.0|   277.7|
| 3540|   15.0|   277.8|
| 3541|   15.0|   277.8|
| 3542|   15.0|   277.8|
| 3543|   15.0|   277.9|
| 3544|   15.0|   277.9|
| 3545|   15.0|   277.9|
| 3546|   15.0|   277.9|
| 3547|   15.0|   278.0|
| 3548|   15.0|   278.0|
| 3549|   15.0|   278.0|
| 3550|   15.0|   278.1|
| 3551|   15.0|   278.1|
| 3552|   15.0|   278.1|
| 3553|   15.0|   278.2|
| 3554|   15.0|   278.2|
| 3555|   15.0|   278.2|
| 3556|   15.0|   278.2|
| 3557|   15.0|   278.3|
| 3558|   15.0|   278.3|
| 3559|   15.0|   278.3|
| 3560|   15.0|   278.4|
| 3561|   15.0|   278.4|
| 3562|   15.0|   278.4|
| 3563|   15.0|   278.5|
| 3564|   15.0|   278.5|
| 3565|   15.0|   278.5|
| 3566|   15.0|   278.5|
| 3567|   15.0|   278.6|
| 3568|   15.0|   278.6|
| 3569|   15.0|   278.6|
| 3570|   15.0|   278.7|
| 3571|   15.0|   278.7|
| 3572|   15.0|   278.7|
| 3573|   15.0|   278.7|
| 3574|   15.0|   278.8|
| 3575|   15.0|   278.8|
| 3576|   15.0|   278.8|
| 3577|   15.0|   278.9|
| 3578|   15.0|   278.9|
| 3579|   15.0|   278.9|
| 3580|   15.0|   279.0|
| 3581|   15.0|   279.0|
| 3582|   15.0|   279.0|
| 3583|   15.0|   279.0|
| 3584|   15.0|   279.1|
| 3585|   15.0|   279.1|
| 3586|   15.0|   279.1|
| 3587|   15.0|   279.2|
| 3588|   15.0|   279.2|
| 3589|   15.0|   279.2|
| 3590|   15.0|   279.2|
| 3591|   15.0|   279.3|
| 3592|   15.0|   279.3|
| 3593|   15.0|   279.3|
| 3594|   15.0|   279.4|
| 3595|   15.0|   279.4|
| 3596|   15.0|   279.4|
| 3597|   15.0|   279.5|
| 3598|   15.0|   279.5|
| 3599|   15.0|   279.5|
| 3600|   15.0|   279.5|
| 3601|   15.0|   279.6|
| 3602|   15.0|   279.6|
| 3603|   15.0|   279.6|
| 3604|   15.0|   279.7|
| 3605|   15.0|   279.7|
| 3606|   15.0|   279.7|
| 3607|   15.0|   279.7|
| 3608|   15.0|   279.8|
| 3609|   15.0|   279.8|
| 3610|   15.0|   279.8|
| 3611|   15.0|   279.9|
| 3612|   15.0|   279.9|
| 3613|   15.0|   279.9|
| 3614|   15.0|   280.0|
| 3615|   15.0|   280.0|
| 3616|   15.0|   280.0|
| 3617|   15.0|   280.0|
| 3618|   15.0|   280.1|
| 3619|   15.0|   280.1|
| 3620|   15.0|   280.1|
| 3621|   15.0|   280.2|
| 3622|   15.0|   280.2|
| 3623|   15.0|   280.2|
| 3624|   15.0|   280.2|
| 3625|   15.0|   280.3|
| 3626|   15.0|   280.3|
| 3627|   15.0|   280.3|
| 3628|   15.0|   280.4|
| 3629|   15.0|   280.4|
| 3630|   15.0|   280.4|
| 3631|   15.0|   280.5|
| 3632|   15.0|   280.5|
| 3633|   15.0|   280.5|
| 3634|   15.0|   280.5|
| 3635|   15.0|   280.6|
| 3636|   15.0|   280.6|
| 3637|   15.0|   280.6|
| 3638|   15.0|   280.7|
| 3639|   15.0|   280.7|
| 3640|   15.0|   280.7|
| 3641|   15.0|   280.7|
| 3642|   15.0|   280.8|
| 3643|   15.0|   280.8|
| 3644|   15.0|   280.8|
| 3645|   15.0|   280.9|
| 3646|   15.0|   280.9|
| 3647|   15.0|   280.9|
| 3648|   15.0|   280.9|
| 3649|   15.0|   281.0|
| 3650|   15.0|   281.0|
| 3651|   15.0|   281.0|
| 3652|   15.0|   281.1|
| 3653|   15.0|   281.1|
| 3654|   15.0|   281.1|
| 3655|   15.0|   281.2|
| 3656|   15.0|   281.2|
| 3657|   15.0|   281.2|
| 3658|   15.0|   281.2|
| 3659|   15.0|   281.3|
| 3660|   15.0|   281.3|
| 3661|   15.0|   281.3|
| 3662|   15.0|   281.4|
| 3663|   15.0|   281.4|
| 3664|   15.0|   281.4|
| 3665|   15.0|   281.4|
| 3666|   15.0|   281.5|
| 3667|   15.0|   281.5|
| 3668|   15.0|   281.5|
| 3669|   15.0|   281.6|
| 3670|   15.0|   281.6|
| 3671|   15.0|   281.6|
| 3672|   15.0|   281.6|
| 3673|   15.0|   281.7|
| 3674|   15.0|   281.7|
| 3675|   15.0|   281.7|
| 3676|   15.0|   281.8|
| 3677|   15.0|   281.8|
| 3678|   15.0|   281.8|
| 3679|   15.0|   281.9|
| 3680|   15.0|   281.9|
| 3681|   15.0|   281.9|
| 3682|   15.0|   281.9|
| 3683|   15.0|   282.0|
| 3684|   15.0|   282.0|
| 3685|   15.0|   282.0|
| 3686|   15.0|   282.1|
| 3687|   15.0|   282.1|
| 3688|   15.0|   282.1|
| 3689|   15.0|   282.1|
| 3690|   15.0|   282.2|
| 3691|   15.0|   282.2|
| 3692|   15.0|   282.2|
| 3693|   15.0|   282.3|
| 3694|   15.0|   282.3|
| 3695|   15.0|   282.3|
| 3696|   15.0|   282.3|
| 3697|   15.0|   282.4|
| 3698|   15.0|   282.4|
| 3699|   15.0|   282.4|
| 3700|   15.0|   282.5|
| 3701|   15.0|   282.5|
| 3702|   15.0|   282.5|
| 3703|   15.0|   282.5|
| 3704|   15.0|   282.6|
| 3705|   15.0|   282.6|
| 3706|   15.0|   282.6|
| 3707|   15.0|   282.7|
| 3708|   15.0|   282.7|
| 3709|   15.0|   282.7|
| 3710|   15.0|   282.7|
| 3711|   15.0|   282.8|
| 3712|   15.0|   282.8|
| 3713|   15.0|   282.8|
| 3714|   15.0|   282.9|
| 3715|   15.0|   282.9|
| 3716|   15.0|   282.9|
| 3717|   15.0|   282.9|
| 3718|   15.0|   283.0|
| 3719|   15.0|   283.0|
| 3720|   15.0|   283.0|
| 3721|   15.0|   283.1|
| 3722|   15.0|   283.1|
| 3723|   15.0|   283.1|
| 3724|   15.0|   283.2|
| 3725|   15.0|   283.2|
| 3726|   15.0|   283.2|
| 3727|   15.0|   283.2|
| 3728|   15.0|   283.3|
| 3729|   15.0|   283.3|
| 3730|   15.0|   283.3|
| 3731|   15.0|   283.4|
| 3732|   15.0|   283.4|
| 3733|   15.0|   283.4|
| 3734|   15.0|   283.4|
| 3735|   15.0|   283.5|
| 3736|   15.0|   283.5|
| 3737|   15.0|   283.5|
| 3738|   15.0|   283.6|
| 3739|   15.0|   283.6|
| 3740|   15.0|   283.6|
| 3741|   15.0|   283.6|
| 3742|   15.0|   283.7|
| 3743|   15.0|   283.7|
| 3744|   15.0|   283.7|
| 3745|   15.0|   283.8|
| 3746|   15.0|   283.8|
| 3747|   15.0|   283.8|
| 3748|   15.0|   283.8|
| 3749|   15.0|   283.9|
| 3750|   15.0|   283.9|
| 3751|   15.0|   283.9|
| 3752|   15.0|   284.0|
| 3753|   15.0|   284.0|
| 3754|   15.0|   284.0|
| 3755|   15.0|   284.0|
| 3756|   15.0|   284.1|
| 3757|   15.0|   284.1|
| 3758|   15.0|   284.1|
| 3759|   15.0|   284.2|
| 3760|   15.0|   284.2|
| 3761|   15.0|   284.2|
| 3762|   15.0|   284.2|
| 3763|   15.0|   284.3|
| 3764|   15.0|   284.3|
| 3765|   15.0|   284.3|
| 3766|   15.0|   284.4|
| 3767|   15.0|   284.4|
| 3768|   15.0|   284.4|
| 3769|   15.0|   284.4|
| 3770|   15.0|   284.5|
| 3771|   15.0|   284.5|
| 3772|   15.0|   284.5|
| 3773|   15.0|   284.6|
| 3774|   15.0|   284.6|
| 3775|   15.0|   284.6|
| 3776|   15.0|   284.6|
| 3777|   15.0|   284.7|
| 3778|   15.0|   284.7|
| 3779|   15.0|   284.7|
| 3780|   15.0|   284.8|
| 3781|   15.0|   284.8|
| 3782|   15.0|   284.8|
| 3783|   15.0|   284.8|
| 3784|   15.0|   284.9|
| 3785|   15.0|   284.9|
| 3786|   15.0|   284.9|
| 3787|   15.0|   285.0|
| 3788|   15.0|   285.0|
| 3789|   15.0|   285.0|
| 3790|   15.0|   285.0|
| 3791|   15.0|   285.1|
| 3792|   15.0|   285.1|
| 3793|   15.0|   285.1|
| 3794|   15.0|   285.2|
| 3795|   15.0|   285.2|
| 3796|   15.0|   285.2|
| 3797|   15.0|   285.2|
| 3798|   15.0|   285.3|
| 3799|   15.0|   285.3|
| 3800|   15.0|   285.3|
| 3801|   15.0|   285.4|
| 3802|   15.0|   285.4|
| 3803|   15.0|   285.4|
| 3804|   15.0|   285.4|
| 3805|   15.0|   285.5|
| 3806|   15.0|   285.5|
| 3807|   15.0|   285.5|
| 3808|   15.0|   285.6|
| 3809|   15.0|   285.6|
| 3810|   15.0|   285.6|
| 3811|   15.0|   285.6|
| 3812|   15.0|   285.7|
| 3813|   15.0|   285.7|
| 3814|   15.0|   285.7|
| 3815|   15.0|   285.8|
| 3816|   15.0|   285.8|
| 3817|   15.0|   285.8|
| 3818|   15.0|   285.8|
| 3819|   15.0|   285.9|
| 3820|   15.0|   285.9|
| 3821|   15.0|   285.9|
| 3822|   15.0|   286.0|
| 3823|   15.0|   286.0|
| 3824|   15.0|   286.0|
| 3825|   15.0|   286.0|
| 3826|   15.0|   286.1|
| 3827|   15.0|   286.1|
| 3828|   15.0|   286.1|
| 3829|   15.0|   286.2|
| 3830|   15.0|   286.2|
| 3831|   15.0|   286.2|
| 3832|   15.0|   286.2|
| 3833|   15.0|   286.3|
| 3834|   15.0|   286.3|
| 3835|   15.0|   286.3|
| 3836|   15.0|   286.3|
| 3837|   15.0|   286.4|
| 3838|   15.0|   286.4|
| 3839|   15.0|   286.4|
| 3840|   15.0|   286.5|
| 3841|   15.0|   286.5|
| 3842|   15.0|   286.5|
| 3843|   15.0|   286.5|
| 3844|   15.0|   286.6|
| 3845|   15.0|   286.6|
| 3846|   15.0|   286.6|
| 3847|   15.0|   286.7|
| 3848|   15.0|   286.7|
| 3849|   15.0|   286.7|
| 3850|   15.0|   286.7|
| 3851|   15.0|   286.8|
| 3852|   15.0|   286.8|
| 3853|   15.0|   286.8|
| 3854|   15.0|   286.9|
| 3855|   15.0|   286.9|
| 3856|   15.0|   286.9|
| 3857|   15.0|   286.9|
| 3858|   15.0|   287.0|
| 3859|   15.0|   287.0|
| 3860|   15.0|   287.0|
| 3861|   15.0|   287.1|
| 3862|   15.0|   287.1|
| 3863|   15.0|   287.1|
| 3864|   15.0|   287.1|
| 3865|   15.0|   287.2|
| 3866|   15.0|   287.2|
| 3867|   15.0|   287.2|
| 3868|   15.0|   287.3|
| 3869|   15.0|   287.3|
| 3870|   15.0|   287.3|
| 3871|   15.0|   287.3|
| 3872|   15.0|   287.4|
| 3873|   15.0|   287.4|
| 3874|   15.0|   287.4|
| 3875|   15.0|   287.4|
| 3876|   15.0|   287.5|
| 3877|   15.0|   287.5|
| 3878|   15.0|   287.5|
| 3879|   15.0|   287.6|
| 3880|   15.0|   287.6|
| 3881|   15.0|   287.6|
| 3882|   15.0|   287.6|
| 3883|   15.0|   287.7|
| 3884|   15.0|   287.7|
| 3885|   15.0|   287.7|
| 3886|   15.0|   287.8|
| 3887|   15.0|   287.8|
| 3888|   15.0|   287.8|
| 3889|   15.0|   287.8|
| 3890|   15.0|   287.9|
| 3891|   15.0|   287.9|
| 3892|   15.0|   287.9|
| 3893|   15.0|   288.0|
| 3894|   15.0|   288.0|
| 3895|   15.0|   288.0|
| 3896|   15.0|   288.0|
| 3897|   15.0|   288.1|
| 3898|   15.0|   288.1|
| 3899|   15.0|   288.1|
| 3900|   15.0|   288.2|
| 3901|   15.0|   288.2|
| 3902|   15.0|   288.2|
| 3903|   15.0|   288.2|
| 3904|   15.0|   288.3|
| 3905|   15.0|   288.3|
| 3906|   15.0|   288.3|
| 3907|   15.0|   288.3|
| 3908|   15.0|   288.4|
| 3909|   15.0|   288.4|
| 3910|   15.0|   288.4|
| 3911|   15.0|   288.5|
| 3912|   15.0|   288.5|
| 3913|   15.0|   288.5|
| 3914|   15.0|   288.5|
| 3915|   15.0|   288.6|
| 3916|   15.0|   288.6|
| 3917|   15.0|   288.6|
| 3918|   15.0|   288.7|
| 3919|   15.0|   288.7|
| 3920|   15.0|   288.7|
| 3921|   15.0|   288.7|
| 3922|   15.0|   288.8|
| 3923|   15.0|   288.8|
| 3924|   15.0|   288.8|
| 3925|   15.0|   288.9|
| 3926|   15.0|   288.9|
| 3927|   15.0|   288.9|
| 3928|   15.0|   288.9|
| 3929|   15.0|   289.0|
| 3930|   15.0|   289.0|
| 3931|   15.0|   289.0|
| 3932|   15.0|   289.0|
| 3933|   15.0|   289.1|
| 3934|   15.0|   289.1|
| 3935|   15.0|   289.1|
| 3936|   15.0|   289.2|
| 3937|   15.0|   289.2|
| 3938|   15.0|   289.2|
| 3939|   15.0|   289.2|
| 3940|   15.0|   289.3|
| 3941|   15.0|   289.3|
| 3942|   15.0|   289.3|
| 3943|   15.0|   289.4|
| 3944|   15.0|   289.4|
| 3945|   15.0|   289.4|
| 3946|   15.0|   289.4|
| 3947|   15.0|   289.5|
| 3948|   15.0|   289.5|
| 3949|   15.0|   289.5|
| 3950|   15.0|   289.5|
| 3951|   15.0|   289.6|
| 3952|   15.0|   289.6|
| 3953|   15.0|   289.6|
| 3954|   15.0|   289.7|
| 3955|   15.0|   289.7|
| 3956|   15.0|   289.7|
| 3957|   15.0|   289.7|
| 3958|   15.0|   289.8|
| 3959|   15.0|   289.8|
| 3960|   15.0|   289.8|
| 3961|   15.0|   289.9|
| 3962|   15.0|   289.9|
| 3963|   15.0|   289.9|
| 3964|   15.0|   289.9|
| 3965|   15.0|   290.0|
| 3966|   15.0|   290.0|
| 3967|   15.0|   290.0|
| 3968|   15.0|   290.0|
| 3969|   15.0|   290.1|
| 3970|   15.0|   290.1|
| 3971|   15.0|   290.1|
| 3972|   15.0|   290.2|
| 3973|   15.0|   290.2|
| 3974|   15.0|   290.2|
| 3975|   15.0|   290.2|
| 3976|   15.0|   290.3|
| 3977|   15.0|   290.3|
| 3978|   15.0|   290.3|
| 3979|   15.0|   290.4|
| 3980|   15.0|   290.4|
| 3981|   15.0|   290.4|
| 3982|   15.0|   290.4|
| 3983|   15.0|   290.5|
| 3984|   15.0|   290.5|
| 3985|   15.0|   290.5|
| 3986|   15.0|   290.5|
| 3987|   15.0|   290.6|
| 3988|   15.0|   290.6|
| 3989|   15.0|   290.6|
| 3990|   15.0|   290.7|
| 3991|   15.0|   290.7|
| 3992|   15.0|   290.7|
| 3993|   15.0|   290.7|
| 3994|   15.0|   290.8|
| 3995|   15.0|   290.8|
| 3996|   15.0|   290.8|
| 3997|   15.0|   290.8|
| 3998|   15.0|   290.9|
| 3999|   15.0|   290.9|
| 4000|   15.0|   290.9|
| 4001|   15.0|   291.0|
| 4002|   15.0|   291.0|
| 4003|   15.0|   291.0|
| 4004|   15.0|   291.0|
| 4005|   15.0|   291.1|
| 4006|   15.0|   291.1|
| 4007|   15.0|   291.1|
| 4008|   15.0|   291.2|
| 4009|   15.0|   291.2|
| 4010|   15.0|   291.2|
| 4011|   15.0|   291.2|
| 4012|   15.0|   291.3|
| 4013|   15.0|   291.3|
| 4014|   15.0|   291.3|
| 4015|   15.0|   291.3|
| 4016|   15.0|   291.4|
| 4017|   15.0|   291.4|
| 4018|   15.0|   291.4|
| 4019|   15.0|   291.5|
| 4020|   15.0|   291.5|
| 4021|   15.0|   291.5|
| 4022|   15.0|   291.5|
| 4023|   15.0|   291.6|
| 4024|   15.0|   291.6|
| 4025|   15.0|   291.6|
| 4026|   15.0|   291.6|
| 4027|   15.0|   291.7|
| 4028|   15.0|   291.7|
| 4029|   15.0|   291.7|
| 4030|   15.0|   291.8|
| 4031|   15.0|   291.8|
| 4032|   15.0|   291.8|
| 4033|   15.0|   291.8|
| 4034|   15.0|   291.9|
| 4035|   15.0|   291.9|
| 4036|   15.0|   291.9|
| 4037|   15.0|   292.0|
| 4038|   15.0|   292.0|
| 4039|   15.0|   292.0|
| 4040|   15.0|   292.0|
| 4041|   15.0|   292.1|
| 4042|   15.0|   292.1|
| 4043|   15.0|   292.1|
| 4044|   15.0|   292.1|
| 4045|   15.0|   292.2|
| 4046|   15.0|   292.2|
| 4047|   15.0|   292.2|
| 4048|   15.0|   292.3|
| 4049|   15.0|   292.3|
| 4050|   15.0|   292.3|
| 4051|   15.0|   292.3|
| 4052|   15.0|   292.4|
| 4053|   15.0|   292.4|
| 4054|   15.0|   292.4|
| 4055|   15.0|   292.4|
| 4056|   15.0|   292.5|
| 4057|   15.0|   292.5|
| 4058|   15.0|   292.5|
| 4059|   15.0|   292.6|
| 4060|   15.0|   292.6|
| 4061|   15.0|   292.6|
| 4062|   15.0|   292.6|
| 4063|   15.0|   292.7|
| 4064|   15.0|   292.7|
| 4065|   15.0|   292.7|
| 4066|   15.0|   292.7|
| 4067|   15.0|   292.8|
| 4068|   15.0|   292.8|
| 4069|   15.0|   292.8|
| 4070|   15.0|   292.9|
| 4071|   15.0|   292.9|
| 4072|   15.0|   292.9|
| 4073|   15.0|   292.9|
| 4074|   15.0|   293.0|
| 4075|   15.0|   293.0|
| 4076|   15.0|   293.0|
| 4077|   15.0|   293.0|
| 4078|   15.0|   293.1|
| 4079|   15.0|   293.1|
| 4080|   15.0|   293.1|
| 4081|   15.0|   293.2|
| 4082|   15.0|   293.2|
| 4083|   15.0|   293.2|
| 4084|   15.0|   293.2|
| 4085|   15.0|   293.3|
| 4086|   15.0|   293.3|
| 4087|   15.0|   293.3|
| 4088|   15.0|   293.3|
| 4089|   15.0|   293.4|
| 4090|   15.0|   293.4|
| 4091|   15.0|   293.4|
| 4092|   15.0|   293.5|
| 4093|   15.0|   293.5|
| 4094|   15.0|   293.5|
| 4095|   15.0|   293.5|
| 4096|   15.0|   293.6|
| 4097|   15.0|   293.6|
| 4098|   15.0|   293.6|
| 4099|   15.0|   293.6|
| 4100|   15.0|   293.7|
| 4101|   15.0|   293.7|
| 4102|   15.0|   293.7|
| 4103|   15.0|   293.8|
| 4104|   15.0|   293.8|
| 4105|   15.0|   293.8|
| 4106|   15.0|   293.8|
| 4107|   15.0|   293.9|
| 4108|   15.0|   293.9|
| 4109|   15.0|   293.9|
| 4110|   15.0|   293.9|
| 4111|   15.0|   294.0|
| 4112|   15.0|   294.0|
| 4113|   15.0|   294.0|
| 4114|   15.0|   294.1|
| 4115|   15.0|   294.1|
| 4116|   15.0|   294.1|
| 4117|   15.0|   294.1|
| 4118|   15.0|   294.2|
| 4119|   15.0|   294.2|
| 4120|   15.0|   294.2|
| 4121|   15.0|   294.2|
| 4122|   15.0|   294.3|
| 4123|   15.0|   294.3|
| 4124|   15.0|   294.3|
| 4125|   15.0|   294.3|
| 4126|   15.0|   294.4|
| 4127|   15.0|   294.4|
| 4128|   15.0|   294.4|
| 4129|   15.0|   294.5|
| 4130|   15.0|   294.5|
| 4131|   15.0|   294.5|
| 4132|   15.0|   294.5|
| 4133|   15.0|   294.6|
| 4134|   15.0|   294.6|
| 4135|   15.0|   294.6|
| 4136|   15.0|   294.6|
| 4137|   15.0|   294.7|
| 4138|   15.0|   294.7|
| 4139|   15.0|   294.7|
| 4140|   15.0|   294.8|


``` r
# Tabla de tiempos de retorno (primeros 25 niveles u)
tabla_tr <- data.frame(
  u = u_vals,
  Gumbel =tr_gumbel_vals,
  Fréchet = tr_frechet_vals
)

# Mostrar con kable
knitr::kable(tabla_tr, digits = 1, caption = "TR para Gumbel y Fréchet")
```



Table: (\#tab:tablaTR)TR para Gumbel y Fréchet

|   u|       Gumbel| Fréchet|
|---:|------------:|-------:|
|  15| 1.600000e+00|     1.0|
|  20| 2.200000e+00|     1.0|
|  25| 3.200000e+00|     1.6|
|  30| 5.000000e+00|     3.3|
|  35| 7.900000e+00|     6.2|
|  40| 1.270000e+01|    10.4|
|  45| 2.060000e+01|    16.1|
|  50| 3.360000e+01|    23.4|
|  55| 5.510000e+01|    32.5|
|  60| 9.050000e+01|    43.5|
|  65| 1.489000e+02|    56.4|
|  70| 2.452000e+02|    71.4|
|  75| 4.039000e+02|    88.7|
|  80| 6.656000e+02|   108.2|
|  85| 1.097100e+03|   130.1|
|  90| 1.808500e+03|   154.5|
|  95| 2.981500e+03|   181.5|
| 100| 4.915300e+03|   211.1|
| 105| 8.103600e+03|   243.5|
| 110| 1.336020e+04|   278.7|
| 115| 2.202700e+04|   316.7|
| 120| 3.631600e+04|   357.8|
| 125| 5.987460e+04|   401.8|
| 130| 9.871630e+04|   449.0|
| 135| 1.627553e+05|   499.3|
| 140| 2.683378e+05|   552.9|
| 145| 4.424139e+05|   609.8|
| 150| 7.294169e+05|   670.1|
| 155| 1.202605e+06|   733.9|
| 160| 1.982760e+06|   801.1|
| 165| 3.269018e+06|   871.9|
| 170| 5.389699e+06|   946.4|
| 175| 8.886111e+06|  1024.5|
| 180| 1.465072e+07|  1106.4|
| 185| 2.415495e+07|  1192.1|
| 190| 3.982478e+07|  1281.6|
| 195| 6.565997e+07|  1375.1|
| 200| 1.082550e+08|  1472.6|
| 205| 1.784823e+08|  1574.1|
| 210| 2.942676e+08|  1679.6|
| 215| 4.851652e+08|  1789.4|
| 220| 7.999022e+08|  1903.3|
| 225| 1.318816e+09|  2021.4|
| 230| 2.174359e+09|  2143.9|
| 235| 3.584914e+09|  2270.7|
| 240| 5.910523e+09|  2401.9|
| 245| 9.744803e+09|  2537.5|
| 250| 1.606647e+10|  2677.6|

Ahora si observamos los resultados tabulados en las Tablas \@ref(tab:tablaVR) y \@ref(tab:tablaTR):




``` r
# Elegir t
t <- 90

# Calcular VR(t)
vr_t_gumbel <- vr_gumbel_vals[which(t_vals == t)]
vr_t_frechet <- vr_frechet_vals[which(t_vals == t)]

# Evaluar TR en VR(t)
tr_vr_gumbel <- TR_gumbel(vr_t_gumbel, mu, beta)
tr_vr_frechet <- TR_frechet(vr_t_frechet, mu, beta, alpha)

# Mostrar
cat("Gumbel:\n VR(90) =", round(vr_t_gumbel, 0), "→ TR(VR) =", round(tr_vr_gumbel, 1), "\n")
```

```
## Gumbel:
##  VR(90) = 15 → TR(VR) = 1.6
```

``` r
cat("Fréchet:\n VR(90) =", round(vr_t_frechet, 0), "→ TR(VR) =", round(tr_vr_frechet, 1), "\n")
```

```
## Fréchet:
##  VR(90) = 75 → TR(VR) = 90
```
Interpretación del resultado: 

- Para la Gumbel: Si vamos a la Tabla \@ref(tab:tablaVR) y miramos $t=90$, el $VR(t=90)\approx 15$, si vamos a la la Tabla \@ref(tab:tablaTR) el $TR(u=15)\approx 1.6$. 

- Para la Fréchet: Si vamos a la Tabla \@ref(tab:tablaVR) y miramos $t=90$, el $VR(t=90)\approx 75$, si vamos a la la Tabla \@ref(tab:tablaTR) el $TR(u=15)\approx 1.6$. 

-->
<!--

<div class="figure">
<img src="01-asint_files/figure-html/fig1-1.png" alt="(1) Gráfico de cuantiles (Q–Q)" width="576" />
<p class="caption">(\#fig:fig1)(1) Gráfico de cuantiles (Q–Q)</p>
</div>

<div class="figure">
<img src="01-asint_files/figure-html/fig2-1.png" alt="(2) Gráfico de probabilidades (P–P)" width="576" />
<p class="caption">(\#fig:fig2)(2) Gráfico de probabilidades (P–P)</p>
</div>

<div class="figure">
<img src="01-asint_files/figure-html/fig3-1.png" alt="(3) Gráfico de densidad" width="576" />
<p class="caption">(\#fig:fig3)(3) Gráfico de densidad</p>
</div>

<div class="figure">
<img src="01-asint_files/figure-html/fig4-1.png" alt="(4) Gráfico de residuos estandarizados" width="576" />
<p class="caption">(\#fig:fig4)(4) Gráfico de residuos estandarizados</p>
</div>


-->
</div>
</div>


















<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>El análisis asintótico es un método de descripción del comportamiento en el límite.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>EVT por sus siglas en en inglés relativas a Extreme Value
Theory.<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>BM, por sus siglas en inglés relativas a Block Maxima.<a href="#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>POT, por sus siglas en inglés.<a href="#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>Sea <span class="math inline">\(z^+\)</span> el menor valor de <span class="math inline">\(z\)</span> tal que <span class="math inline">\(F(z) = 1\)</span>. O sea, es el valor más bajo a partir del cual la función de distribución ya no crece más. Es el “techo” natural de la variable aleatoria.<a href="#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p>En el Apéndice <a href="#sec:ap"><strong>??</strong></a> se encuentra el Teorema <a href="#thm:thap1"><strong>??</strong></a> de los tipos de extremales.<a href="#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p>Donde <span class="math inline">\(x = \frac{z - b}{a}\)</span>, y se ha fijado <span class="math inline">\(b = 0\)</span> y <span class="math inline">\(a = 1\)</span> para expresar las distribuciones en su forma estándar.<a href="#fnref7" class="footnote-back">↩︎</a></p></li>
<li id="fn8"><p>Porque la Weibull tiene soporte en <span class="math inline">\((-\infty, 0]\)</span>.<a href="#fnref8" class="footnote-back">↩︎</a></p></li>
<li id="fn9"><p>En el Apéndice <a href="#sec:pdf"><strong>??</strong></a> se explica la diferencia entre PDF y CDF.<a href="#fnref9" class="footnote-back">↩︎</a></p></li>
<li id="fn10"><p>La función Gamma permite expresar la media, la varianza y otras propiedades estadísticas de la GEV (ver Apéndice <a href="#sec:gev"><strong>??</strong></a>) en función de su parámetro de forma <span class="math inline">\(\xi\)</span>.<a href="#fnref10" class="footnote-back">↩︎</a></p></li>
<li id="fn11"><p>Al final del capítulo 2 se verá que esto puede subsanarse con versiones más generales del Teorema <a href="#thm:FTG">1.3</a>.<a href="#fnref11" class="footnote-back">↩︎</a></p></li>
<li id="fn12"><p>En inglés es <em>randomness</em>.<a href="#fnref12" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>


    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/%s",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": false,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
